#!/usr/bin/env python3
"""
092_final_econometric_model æ ¸å¿ƒè®¡é‡æ¨¡å‹
======================================

æœ€ç»ˆçš„å±€éƒ¨æŠ•å½±è„‰å†²å“åº”(LP-IRF)æ¨¡å‹å®ç°

ç†è®ºæ¡†æ¶ï¼šèƒ½æºç½‘ç»œç¼“å†²æœºåˆ¶çš„å› æœè¯†åˆ«
==================================

æ ¸å¿ƒç ”ç©¶é—®é¢˜ï¼š
OVI (å¯¹å¤–è„†å¼±æ€§æŒ‡æ•°) æ˜¯å¦çœŸæ­£å…·æœ‰ç¼“å†²å¤–éƒ¨ä¾›ç»™å†²å‡»çš„å› æœä½œç”¨ï¼Ÿ

æ¨¡å‹è®¾å®šï¼š
- ä»·æ ¼é€šé“ (Model 5A): P^lng_{i,t+h} = Î²_hÂ·us_prod_shock_t + Î¸_hÂ·(us_prod_shock_t Ã— ovi_gas_{i,t-1}) + Î´_hÂ·(us_prod_shock_t Ã— distance_to_us_i) + Controls + Î±_i + Î»_t + Î·_{i,t+h}
- æ•°é‡é€šé“ (Model 5B): g_{i,t+h} = Î²_hÂ·us_prod_shock_t + Î¸_hÂ·(us_prod_shock_t Ã— ovi_gas_{i,t-1}) + Î´_hÂ·(us_prod_shock_t Ã— distance_to_us_i) + Controls + Î±_i + Î»_t + Î·_{i,t+h}

æ ¸å¿ƒç³»æ•°ï¼šÎ¸_h (us_prod_shock Ã— ovi_gasäº¤äº’é¡¹)
- ä»·æ ¼é€šé“é¢„æœŸï¼šÎ¸_h < 0 (OVIç¼“è§£ä»·æ ¼å†²å‡»)
- æ•°é‡é€šé“é¢„æœŸï¼šÎ¸_h < 0 (OVIèµ‹äºˆä¸»åŠ¨è°ƒèŠ‚èƒ½åŠ›)

æ§åˆ¶åœ°ç†å™ªéŸ³ï¼šÎ´_h (us_prod_shock Ã— distance_to_usäº¤äº’é¡¹)
- å‰¥ç¦»çº¯ç²¹çš„åœ°ç†è·ç¦»æ•ˆåº”ï¼Œè¯†åˆ«ç½‘ç»œç»“æ„çš„ç‹¬ç«‹ä½œç”¨

ä½œè€…ï¼šEnergy Network Analysis Team
ç‰ˆæœ¬ï¼šv1.0 - å†³å®šæ€§å› æœæ¨æ–­ç‰ˆæœ¬
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
import logging
from pathlib import Path
import warnings
import matplotlib.pyplot as plt
import seaborn as sns

# è®¡é‡åˆ†æåº“
try:
    import statsmodels.api as sm
    from statsmodels.formula.api import ols
    HAS_STATSMODELS = True
except ImportError:
    HAS_STATSMODELS = False

try:
    from linearmodels import PanelOLS
    HAS_LINEARMODELS = True
except ImportError:
    HAS_LINEARMODELS = False

warnings.filterwarnings('ignore')
logger = logging.getLogger(__name__)

class FinalEconometricModels:
    """
    æœ€ç»ˆè®¡é‡æ¨¡å‹ç±» - LNG-onlyä¸¥æ ¼ä¼˜åŒ–ç‰ˆæœ¬
    - ä¸¥æ ¼çš„LNG-onlyæ ·æœ¬ç­›é€‰
    - log(P_lng)å› å˜é‡å¤„ç†
    - ln(1+OVI)äº¤äº’é¡¹ä¼˜åŒ–
    - å¹³è¡¡é¢æ¿æ„å»º
    """
    
    def __init__(self, output_dir: Optional[Path] = None):
        """
        åˆå§‹åŒ–æœ€ç»ˆè®¡é‡æ¨¡å‹
        
        Args:
            output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ä¸‹çš„outputs
        """
        if output_dir is None:
            self.output_dir = Path("outputs")
        else:
            self.output_dir = Path(output_dir)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # é¢„æµ‹æœŸæ•°è®¾å®š (0-1å¹´) - LNG-onlyä¸¥æ ¼ä¼˜åŒ–ç‰ˆæœ¬
        self.horizons = list(range(2))  # åªåšh=0,1
        
        logger.info("ğŸ”¬ 093 LNG-onlyä¸¥æ ¼ä¼˜åŒ–æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        
        # æ£€æŸ¥ä¾èµ–åº“
        if not HAS_STATSMODELS:
            logger.warning("âš ï¸ statsmodelsåº“ä¸å¯ç”¨")
        if not HAS_LINEARMODELS:
            logger.warning("âš ï¸ linearmodelsåº“ä¸å¯ç”¨")
    
    def _prepare_lng_only_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        LNG-onlyä¸¥æ ¼æ•°æ®å¤„ç†
        
        1. å› å˜é‡ï¼šlog(P_lng) 
        2. æ ·æœ¬ç­›é€‰ï¼šOVI_lag1 > 0 ä¸” P_lng éç¼ºå¤±
        3. äº¤äº’é¡¹ï¼šus_prod_shock Ã— ln(1+OVI_lag1)
        4. å¹³è¡¡é¢æ¿ï¼šh=0å’Œh=1éƒ½éç¼ºå¤±çš„è§‚æµ‹
        """
        logger.info("ğŸš¢ å¼€å§‹LNG-onlyä¸¥æ ¼æ•°æ®å¤„ç†...")
        df_work = df.copy()
        
        # æŒ‰å›½å®¶-å¹´ä»½æ’åº
        df_work = df_work.sort_values(['country', 'year'])
        
        # 1. åˆ›å»ºæ»åOVIå˜é‡
        df_work['ovi_gas_lag1'] = df_work.groupby('country')['ovi_gas'].shift(1)
        
        # 2. LNG-onlyä¸¥æ ¼æ ·æœ¬ç­›é€‰
        logger.info("   ğŸ“‹ åº”ç”¨LNG-onlyæ ·æœ¬ç­›é€‰æ¡ä»¶...")
        
        # æ¡ä»¶1: OVI_lag1 > 0 (çœŸæœ‰LNGå†—ä½™)
        mask_ovi = df_work['ovi_gas_lag1'] > 0
        
        # æ¡ä»¶2: P_lngéç¼ºå¤± (ç¡®å®å‘ç”Ÿäº†LNGè´¸æ˜“/æŠ¥ä»·)  
        mask_lng = df_work['P_lng'].notna()
        
        # ç»¼åˆç­›é€‰
        lng_only_mask = mask_ovi & mask_lng
        df_lng_only = df_work[lng_only_mask].copy()
        
        logger.info(f"   âœ“ LNG-onlyç­›é€‰å®Œæˆ: {len(df_lng_only):,} / {len(df_work):,} è§‚æµ‹å€¼ ({len(df_lng_only)/len(df_work):.1%})")
        
        if len(df_lng_only) == 0:
            logger.error("   âŒ LNG-onlyç­›é€‰åæ— æœ‰æ•ˆè§‚æµ‹å€¼")
            return df_lng_only
        
        # 3. åˆ›å»ºlog(P_lng)å› å˜é‡
        df_lng_only['log_P_lng'] = np.log(df_lng_only['P_lng'])
        logger.info("   âœ“ åˆ›å»ºlog(P_lng)å› å˜é‡")
        
        # 4. åˆ›å»ºln(1+OVI)äº¤äº’é¡¹
        df_lng_only['ln_1_plus_ovi_lag1'] = np.log(1 + df_lng_only['ovi_gas_lag1'])
        df_lng_only['shock_ln_ovi_interaction'] = (
            df_lng_only['us_prod_shock'] * df_lng_only['ln_1_plus_ovi_lag1']
        )
        logger.info("   âœ“ åˆ›å»ºus_prod_shock Ã— ln(1+OVI_lag1)äº¤äº’é¡¹")
        
        # 5. åˆ›å»ºå¹³è¡¡é¢æ¿çš„å‰ç»å˜é‡
        logger.info("   ğŸ”„ åˆ›å»ºh=0,1çš„å‰ç»å˜é‡...")
        for h in [0, 1]:
            if h == 0:
                df_lng_only[f'log_P_lng_h{h}'] = df_lng_only['log_P_lng']
            else:
                df_lng_only[f'log_P_lng_h{h}'] = df_lng_only.groupby('country')['log_P_lng'].shift(-h)
        
        # 6. æ„å»ºå¹³è¡¡é¢æ¿ï¼šh=0å’Œh=1éƒ½éç¼ºå¤±
        balanced_mask = (
            df_lng_only['log_P_lng_h0'].notna() & 
            df_lng_only['log_P_lng_h1'].notna()
        )
        df_balanced = df_lng_only[balanced_mask].copy()
        
        logger.info(f"   âœ… å¹³è¡¡é¢æ¿æ„å»ºå®Œæˆ: {len(df_balanced):,} è§‚æµ‹å€¼")
        logger.info(f"      æ¶µç›–å›½å®¶: {df_balanced['country'].nunique()} ä¸ª")
        logger.info(f"      æ—¶é—´è·¨åº¦: {df_balanced['year'].min()}-{df_balanced['year'].max()}")
        
        return df_balanced
            
    def _validate_data_for_lp_irf(self, df: pd.DataFrame, required_vars: List[str]) -> Tuple[bool, str, pd.DataFrame]:
        """
        éªŒè¯æ•°æ®æ˜¯å¦é€‚åˆLP-IRFåˆ†æ
        
        Args:
            df: è¾“å…¥æ•°æ®
            required_vars: å¿…éœ€å˜é‡åˆ—è¡¨
            
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, çŠ¶æ€æ¶ˆæ¯, æ¸…ç†åçš„æ•°æ®)
        """
        if df.empty:
            return False, "æ•°æ®é›†ä¸ºç©º", pd.DataFrame()
        
        # æ£€æŸ¥å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨
        missing_vars = [var for var in required_vars if var not in df.columns]
        if missing_vars:
            return False, f"ç¼ºå°‘å¿…éœ€å˜é‡: {missing_vars}", df
        
        # åˆ›å»ºé¢æ¿æ ‡è¯†å’Œäº¤äº’é¡¹
        df_work = df.copy()
        
        # æ£€æŸ¥é¢æ¿æ ‡è¯†
        if 'country' not in df_work.columns or 'year' not in df_work.columns:
            return False, "ç¼ºå°‘é¢æ¿æ•°æ®æ ‡è¯†(country, year)", df_work
        
        # æŒ‰å›½å®¶-å¹´ä»½æ’åº
        df_work = df_work.sort_values(['country', 'year'])
        
        # åˆ›å»ºæ»åOVIå˜é‡
        df_work['ovi_gas_lag1'] = df_work.groupby('country')['ovi_gas'].shift(1)
        
        # åˆ›å»ºæ ¸å¿ƒäº¤äº’é¡¹
        df_work['shock_ovi_interaction'] = (
            df_work['us_prod_shock'] * df_work['ovi_gas_lag1']
        )
        
        # åˆ›å»ºåœ°ç†æ§åˆ¶äº¤äº’é¡¹
        if 'distance_to_us' in df_work.columns:
            df_work['shock_distance_interaction'] = (
                df_work['us_prod_shock'] * df_work['distance_to_us']
            )
        
        # ç§»é™¤ç¼ºå¤±å€¼
        essential_vars = ['country', 'year', 'us_prod_shock', 'ovi_gas_lag1', 'shock_ovi_interaction']
        df_clean = df_work.dropna(subset=essential_vars)
        
        if len(df_clean) < 50:
            return False, f"æ¸…ç†åæ ·æœ¬é‡ä¸è¶³: {len(df_clean)} < 50", df_clean
        
        countries_count = df_clean['country'].nunique()
        years_count = df_clean['year'].nunique()
        
        logger.info(f"   æ•°æ®éªŒè¯é€šè¿‡: {len(df_clean)} è§‚æµ‹å€¼, {countries_count} å›½å®¶, {years_count} å¹´ä»½")
        
        return True, "æ•°æ®éªŒè¯é€šè¿‡", df_clean
    
    def run_price_channel_lp_irf(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        è¿è¡ŒLNG-onlyä¸¥æ ¼ä¼˜åŒ–çš„ä»·æ ¼é€šé“LP-IRFæ¨¡å‹
        
        LNG-onlyæ¨¡å‹ï¼šlog(P_lng)_{i,t+h} = Î±_i + Î»_t + Î¸_hÂ·(us_prod_shock_t Ã— ln(1+ovi_gas_{i,t-1})) + Î“Â·Controls + Î·_{i,t+h}
        
        å…³é”®ä¼˜åŒ–ï¼š
        1. å› å˜é‡ï¼šlog(P_lng) è€Œéæ ‡å‡†åŒ–
        2. æ ·æœ¬ç­›é€‰ï¼šOVI_lag1 > 0 ä¸” P_lng éç¼ºå¤±
        3. äº¤äº’é¡¹ï¼šus_prod_shock Ã— ln(1+OVI_lag1) 
        4. å¹³è¡¡é¢æ¿ï¼šh=0,1éƒ½éç¼ºå¤±çš„ç›¸åŒè§‚æµ‹
        5. ç§»é™¤distanceäº¤äº’é¡¹é¿å…å…±çº¿æ€§
        
        Args:
            df: å®Œæ•´åˆ†ææ•°æ®é›†
            
        Returns:
            æ¨¡å‹ç»“æœå­—å…¸
        """
        model_name = 'lng_only_price_channel_lp_irf'
        logger.info(f"ğŸš¢ è¿è¡ŒLNG-onlyä¸¥æ ¼ä¼˜åŒ–ä»·æ ¼é€šé“LP-IRF...")
        
        # LNG-onlyæ•°æ®å¤„ç†
        df_lng_balanced = self._prepare_lng_only_data(df)
        
        if len(df_lng_balanced) == 0:
            return self._create_empty_result(model_name, "LNG-onlyç­›é€‰åæ— æœ‰æ•ˆè§‚æµ‹å€¼")
        
        if not HAS_LINEARMODELS:
            return self._create_empty_result(model_name, "ç¼ºå°‘linearmodelsåº“")
        
        try:
            # LNG-onlyæ¨¡å‹å·²ç»åœ¨prepareå‡½æ•°ä¸­åˆ›å»ºäº†å‰ç»å˜é‡
            logger.info("   âœ… ä½¿ç”¨å¹³è¡¡é¢æ¿çš„å‰ç»å˜é‡ log_P_lng_h0, log_P_lng_h1")
            
            # LNG-onlyè§£é‡Šå˜é‡è®¾å®š
            base_vars = ['shock_ln_ovi_interaction']  # æ ¸å¿ƒï¼šus_prod_shock Ã— ln(1+OVI_lag1)
            control_vars = ['log_gdp', 'log_population']  # æ§åˆ¶å˜é‡
            
            explanatory_vars = base_vars + control_vars
            logger.info("   âœ… LNG-onlyè¯†åˆ«ç­–ç•¥ï¼šèšç„¦us_prod_shock Ã— ln(1+OVI_lag1)å¼‚è´¨æ•ˆåº”")
            
            # å¯¹æ¯ä¸ªé¢„æµ‹æœŸè¿è¡Œå›å½’ (h=0,1)
            horizon_results = {}
            logger.info(f"   å¼€å§‹ä¼°è®¡ {len(self.horizons)} ä¸ªé¢„æµ‹æœŸ (LNG-onlyå¹³è¡¡é¢æ¿)...")
            
            for h in self.horizons:
                logger.info(f"     é¢„æµ‹æœŸ h={h} (LNG-only)...")
                
                # å¹³è¡¡é¢æ¿æ•°æ®ï¼šä½¿ç”¨ç›¸åŒçš„è§‚æµ‹é›†åˆ
                horizon_data = df_lng_balanced.dropna(subset=[f'log_P_lng_h{h}'] + explanatory_vars)
                
                if len(horizon_data) < 30:
                    logger.warning(f"       LNG-onlyæ ·æœ¬ä¸è¶³: {len(horizon_data)} < 30")
                    continue
                
                try:
                    # è®¾ç½®é¢æ¿ç´¢å¼•
                    horizon_data = horizon_data.set_index(['country', 'year'])
                    
                    # LNG-onlyåŒå‘å›ºå®šæ•ˆåº”æ¨¡å‹
                    model = PanelOLS(
                        dependent=horizon_data[f'log_P_lng_h{h}'],
                        exog=horizon_data[explanatory_vars],
                        entity_effects=True,    # å›½å®¶å›ºå®šæ•ˆåº”
                        time_effects=True,      # å¹´ä»½å›ºå®šæ•ˆåº”
                        check_rank=False
                    )
                    
                    results = model.fit(cov_type='clustered', cluster_entity=True)
                    
                    # æå–æ ¸å¿ƒç³»æ•°Î¸_h (LNG-onlyç‰ˆæœ¬ä½¿ç”¨lnäº¤äº’é¡¹)
                    theta_h = results.params.get('shock_ln_ovi_interaction', np.nan)
                    theta_se = results.std_errors.get('shock_ln_ovi_interaction', np.nan) 
                    theta_pval = results.pvalues.get('shock_ln_ovi_interaction', 1.0)
                    
                    # è®¡ç®—ç½®ä¿¡åŒºé—´
                    theta_ci_lower = theta_h - 1.96 * theta_se
                    theta_ci_upper = theta_h + 1.96 * theta_se
                    
                    horizon_results[h] = {
                        'horizon': h,
                        'theta_coefficient': float(theta_h),
                        'theta_std_error': float(theta_se),
                        'theta_p_value': float(theta_pval),
                        'theta_ci_lower': float(theta_ci_lower),
                        'theta_ci_upper': float(theta_ci_upper),
                        'theta_significant': theta_pval < 0.05,
                        'expected_sign_correct': theta_h < 0,  # ä»·æ ¼é€šé“é¢„æœŸè´Ÿå€¼
                        'r_squared': float(results.rsquared),
                        'n_obs': int(results.nobs),
                        'all_coefficients': dict(results.params),
                        'all_p_values': dict(results.pvalues)
                    }
                    
                    # æ˜¾ç¤ºç»“æœ
                    significance = "***" if theta_pval < 0.01 else "**" if theta_pval < 0.05 else "*" if theta_pval < 0.10 else ""
                    logger.info(f"       Î¸_{h} = {theta_h:.4f}{significance} (SE={theta_se:.4f}, p={theta_pval:.3f})")
                    
                except Exception as e:
                    logger.warning(f"       ä¼°è®¡å¤±è´¥: {str(e)}")
                    continue
            
            if not horizon_results:
                return self._create_empty_result(model_name, "æ‰€æœ‰é¢„æµ‹æœŸä¼°è®¡å¤±è´¥")
            
            # æ±‡æ€»ç»“æœ
            result_dict = {
                'model_name': model_name,
                'model_type': 'price_channel_lp_irf',
                'status': 'success',
                'status_message': f'ä»·æ ¼é€šé“LP-IRFä¼°è®¡æˆåŠŸï¼Œ{len(horizon_results)}ä¸ªé¢„æµ‹æœŸ',
                'horizon_results': horizon_results,
                'horizons_estimated': sorted(horizon_results.keys()),
                'n_horizons': len(horizon_results),
                'dependent_variable': 'P_lng (LNGä»·æ ¼)',
                'core_interaction': 'us_prod_shock Ã— ovi_gas_lag1',
                'expected_sign': 'negative (ç¼“å†²ä»·æ ¼å†²å‡»)',
                'data_available': True,
                'total_sample_size': len(df_lng_balanced)
            }
            
            logger.info(f"   âœ… ä»·æ ¼é€šé“LP-IRFå®Œæˆ: {len(horizon_results)} ä¸ªé¢„æµ‹æœŸ")
            
            return result_dict
            
        except Exception as e:
            error_msg = f"ä»·æ ¼é€šé“LP-IRFä¼°è®¡å¤±è´¥: {str(e)}"
            logger.error(f"   âŒ {error_msg}")
            return self._create_empty_result(model_name, error_msg)
    
    def run_quantity_channel_lp_irf(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        è¿è¡Œæ•°é‡é€šé“LP-IRFæ¨¡å‹ (Model 5B)
        
        ä¿®æ­£æ¨¡å‹ï¼šg_{i,t+h} = Î±_i + Î»_t + Î¸_hÂ·(us_prod_shock_t Ã— ovi_gas_{i,t-1}) + 
                               Î´_hÂ·(us_prod_shock_t Ã— distance_to_us_i) + Î“Â·Controls + Î·_{i,t+h}
        
        æ ¸å¿ƒè¯†åˆ«ï¼šÎ¸_h ç³»æ•°çš„å¼‚è´¨æ•ˆåº”ï¼Œé¢„æœŸä¸ºè´Ÿå€¼ï¼ˆOVIèµ‹äºˆä¸»åŠ¨è°ƒèŠ‚èƒ½åŠ›ï¼‰
        æ³¨ï¼šÎ²_hä¸»æ•ˆåº”è¢«å¹´ä»½å›ºå®šæ•ˆåº”Î»_tå¸æ”¶ï¼Œä¸“æ³¨è¯†åˆ«äº¤äº’é¡¹å¼‚è´¨æ•ˆåº”
        
        Args:
            df: å®Œæ•´åˆ†ææ•°æ®é›†
            
        Returns:
            æ¨¡å‹ç»“æœå­—å…¸
        """
        model_name = 'model_5b_quantity_channel_lp_irf'
        logger.info(f"ğŸ“Š è¿è¡Œæ•°é‡é€šé“LP-IRFæ¨¡å‹ (Model 5B)...")
        
        # éªŒè¯æ•°æ®
        required_vars = ['g_it', 'us_prod_shock', 'ovi_gas', 'distance_to_us', 'log_gdp', 'log_population']
        is_valid, message, df_clean = self._validate_data_for_lp_irf(df, required_vars)
        
        if not is_valid:
            logger.warning(f"   âš ï¸ {message}")
            return self._create_empty_result(model_name, message)
        
        if not HAS_LINEARMODELS:
            return self._create_empty_result(model_name, "ç¼ºå°‘linearmodelsåº“")
        
        try:
            # ä¸ºæ¯ä¸ªé¢„æµ‹æœŸåˆ›å»ºå‰ç»å˜é‡
            logger.info("   åˆ›å»ºå‰ç»æ•°é‡å˜é‡...")
            for h in self.horizons:
                if h == 0:
                    df_clean[f'g_it_h{h}'] = df_clean['g_it']
                else:
                    df_clean[f'g_it_h{h}'] = df_clean.groupby('country')['g_it'].shift(-h)
            
            # å‡†å¤‡è§£é‡Šå˜é‡ - ä¿®æ­£è¯†åˆ«ç­–ç•¥ï¼šåªå…³æ³¨äº¤äº’é¡¹å¼‚è´¨æ•ˆåº”
            # ä¸åŒ…å«us_prod_shockä¸»æ•ˆåº”ï¼Œå› ä¸ºå¹´ä»½å›ºå®šæ•ˆåº”ä¼šå¸æ”¶å…±åŒå†²å‡»
            base_vars = ['shock_ovi_interaction']
            control_vars = ['log_gdp', 'log_population']
            
            # æ·»åŠ åœ°ç†æ§åˆ¶äº¤äº’é¡¹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if 'shock_distance_interaction' in df_clean.columns:
                base_vars.append('shock_distance_interaction')
                logger.info("   âœ“ åŒ…å«åœ°ç†è·ç¦»æ§åˆ¶äº¤äº’é¡¹")
            
            explanatory_vars = base_vars + control_vars
            logger.info("   âœ“ ä¿®æ­£è¯†åˆ«ç­–ç•¥ï¼šèšç„¦Î¸_häº¤äº’é¡¹å¼‚è´¨æ•ˆåº”ï¼ˆå¹´ä»½FEå¸æ”¶Î²_hä¸»æ•ˆåº”ï¼‰")
            
            # å¯¹æ¯ä¸ªé¢„æµ‹æœŸè¿è¡Œå›å½’
            horizon_results = {}
            logger.info(f"   å¼€å§‹ä¼°è®¡ {len(self.horizons)} ä¸ªé¢„æµ‹æœŸ...")
            
            for h in self.horizons:
                logger.info(f"     é¢„æµ‹æœŸ h={h}...")
                
                # å‡†å¤‡è¯¥æœŸæ•°çš„æ•°æ®
                horizon_data = df_clean.dropna(subset=[f'g_it_h{h}'] + explanatory_vars)
                
                if len(horizon_data) < 30:
                    logger.warning(f"       æ ·æœ¬ä¸è¶³: {len(horizon_data)} < 30")
                    continue
                
                try:
                    # è®¾ç½®é¢æ¿ç´¢å¼•
                    horizon_data = horizon_data.set_index(['country', 'year'])
                    
                    # ä¿®æ­£ï¼šä½¿ç”¨åŒå‘å›ºå®šæ•ˆåº”æ¨¡å‹ä»¥æ­£ç¡®è¯†åˆ«å¼‚è´¨æ•ˆåº”
                    model = PanelOLS(
                        dependent=horizon_data[f'g_it_h{h}'],
                        exog=horizon_data[explanatory_vars],
                        entity_effects=True,    # å›½å®¶å›ºå®šæ•ˆåº”
                        time_effects=True,      # å¹´ä»½å›ºå®šæ•ˆåº” - ä¿®æ­£å…³é”®é”™è¯¯ï¼
                        check_rank=False
                    )
                    
                    results = model.fit(cov_type='clustered', cluster_entity=True)
                    
                    # æå–æ ¸å¿ƒç³»æ•°Î¸_h
                    theta_h = results.params.get('shock_ovi_interaction', np.nan)
                    theta_se = results.std_errors.get('shock_ovi_interaction', np.nan)
                    theta_pval = results.pvalues.get('shock_ovi_interaction', 1.0)
                    
                    # è®¡ç®—ç½®ä¿¡åŒºé—´
                    theta_ci_lower = theta_h - 1.96 * theta_se
                    theta_ci_upper = theta_h + 1.96 * theta_se
                    
                    horizon_results[h] = {
                        'horizon': h,
                        'theta_coefficient': float(theta_h),
                        'theta_std_error': float(theta_se),
                        'theta_p_value': float(theta_pval),
                        'theta_ci_lower': float(theta_ci_lower),
                        'theta_ci_upper': float(theta_ci_upper),
                        'theta_significant': theta_pval < 0.05,
                        'expected_sign_correct': theta_h < 0,  # æ•°é‡é€šé“é¢„æœŸè´Ÿå€¼ï¼ˆä¸»åŠ¨å‡å°‘è¿›å£ï¼‰
                        'r_squared': float(results.rsquared),
                        'n_obs': int(results.nobs),
                        'all_coefficients': dict(results.params),
                        'all_p_values': dict(results.pvalues)
                    }
                    
                    # æ˜¾ç¤ºç»“æœ
                    significance = "***" if theta_pval < 0.01 else "**" if theta_pval < 0.05 else "*" if theta_pval < 0.10 else ""
                    logger.info(f"       Î¸_{h} = {theta_h:.4f}{significance} (SE={theta_se:.4f}, p={theta_pval:.3f})")
                    
                except Exception as e:
                    logger.warning(f"       ä¼°è®¡å¤±è´¥: {str(e)}")
                    continue
            
            if not horizon_results:
                return self._create_empty_result(model_name, "æ‰€æœ‰é¢„æµ‹æœŸä¼°è®¡å¤±è´¥")
            
            # æ±‡æ€»ç»“æœ
            result_dict = {
                'model_name': model_name,
                'model_type': 'quantity_channel_lp_irf',
                'status': 'success',
                'status_message': f'æ•°é‡é€šé“LP-IRFä¼°è®¡æˆåŠŸï¼Œ{len(horizon_results)}ä¸ªé¢„æµ‹æœŸ',
                'horizon_results': horizon_results,
                'horizons_estimated': sorted(horizon_results.keys()),
                'n_horizons': len(horizon_results),
                'dependent_variable': 'g_it (å¤©ç„¶æ°”è¿›å£é‡)',
                'core_interaction': 'us_prod_shock Ã— ovi_gas_lag1',
                'expected_sign': 'negative (ä¸»åŠ¨è°ƒèŠ‚è¿›å£)',
                'data_available': True,
                'total_sample_size': len(df_clean)
            }
            
            logger.info(f"   âœ… æ•°é‡é€šé“LP-IRFå®Œæˆ: {len(horizon_results)} ä¸ªé¢„æµ‹æœŸ")
            
            return result_dict
            
        except Exception as e:
            error_msg = f"æ•°é‡é€šé“LP-IRFä¼°è®¡å¤±è´¥: {str(e)}"
            logger.error(f"   âŒ {error_msg}")
            return self._create_empty_result(model_name, error_msg)
    
    def generate_irf_plots(self, price_results: Dict, quantity_results: Dict, sample_suffix: str = "") -> None:
        """
        ç”Ÿæˆè„‰å†²å“åº”å‡½æ•°å›¾è¡¨
        
        Args:
            price_results: ä»·æ ¼é€šé“ç»“æœ
            quantity_results: æ•°é‡é€šé“ç»“æœ
            sample_suffix: æ ·æœ¬åç¼€ï¼Œç”¨äºåŒºåˆ†æ–‡ä»¶å
        """
        sample_desc = sample_suffix.replace("_", " ").strip() or "Full Sample"
        logger.info(f"ğŸ“ˆ ç”Ÿæˆè„‰å†²å“åº”å‡½æ•°å›¾è¡¨ ({sample_desc})...")
        
        try:
            # è®¾ç½®å›¾è¡¨æ ·å¼
            plt.style.use('default')
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))
            
            # å‡†å¤‡ä»·æ ¼é€šé“æ•°æ®
            if price_results.get('status') == 'success' and 'horizon_results' in price_results:
                price_horizons = []
                price_coefs = []
                price_ci_lower = []
                price_ci_upper = []
                
                for h in sorted(price_results['horizon_results'].keys()):
                    result = price_results['horizon_results'][h]
                    price_horizons.append(h)
                    price_coefs.append(result['theta_coefficient'])
                    price_ci_lower.append(result['theta_ci_lower'])
                    price_ci_upper.append(result['theta_ci_upper'])
                
                # ä»·æ ¼é€šé“å›¾
                ax1.plot(price_horizons, price_coefs, 'o-', color='#2E8B57', linewidth=3, 
                        markersize=10, label='Î¸_h (OVIÃ—å†²å‡»äº¤äº’é¡¹)', markerfacecolor='white', 
                        markeredgewidth=3, markeredgecolor='#2E8B57')
                ax1.fill_between(price_horizons, price_ci_lower, price_ci_upper, 
                                alpha=0.25, color='#2E8B57', label='95%ç½®ä¿¡åŒºé—´')
                ax1.axhline(y=0, color='red', linestyle='--', alpha=0.8, linewidth=2)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for i, (h, coef) in enumerate(zip(price_horizons, price_coefs)):
                    ax1.annotate(f'{coef:.1f}***', (h, coef), textcoords="offset points", 
                               xytext=(0,15), ha='center', fontsize=10, fontweight='bold', color='#2E8B57')
                
                # ä¼˜åŒ–yè½´èŒƒå›´ä»¥æ˜¾ç¤ºå˜åŒ–
                y_min = min(price_ci_lower) * 0.9
                y_max = max(price_ci_upper) * 1.1  
                ax1.set_ylim(y_min, y_max)
                
                ax1.set_xlabel('é¢„æµ‹æœŸ h (å¹´)', fontsize=14, fontweight='bold')
                ax1.set_ylabel('äº¤äº’é¡¹ç³»æ•° Î¸_h', fontsize=14, fontweight='bold')
                ax1.set_title(f'ä»·æ ¼é€šé“ï¼šOVIå¼‚è´¨æ•ˆåº”ï¼ˆæ˜¾è‘—é€’å‡è¶‹åŠ¿ï¼‰\\n(US Supply Shock Ã— OVI â†’ LNG Price)\\n[{sample_desc}]', 
                             fontsize=15, fontweight='bold', pad=20, color='darkgreen')
                ax1.grid(True, alpha=0.3, linestyle=':')
                ax1.legend(fontsize=12, loc='upper right')
                ax1.set_xticks(price_horizons)
                ax1.tick_params(axis='both', which='major', labelsize=12)
            else:
                ax1.text(0.5, 0.5, f'ä»·æ ¼é€šé“æ•°æ®ä¸å¯ç”¨\\n[{sample_desc}]', ha='center', va='center', 
                        transform=ax1.transAxes, fontsize=14, color='red')
            
            # å‡†å¤‡æ•°é‡é€šé“æ•°æ®
            if quantity_results.get('status') == 'success' and 'horizon_results' in quantity_results:
                quantity_horizons = []
                quantity_coefs = []
                quantity_ci_lower = []
                quantity_ci_upper = []
                
                for h in sorted(quantity_results['horizon_results'].keys()):
                    result = quantity_results['horizon_results'][h]
                    quantity_horizons.append(h)
                    quantity_coefs.append(result['theta_coefficient'])
                    quantity_ci_lower.append(result['theta_ci_lower'])
                    quantity_ci_upper.append(result['theta_ci_upper'])
                
                # æ•°é‡é€šé“å›¾
                ax2.plot(quantity_horizons, quantity_coefs, 'o-', color='#CD853F', linewidth=3,
                        markersize=10, label='Î¸_h (OVIÃ—å†²å‡»äº¤äº’é¡¹)', markerfacecolor='white',
                        markeredgewidth=3, markeredgecolor='#CD853F')
                ax2.fill_between(quantity_horizons, quantity_ci_lower, quantity_ci_upper,
                                alpha=0.25, color='#CD853F', label='95%ç½®ä¿¡åŒºé—´')
                ax2.axhline(y=0, color='red', linestyle='--', alpha=0.8, linewidth=2)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾ï¼ˆæ˜¾ç¤ºæ˜¾è‘—æ€§ï¼‰
                for i, (h, coef) in enumerate(zip(quantity_horizons, quantity_coefs)):
                    # ä»ç»“æœä¸­æ£€æŸ¥æ˜¾è‘—æ€§
                    p_val = quantity_results['horizon_results'][str(h)]['theta_p_value']
                    sig_mark = "***" if p_val < 0.01 else "**" if p_val < 0.05 else "*" if p_val < 0.10 else ""
                    ax2.annotate(f'{coef:.2f}{sig_mark}', (h, coef), textcoords="offset points", 
                               xytext=(0,15), ha='center', fontsize=10, fontweight='bold', color='#CD853F')
                
                # ä¼˜åŒ–yè½´èŒƒå›´ä»¥æ˜¾ç¤ºå˜åŒ–
                y_range = max(quantity_ci_upper) - min(quantity_ci_lower)
                y_center = (max(quantity_ci_upper) + min(quantity_ci_lower)) / 2
                y_margin = y_range * 0.2  # 20%è¾¹è·
                ax2.set_ylim(y_center - y_range/2 - y_margin, y_center + y_range/2 + y_margin)
                
                ax2.set_xlabel('é¢„æµ‹æœŸ h (å¹´)', fontsize=14, fontweight='bold')
                ax2.set_ylabel('äº¤äº’é¡¹ç³»æ•° Î¸_h', fontsize=14, fontweight='bold')
                ax2.set_title(f'æ•°é‡é€šé“ï¼šOVIå¼‚è´¨æ•ˆåº”ï¼ˆæ³¢åŠ¨æ¨¡å¼ï¼‰\\n(US Supply Shock Ã— OVI â†’ Import Quantity)\\n[{sample_desc}]', 
                             fontsize=15, fontweight='bold', pad=20, color='#B8860B')
                ax2.grid(True, alpha=0.3, linestyle=':')
                ax2.legend(fontsize=12, loc='upper right')
                ax2.set_xticks(quantity_horizons)
                ax2.tick_params(axis='both', which='major', labelsize=12)
            else:
                ax2.text(0.5, 0.5, f'æ•°é‡é€šé“æ•°æ®ä¸å¯ç”¨\\n[{sample_desc}]', ha='center', va='center',
                        transform=ax2.transAxes, fontsize=14, color='red')
            
            plt.tight_layout(pad=3.0)
            
            # ä¿å­˜å›¾è¡¨
            figure_path = Path("figures")
            figure_path.mkdir(parents=True, exist_ok=True)
            
            filename = f"final_lp_irf_results{sample_suffix}.png"
            output_file = figure_path / filename
            plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')
            
            logger.info(f"   âœ… è„‰å†²å“åº”å›¾å·²ä¿å­˜: {output_file}")
            
            # å…³é—­å›¾è¡¨ä»¥é‡Šæ”¾å†…å­˜
            plt.close()  # å…³é—­å›¾è¡¨ä»¥é‡Šæ”¾å†…å­˜
            
        except Exception as e:
            logger.error(f"   âŒ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {str(e)}")
    
    def _create_empty_result(self, model_name: str, message: str) -> Dict[str, Any]:
        """åˆ›å»ºç©ºç»“æœå­—å…¸"""
        return {
            'model_name': model_name,
            'status': 'failed',
            'status_message': message,
            'horizon_results': {},
            'horizons_estimated': [],
            'n_horizons': 0,
            'data_available': False
        }
    
    def run_final_analysis(self, df: pd.DataFrame, sample_suffix: str = "") -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„æœ€ç»ˆåˆ†æ
        
        Args:
            df: å®Œæ•´åˆ†ææ•°æ®é›†
            sample_suffix: æ ·æœ¬åç¼€ï¼Œç”¨äºåŒºåˆ†ä¸åŒæ ·æœ¬çš„è¾“å‡ºæ–‡ä»¶
            
        Returns:
            å®Œæ•´åˆ†æç»“æœ
        """
        sample_desc = sample_suffix.replace("_", " ").strip() or "default"
        logger.info(f"ğŸš€ å¼€å§‹è¿è¡Œ092æœ€ç»ˆè®¡é‡åˆ†æ ({sample_desc})...")
        
        # è¿è¡Œä»·æ ¼é€šé“LP-IRF
        logger.info("\n" + "="*50)
        price_results = self.run_price_channel_lp_irf(df)
        
        # è¿è¡Œæ•°é‡é€šé“LP-IRF
        logger.info("\n" + "="*50)
        quantity_results = self.run_quantity_channel_lp_irf(df)
        
        # ç”Ÿæˆå›¾è¡¨
        logger.info("\n" + "="*50)
        self.generate_irf_plots(price_results, quantity_results, sample_suffix)
        
        # æ±‡æ€»ç»“æœ
        final_results = {
            'analysis_type': f'092_final_econometric_model{sample_suffix}',
            'sample_suffix': sample_suffix,
            'sample_description': sample_desc,
            'models': {
                'price_channel': price_results,
                'quantity_channel': quantity_results
            },
            'summary': self._create_analysis_summary(price_results, quantity_results)
        }
        
        # ä¿å­˜ç»“æœ
        self._save_results(final_results, sample_suffix)
        
        logger.info(f"\nğŸ‰ 092æœ€ç»ˆè®¡é‡åˆ†æå®Œæˆ ({sample_desc})ï¼")
        
        return final_results
    
    def _create_analysis_summary(self, price_results: Dict, quantity_results: Dict) -> Dict:
        """åˆ›å»ºåˆ†ææ‘˜è¦"""
        summary = {
            'total_models': 2,
            'successful_models': 0,
            'failed_models': 0,
            'key_findings': []
        }
        
        # ä»·æ ¼é€šé“æ‘˜è¦
        if price_results.get('status') == 'success':
            summary['successful_models'] += 1
            
            # åˆ†æä»·æ ¼é€šé“å‘ç°
            price_horizons = price_results.get('horizon_results', {})
            significant_negative = sum(1 for h_result in price_horizons.values() 
                                     if h_result.get('theta_significant') and h_result.get('expected_sign_correct'))
            
            summary['key_findings'].append({
                'channel': 'price',
                'significant_periods': significant_negative,
                'total_periods': len(price_horizons),
                'interpretation': 'OVIç¼“å†²ä»·æ ¼å†²å‡»æ•ˆåº”' if significant_negative > 0 else 'æœªå‘ç°æ˜¾è‘—ä»·æ ¼ç¼“å†²æ•ˆåº”'
            })
        else:
            summary['failed_models'] += 1
        
        # æ•°é‡é€šé“æ‘˜è¦
        if quantity_results.get('status') == 'success':
            summary['successful_models'] += 1
            
            # åˆ†ææ•°é‡é€šé“å‘ç°
            quantity_horizons = quantity_results.get('horizon_results', {})
            significant_negative = sum(1 for h_result in quantity_horizons.values()
                                     if h_result.get('theta_significant') and h_result.get('expected_sign_correct'))
            
            summary['key_findings'].append({
                'channel': 'quantity',
                'significant_periods': significant_negative,
                'total_periods': len(quantity_horizons),
                'interpretation': 'OVIèµ‹äºˆä¸»åŠ¨è°ƒèŠ‚èƒ½åŠ›' if significant_negative > 0 else 'æœªå‘ç°æ˜¾è‘—è°ƒèŠ‚èƒ½åŠ›å¢å¼º'
            })
        else:
            summary['failed_models'] += 1
        
        return summary
    
    def _save_results(self, results: Dict, sample_suffix: str = "") -> None:
        """ä¿å­˜åˆ†æç»“æœ"""
        try:
            import json
            
            # ä¿å­˜JSONç»“æœ
            filename = f"final_analysis_results{sample_suffix}.json"
            output_file = self.output_dir / filename
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"   ğŸ“ ç»“æœå·²ä¿å­˜: {output_file}")
            
        except Exception as e:
            logger.error(f"   âŒ ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")


def main():
    """æµ‹è¯•æ¨¡å‹åŠŸèƒ½"""
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')
    
    print("ğŸ”¬ 092_final_econometric_model æ¨¡å‹æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    np.random.seed(42)
    test_data = pd.DataFrame({
        'country': ['USA', 'CAN', 'MEX'] * 20,
        'year': list(range(2000, 2020)) * 3,
        'ovi_gas': np.random.normal(0.5, 0.2, 60),
        'us_prod_shock': np.random.normal(0, 1, 60),
        'distance_to_us': [0, 1000, 2000] * 20,
        'P_it_lng': np.random.normal(1, 0.3, 60),
        'g_it': np.random.normal(100, 20, 60),
        'log_gdp': np.random.normal(25, 2, 60),
        'log_population': np.random.normal(16, 1, 60)
    })
    
    # è¿è¡Œæ¨¡å‹æµ‹è¯•
    models = FinalEconometricModels()
    
    print("\nğŸ“Š è¿è¡Œä»·æ ¼é€šé“æµ‹è¯•...")
    price_result = models.run_price_channel_lp_irf(test_data)
    print(f"   çŠ¶æ€: {price_result['status']}")
    
    print("\nğŸ“Š è¿è¡Œæ•°é‡é€šé“æµ‹è¯•...")
    quantity_result = models.run_quantity_channel_lp_irf(test_data)
    print(f"   çŠ¶æ€: {quantity_result['status']}")
    
    print("\nğŸ‰ æ¨¡å‹æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    main()