#!/usr/bin/env python3
"""
é…ç½®æ–‡ä»¶ (Configuration File)
=============================

09_econometric_analysis æ¨¡å—çš„é…ç½®å‚æ•°

ä½œè€…ï¼šEnergy Network Analysis Team
ç‰ˆæœ¬ï¼šv1.0 - è®¡é‡åˆ†ææ¡†æ¶
"""

import os
from pathlib import Path
from typing import Dict, List, Any, Tuple

# åŸºç¡€è·¯å¾„é…ç½®
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent
DATA_DIR = PROJECT_ROOT / "data"
SRC_DIR = PROJECT_ROOT / "src"

# æ¨¡å—ç‰¹å®šè·¯å¾„
MODULE_DIR = Path(__file__).parent
OUTPUT_DIR = MODULE_DIR / "outputs"
FIGURES_DIR = MODULE_DIR / "figures"

# ç¡®ä¿ç›®å½•å­˜åœ¨
OUTPUT_DIR.mkdir(exist_ok=True)
FIGURES_DIR.mkdir(exist_ok=True)

# è®¡é‡æ¨¡å‹é…ç½®
class ModelConfig:
    """è®¡é‡æ¨¡å‹ç›¸å…³é…ç½®"""
    
    # æ ¸å¿ƒç ”ç©¶å˜é‡å®šä¹‰
    DEPENDENT_VARIABLES = {
        'vul_us': 'ç¾å›½é”šå®šè„†å¼±æ€§æŒ‡æ•°',
        'node_dli_us': 'Node-DLIç¾å›½æŒ‡æ•°',
        'delta_vul_us': 'è„†å¼±æ€§æŒ‡æ•°å˜åŒ–ç‡',
        'delta_node_dli_us': 'Node-DLIå˜åŒ–ç‡'
    }
    
    # å…³é”®è§£é‡Šå˜é‡
    KEY_EXPLANATORY_VARIABLES = {
        'node_dli_us': 'Node-DLIç¾å›½æŒ‡æ•°',
        'ovi': 'ç‰©ç†å†—ä½™æŒ‡æ•°OVI',
        'us_prod_shock': 'ç¾å›½äº§é‡å†²å‡»',
        'ovi_lag1': 'OVIæ»å1æœŸ',
        'us_prod_shock_lag1': 'ç¾å›½äº§é‡å†²å‡»æ»å1æœŸ'
    }
    
    # æ§åˆ¶å˜é‡ç»„
    CONTROL_VARIABLES = {
        'macro_controls': [
            'log_gdp',                    # GDPå¯¹æ•°
            'log_population',             # äººå£å¯¹æ•°  
            'trade_openness_gdp_pct'      # è´¸æ˜“å¼€æ”¾åº¦
        ],
        'network_controls': [
            'betweenness_centrality',     # ä»‹æ•°ä¸­å¿ƒæ€§
            'eigenvector_centrality',     # ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§
            'in_degree',                  # å…¥åº¦
            'out_degree'                  # å‡ºåº¦
        ],
        'energy_controls': [
            'lng_capacity',               # LNGå®¹é‡
            'pipeline_capacity',          # ç®¡é“å®¹é‡
            'energy_demand'               # èƒ½æºéœ€æ±‚
        ]
    }
    
    # é¢æ¿æ•°æ®è®¾å®š
    PANEL_SETTINGS = {
        'time_var': 'year',              # æ—¶é—´å˜é‡
        'entity_var': 'country',         # ä¸ªä½“å˜é‡
        'min_time_periods': 5,           # æœ€å°‘æ—¶é—´æœŸæ•°
        'min_entities': 10,              # æœ€å°‘ä¸ªä½“æ•°
        'balanced_panel': False          # æ˜¯å¦è¦æ±‚å¹³è¡¡é¢æ¿
    }
    
    # å›ºå®šæ•ˆåº”è®¾å®š
    FIXED_EFFECTS = {
        'time_effects': True,            # æ—¶é—´å›ºå®šæ•ˆåº”
        'entity_effects': True,          # ä¸ªä½“å›ºå®šæ•ˆåº”
        'two_way_effects': True          # åŒå‘å›ºå®šæ•ˆåº”
    }
    
    # æ¨¡å‹ä¼°è®¡è®¾å®š
    ESTIMATION_SETTINGS = {
        'robust': True,                  # ç¨³å¥æ ‡å‡†è¯¯
        'cluster_var': 'country',        # èšç±»å˜é‡
        'bootstrap_reps': 1000,          # Bootstrapé‡å¤æ¬¡æ•°
        'confidence_level': 0.95         # ç½®ä¿¡æ°´å¹³
    }

class AnalysisConfig:
    """åˆ†æè®¾å®šé…ç½®"""
    
    # ç ”ç©¶æ¨¡å‹å®šä¹‰
    RESEARCH_MODELS = {
        'model_1_dli_vul_association': {
            'name': 'æ¨¡å‹1: DLI-è„†å¼±æ€§å…³è”æ£€éªŒ',
            'description': 'åŒå‘å›ºå®šæ•ˆåº”é¢æ¿æ¨¡å‹æ£€éªŒNode-DLIä¸è„†å¼±æ€§çš„å…³è”',
            'formula': 'vul_us ~ node_dli_us + macro_controls + C(year) + C(country)',
            'method': 'fixed_effects',
            'chapter': 'ç¬¬3ç« ',
            'priority': 1
        },
        'model_2_ovi_dli_causality': {
            'name': 'æ¨¡å‹2: OVIå¯¹DLIçš„å› æœæ•ˆåº”',
            'description': 'åŒå‘å›ºå®šæ•ˆåº”é¢æ¿æ¨¡å‹æ£€éªŒOVIå¯¹Node-DLIçš„å› æœæ•ˆåº”',
            'formula': 'node_dli_us ~ ovi_lag1 + macro_controls + C(year) + C(country)',
            'method': 'fixed_effects',
            'chapter': 'è¡¥å……åˆ†æ',
            'priority': 2
        },
        'model_3_local_projection_validation': {
            'name': 'æ¨¡å‹3: å±€éƒ¨æŠ•å½±å› æœéªŒè¯', 
            'description': 'å±€éƒ¨æŠ•å½±æ¨¡å‹éªŒè¯ç¾å›½äº§é‡å†²å‡»çš„åŠ¨æ€æ•ˆåº”',
            'formula': 'delta_y_h ~ us_prod_shock * ovi_lag1 + macro_controls + C(year)',
            'method': 'local_projections',
            'chapter': 'ç¬¬4ç« ',
            'priority': 3,
            'horizons': [0, 1, 2, 3, 4, 5]  # é¢„æµ‹æœŸæ•°
        }
    }
    
    # ç¨³å¥æ€§æ£€éªŒè®¾å®š
    ROBUSTNESS_CHECKS = {
        'alternative_specifications': [
            'exclude_outliers',           # æ’é™¤å¼‚å¸¸å€¼
            'winsorize_variables',        # å˜é‡ç¼©å°¾å¤„ç†
            'alternative_controls',       # æ›¿ä»£æ§åˆ¶å˜é‡
            'subperiod_analysis'          # åˆ†æ—¶æœŸåˆ†æ
        ],
        'sensitivity_analysis': [
            'bootstrap_inference',        # Bootstrapæ¨æ–­
            'jackknife_validation',       # JackknifeéªŒè¯
            'alternative_clustering'      # æ›¿ä»£èšç±»æ–¹æ³•
        ]
    }

class OutputConfig:
    """è¾“å‡ºé…ç½®"""
    
    # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    OUTPUT_PATHS = {
        'regression_results': OUTPUT_DIR / 'regression_results.csv',
        'analysis_report': OUTPUT_DIR / 'analysis_report.md', 
        'model_diagnostics': OUTPUT_DIR / 'model_diagnostics.json',
        'robustness_results': OUTPUT_DIR / 'robustness_results.csv'
    }
    
    # å›¾è¡¨è¾“å‡ºè·¯å¾„  
    FIGURE_PATHS = {
        'coefficient_comparison': FIGURES_DIR / 'coefficient_comparison.png',
        'diagnostic_plots': FIGURES_DIR / 'diagnostic_plots.png',
        'impulse_response': FIGURES_DIR / 'impulse_response.png',
        'robustness_charts': FIGURES_DIR / 'robustness_charts.png'
    }
    
    # æŠ¥å‘Šæ ¼å¼è®¾å®š
    REPORT_SETTINGS = {
        'include_diagnostics': True,     # åŒ…å«è¯Šæ–­ç»Ÿè®¡
        'include_robustness': True,      # åŒ…å«ç¨³å¥æ€§æ£€éªŒ
        'significance_levels': [0.01, 0.05, 0.10],  # æ˜¾è‘—æ€§æ°´å¹³
        'decimal_places': 4,             # å°æ•°ä½æ•°
        'table_format': 'markdown',      # è¡¨æ ¼æ ¼å¼
        'export_latex': True             # å¯¼å‡ºLaTeXæ ¼å¼
    }

class ValidationConfig:
    """æ•°æ®éªŒè¯é…ç½®"""
    
    # æ•°æ®è´¨é‡è¦æ±‚
    DATA_QUALITY_THRESHOLDS = {
        'min_observations': 50,          # æœ€å°‘è§‚æµ‹æ•°
        'max_missing_rate': 0.5,         # æœ€å¤§ç¼ºå¤±ç‡
        'min_variation': 0.01,           # æœ€å°å˜å¼‚ç³»æ•°
        'outlier_threshold': 3.0         # å¼‚å¸¸å€¼é˜ˆå€¼(Z-score)
    }
    
    # æ¨¡å‹è¯Šæ–­è¦æ±‚
    MODEL_DIAGNOSTICS = {
        'check_multicollinearity': True,  # æ£€æŸ¥å¤šé‡å…±çº¿æ€§
        'vif_threshold': 10.0,            # VIFé˜ˆå€¼
        'check_autocorrelation': True,    # æ£€æŸ¥è‡ªç›¸å…³
        'check_heteroskedasticity': True, # æ£€æŸ¥å¼‚æ–¹å·®
        'normality_test': False           # æ­£æ€æ€§æ£€éªŒ(å¯é€‰)
    }

class ComputationConfig:
    """è®¡ç®—é…ç½®"""
    
    # å¹¶è¡Œè®¡ç®—è®¾å®š
    PARALLEL_SETTINGS = {
        'use_multiprocessing': False,    # æš‚æ—¶å…³é—­å¹¶è¡Œ
        'n_workers': 4,                  # å·¥ä½œè¿›ç¨‹æ•°
        'memory_limit': '4GB'            # å†…å­˜é™åˆ¶
    }
    
    # æ•°å€¼è®¡ç®—ç²¾åº¦
    NUMERICAL_SETTINGS = {
        'float_precision': 'float64',    # æµ®ç‚¹ç²¾åº¦
        'convergence_tolerance': 1e-8,   # æ”¶æ•›å®¹å·®
        'max_iterations': 1000           # æœ€å¤§è¿­ä»£æ¬¡æ•°
    }

class LoggingConfig:
    """æ—¥å¿—é…ç½®"""
    
    LOG_LEVEL = 'INFO'
    LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    LOG_FILE = MODULE_DIR / 'econometric_analysis.log'
    
    # æ§åˆ¶å°è¾“å‡º
    CONSOLE_OUTPUT = True
    CONSOLE_LEVEL = 'INFO'
    
    # æ–‡ä»¶è¾“å‡º  
    FILE_OUTPUT = True
    FILE_LEVEL = 'DEBUG'

# é›†æˆé…ç½®ç±»
class Config:
    """ä¸»é…ç½®ç±»ï¼Œæ•´åˆæ‰€æœ‰é…ç½®"""
    
    models = ModelConfig()
    analysis = AnalysisConfig() 
    output = OutputConfig()
    validation = ValidationConfig()
    computation = ComputationConfig()
    logging = LoggingConfig()
    
    @classmethod
    def get_model_formula(cls, model_name: str) -> str:
        """è·å–æ¨¡å‹å…¬å¼"""
        return cls.analysis.RESEARCH_MODELS.get(model_name, {}).get('formula', '')
    
    @classmethod
    def get_control_variables(cls, control_type: str = 'all') -> List[str]:
        """è·å–æ§åˆ¶å˜é‡åˆ—è¡¨"""
        if control_type == 'all':
            all_controls = []
            for controls in cls.models.CONTROL_VARIABLES.values():
                all_controls.extend(controls)
            return all_controls
        else:
            return cls.models.CONTROL_VARIABLES.get(control_type, [])
    
    @classmethod
    def validate_data_requirements(cls, df) -> Dict[str, bool]:
        """éªŒè¯æ•°æ®æ˜¯å¦æ»¡è¶³åˆ†æè¦æ±‚"""
        if df is None or len(df) == 0:
            return {'sufficient_data': False, 'reason': 'empty_dataframe'}
        
        # æ£€æŸ¥æœ€å°‘è§‚æµ‹æ•°
        if len(df) < cls.validation.DATA_QUALITY_THRESHOLDS['min_observations']:
            return {'sufficient_data': False, 'reason': 'insufficient_observations'}
        
        # æ£€æŸ¥é¢æ¿ç»“æ„
        if cls.models.PANEL_SETTINGS['time_var'] not in df.columns:
            return {'sufficient_data': False, 'reason': 'missing_time_variable'}
        
        if cls.models.PANEL_SETTINGS['entity_var'] not in df.columns:
            return {'sufficient_data': False, 'reason': 'missing_entity_variable'}
        
        # æ£€æŸ¥å…³é”®å˜é‡
        key_vars = list(cls.models.DEPENDENT_VARIABLES.keys()) + list(cls.models.KEY_EXPLANATORY_VARIABLES.keys())
        missing_vars = [var for var in key_vars if var not in df.columns or df[var].isna().all()]
        
        if missing_vars:
            return {'sufficient_data': False, 'reason': f'missing_key_variables: {missing_vars}'}
        
        return {'sufficient_data': True, 'reason': 'data_ready'}
    
    @classmethod
    def to_dict(cls) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'models': cls.models.__dict__,
            'analysis': cls.analysis.__dict__,
            'output': cls.output.__dict__,
            'validation': cls.validation.__dict__,
            'computation': cls.computation.__dict__,
            'logging': cls.logging.__dict__
        }

# å¯¼å‡ºä¸»è¦é…ç½®
config = Config()

# ä¾¿æ·å‡½æ•°
def get_config() -> Config:
    """è·å–é…ç½®å®ä¾‹"""
    return config

def print_config_summary():
    """æ‰“å°é…ç½®æ‘˜è¦"""
    print("ğŸ“Š 09_econometric_analysis é…ç½®æ‘˜è¦")
    print("=" * 50)
    print(f"ç ”ç©¶æ¨¡å‹æ•°é‡: {len(config.analysis.RESEARCH_MODELS)}")
    print(f"å› å˜é‡æ•°é‡: {len(config.models.DEPENDENT_VARIABLES)}")
    print(f"è§£é‡Šå˜é‡æ•°é‡: {len(config.models.KEY_EXPLANATORY_VARIABLES)}")
    print(f"æ§åˆ¶å˜é‡æ•°é‡: {len(config.get_control_variables())}")
    print(f"è¾“å‡ºç›®å½•: {config.output.OUTPUT_PATHS['regression_results'].parent}")
    print(f"å›¾è¡¨ç›®å½•: {config.output.FIGURE_PATHS['coefficient_comparison'].parent}")
    
    print("\nğŸ“ˆ ç ”ç©¶æ¨¡å‹:")
    for model_id, model_info in config.analysis.RESEARCH_MODELS.items():
        print(f"  â€¢ {model_info['name']} ({model_info['chapter']})")
    
    print(f"\nâš™ï¸ åˆ†æè®¾å®š:")
    print(f"  æœ€å°‘è§‚æµ‹æ•°: {config.validation.DATA_QUALITY_THRESHOLDS['min_observations']}")
    print(f"  ç½®ä¿¡æ°´å¹³: {config.models.ESTIMATION_SETTINGS['confidence_level']}")
    print(f"  ç¨³å¥æ ‡å‡†è¯¯: {config.models.ESTIMATION_SETTINGS['robust']}")
    print(f"  èšç±»å˜é‡: {config.models.ESTIMATION_SETTINGS['cluster_var']}")

if __name__ == "__main__":
    print_config_summary()