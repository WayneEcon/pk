#!/usr/bin/env python3
"""
ä¸»ç¨‹åºå…¥å£ (Main Entry Point)
============================

09_econometric_analysis æ¨¡å—çš„å®Œæ•´åˆ†ææµæ°´çº¿

ä½œè€…ï¼šEnergy Network Analysis Team
ç‰ˆæœ¬ï¼šv1.0 - è®¡é‡åˆ†ææ¡†æ¶
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any
import logging
from pathlib import Path
import sys
import time
from datetime import datetime

# å¯¼å…¥æœ¬æ¨¡å—ç»„ä»¶
from .config import config, print_config_summary
from .data_loader import DataLoader, get_data_status
from .models import EconometricModels
from .reporting import ReportGenerator
from .visualization import VisualizationEngine

logger = logging.getLogger(__name__)

class EconometricAnalysisPipeline:
    """
    è®¡é‡ç»æµå­¦åˆ†ææµæ°´çº¿ - å®Œæ•´çš„ç«¯åˆ°ç«¯åˆ†ææ¡†æ¶
    """
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†ææµæ°´çº¿"""
        self.config = config
        self.start_time = time.time()
        
        # åˆå§‹åŒ–å„ç»„ä»¶
        self.data_loader = DataLoader()
        self.models = EconometricModels()
        self.reporter = ReportGenerator()
        self.visualizer = VisualizationEngine()
        
        # å­˜å‚¨ç»“æœ
        self.data = None
        self.data_summary = None
        self.model_results = None
        
        logger.info("ğŸš€ è®¡é‡ç»æµå­¦åˆ†ææµæ°´çº¿åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   æ¨¡å—ç‰ˆæœ¬: 09_econometric_analysis v1.0")
        logger.info(f"   å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    def run_full_pipeline(self) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„åˆ†ææµæ°´çº¿
        
        Returns:
            åˆ†æç»“æœæ±‡æ€»å­—å…¸
        """
        logger.info("ğŸ”¬ å¼€å§‹è¿è¡Œå®Œæ•´è®¡é‡åˆ†ææµæ°´çº¿...")
        logger.info("=" * 60)
        
        pipeline_results = {
            'status': 'running',
            'start_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'steps_completed': 0,
            'steps_total': 5,
            'data_loaded': False,
            'models_run': False,
            'reports_generated': False,
            'visualizations_created': False,
            'pipeline_success': False
        }
        
        try:
            # æ­¥éª¤1: æ•°æ®åŠ è½½ä¸éªŒè¯
            logger.info("æ­¥éª¤1/5: æ•°æ®åŠ è½½ä¸éªŒè¯")
            logger.info("=" * 30)
            success = self._step_data_loading()
            pipeline_results['steps_completed'] = 1
            pipeline_results['data_loaded'] = success
            
            if not success:
                logger.warning("âš ï¸ æ•°æ®åŠ è½½å¤±è´¥ï¼Œä½†ç»§ç»­è¿è¡Œä»¥æ¼”ç¤ºç©ºæ•°æ®å¤„ç†èƒ½åŠ›")
            
            # æ­¥éª¤2: è¿è¡Œè®¡é‡æ¨¡å‹
            logger.info("\næ­¥éª¤2/5: è¿è¡Œè®¡é‡æ¨¡å‹")
            logger.info("=" * 30)
            success = self._step_model_estimation()
            pipeline_results['steps_completed'] = 2
            pipeline_results['models_run'] = success
            
            # æ­¥éª¤3: ç”Ÿæˆåˆ†ææŠ¥å‘Š
            logger.info("\næ­¥éª¤3/5: ç”Ÿæˆåˆ†ææŠ¥å‘Š")
            logger.info("=" * 30)
            success = self._step_report_generation()
            pipeline_results['steps_completed'] = 3
            pipeline_results['reports_generated'] = success
            
            # æ­¥éª¤4: åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
            logger.info("\næ­¥éª¤4/5: åˆ›å»ºå¯è§†åŒ–å›¾è¡¨")
            logger.info("=" * 30)
            success = self._step_visualization_creation()
            pipeline_results['steps_completed'] = 4
            pipeline_results['visualizations_created'] = success
            
            # æ­¥éª¤5: æµæ°´çº¿æ€»ç»“
            logger.info("\næ­¥éª¤5/5: æµæ°´çº¿æ€»ç»“")
            logger.info("=" * 30)
            pipeline_results.update(self._step_pipeline_summary())
            pipeline_results['steps_completed'] = 5
            pipeline_results['pipeline_success'] = True
            
            logger.info("âœ… è®¡é‡åˆ†ææµæ°´çº¿è¿è¡Œå®Œæˆ!")
            
        except Exception as e:
            logger.error(f"âŒ æµæ°´çº¿è¿è¡Œå¼‚å¸¸: {str(e)}")
            pipeline_results['status'] = 'failed'
            pipeline_results['error_message'] = str(e)
            pipeline_results['pipeline_success'] = False
        
        finally:
            # è®¡ç®—æ€»è€—æ—¶
            total_time = time.time() - self.start_time
            pipeline_results['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            pipeline_results['total_duration_seconds'] = total_time
            pipeline_results['status'] = 'completed' if pipeline_results.get('pipeline_success') else 'failed'
        
        return pipeline_results
    
    def _step_data_loading(self) -> bool:
        """æ­¥éª¤1: æ•°æ®åŠ è½½ä¸éªŒè¯"""
        try:
            logger.info("ğŸ“Š åŠ è½½åˆ†ææ•°æ®...")
            
            # åŠ è½½æ•°æ®
            self.data = self.data_loader.load_analytical_panel()
            
            # è·å–æ•°æ®æ‘˜è¦
            self.data_summary = get_data_status()
            
            # æ‰“å°æ•°æ®æ¦‚å†µ
            summary = self.data_summary.get('summary', {})
            validation = self.data_summary.get('validation', {})
            
            logger.info(f"   æ•°æ®å½¢çŠ¶: {summary.get('total_rows', 0)} è¡Œ Ã— {summary.get('total_cols', 0)} åˆ—")
            logger.info(f"   å¹´ä»½èŒƒå›´: {summary.get('year_range', 'N/A')}")
            logger.info(f"   å›½å®¶æ•°é‡: {summary.get('countries', 0)}")
            logger.info(f"   æ•°æ®çŠ¶æ€: {summary.get('data_status', 'unknown')}")
            
            # å…³é”®å˜é‡å¯ç”¨æ€§
            key_vars = summary.get('key_variables_available', [])
            if key_vars:
                logger.info("   å¯ç”¨å…³é”®å˜é‡:")
                for var in key_vars:
                    logger.info(f"     â€¢ {var}")
            else:
                logger.warning("   âš ï¸ å…³é”®å˜é‡å‡ä¸å¯ç”¨")
            
            # æ•°æ®éªŒè¯ç»“æœ
            if validation.get('is_valid_for_analysis'):
                logger.info("   âœ… æ•°æ®é€‚åˆè®¡é‡åˆ†æ")
                return True
            else:
                logger.warning("   âŒ æ•°æ®ä¸é€‚åˆè®¡é‡åˆ†æ")
                issues = validation.get('issues', [])
                for issue in issues:
                    logger.warning(f"     â€¢ {issue}")
                logger.info("   å°†ç»§ç»­è¿è¡Œä»¥æ¼”ç¤ºç©ºæ•°æ®å¤„ç†æ¡†æ¶")
                return False
            
        except Exception as e:
            logger.error(f"æ•°æ®åŠ è½½æ­¥éª¤å¤±è´¥: {str(e)}")
            return False
    
    def _step_model_estimation(self) -> bool:
        """æ­¥éª¤2: è¿è¡Œè®¡é‡æ¨¡å‹"""
        try:
            logger.info("ğŸ” å¼€å§‹è¿è¡Œè®¡é‡æ¨¡å‹...")
            
            # è¿è¡Œæ‰€æœ‰æ¨¡å‹
            self.model_results = self.models.run_all_models(self.data)
            
            # æ‰“å°æ¨¡å‹è¿è¡Œç»“æœ
            overview = self.model_results.get('overview', {})
            total_models = overview.get('total_models', 0)
            completed_models = overview.get('completed_models', 0)
            failed_models = overview.get('failed_models', 0)
            
            logger.info(f"   æ€»æ¨¡å‹æ•°: {total_models}")
            logger.info(f"   æˆåŠŸä¼°è®¡: {completed_models}")
            logger.info(f"   ä¼°è®¡å¤±è´¥: {failed_models}")
            
            # è¯¦ç»†æ¨¡å‹çŠ¶æ€
            models_dict = self.model_results.get('models', {})
            for model_name, result in models_dict.items():
                model_config = self.config.analysis.RESEARCH_MODELS.get(model_name, {})
                status_icon = "âœ…" if result.get('status') == 'success' else "âŒ"
                logger.info(f"   {status_icon} {model_config.get('name', model_name)}: {result.get('status_message', 'N/A')}")
                
                if result.get('status') == 'success':
                    n_obs = result.get('n_obs', 0)
                    r_squared = result.get('r_squared', np.nan)
                    r2_str = f"{r_squared:.4f}" if not np.isnan(r_squared) else "N/A"
                    logger.info(f"       è§‚æµ‹æ•°: {n_obs}, RÂ²: {r2_str}")
            
            return completed_models > 0
            
        except Exception as e:
            logger.error(f"æ¨¡å‹ä¼°è®¡æ­¥éª¤å¤±è´¥: {str(e)}")
            return False
    
    def _step_report_generation(self) -> bool:
        """æ­¥éª¤3: ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        try:
            logger.info("ğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
            
            if self.model_results is None:
                logger.warning("   æ²¡æœ‰æ¨¡å‹ç»“æœï¼Œåˆ›å»ºç©ºæŠ¥å‘Šæ¡†æ¶")
                self.model_results = {'overview': {'total_models': 0, 'completed_models': 0, 'failed_models': 0}, 'models': {}}
            
            # ç”Ÿæˆæ‰€æœ‰æŠ¥å‘Š
            generated_reports = self.reporter.generate_all_reports(
                self.model_results, 
                self.data_summary
            )
            
            # æ‰“å°ç”Ÿæˆçš„æŠ¥å‘Š
            for report_type, file_path in generated_reports.items():
                logger.info(f"   âœ… {report_type}: {file_path}")
            
            return len(generated_reports) > 0
            
        except Exception as e:
            logger.error(f"æŠ¥å‘Šç”Ÿæˆæ­¥éª¤å¤±è´¥: {str(e)}")
            return False
    
    def _step_visualization_creation(self) -> bool:
        """æ­¥éª¤4: åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        try:
            logger.info("ğŸ¨ åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
            
            if self.model_results is None:
                logger.warning("   æ²¡æœ‰æ¨¡å‹ç»“æœï¼Œåˆ›å»ºå ä½ç¬¦å›¾è¡¨")
                self.model_results = {'overview': {'total_models': 0, 'completed_models': 0, 'failed_models': 0}, 'models': {}}
            
            # ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–
            generated_figures = self.visualizer.generate_all_visualizations(self.model_results)
            
            # æ‰“å°ç”Ÿæˆçš„å›¾è¡¨
            for figure_type, file_path in generated_figures.items():
                logger.info(f"   ğŸ¯ {figure_type}: {file_path}")
            
            return len(generated_figures) > 0
            
        except Exception as e:
            logger.error(f"å¯è§†åŒ–åˆ›å»ºæ­¥éª¤å¤±è´¥: {str(e)}")
            return False
    
    def _step_pipeline_summary(self) -> Dict[str, Any]:
        """æ­¥éª¤5: æµæ°´çº¿æ€»ç»“"""
        summary = {}
        
        try:
            logger.info("ğŸ“‹ ç”Ÿæˆæµæ°´çº¿æ‰§è¡Œæ‘˜è¦...")
            
            # æ•°æ®æ‘˜è¦
            if self.data_summary:
                data_summary = self.data_summary.get('summary', {})
                summary['data_summary'] = {
                    'total_observations': data_summary.get('total_rows', 0),
                    'total_variables': data_summary.get('total_cols', 0),
                    'year_range': data_summary.get('year_range', 'N/A'),
                    'countries_count': data_summary.get('countries', 0),
                    'data_quality': data_summary.get('data_status', 'unknown')
                }
            
            # æ¨¡å‹æ‘˜è¦
            if self.model_results:
                overview = self.model_results.get('overview', {})
                summary['model_summary'] = {
                    'total_models': overview.get('total_models', 0),
                    'successful_models': overview.get('completed_models', 0),
                    'failed_models': overview.get('failed_models', 0),
                    'success_rate': f"{overview.get('completed_models', 0) / max(overview.get('total_models', 1), 1) * 100:.1f}%"
                }
            
            # è¾“å‡ºæ–‡ä»¶ç»Ÿè®¡
            output_dir = self.config.output.OUTPUT_PATHS['regression_results'].parent
            figures_dir = self.config.output.FIGURE_PATHS['coefficient_comparison'].parent
            
            summary['output_summary'] = {
                'reports_directory': str(output_dir),
                'figures_directory': str(figures_dir),
                'total_output_files': len(list(output_dir.glob('*'))) + len(list(figures_dir.glob('*')))
            }
            
            # æ‰“å°å…³é”®ç»Ÿè®¡
            logger.info("ğŸ¯ å…³é”®ç»“æœæ‘˜è¦:")
            if self.data is not None:
                logger.info(f"   â€¢ æ•°æ®å¯ç”¨æ€§: {'æ˜¯' if len(self.data) > 0 else 'å¦'}")
            if self.model_results:
                logger.info(f"   â€¢ æ¨¡å‹æˆåŠŸç‡: {summary['model_summary']['success_rate']}")
            logger.info(f"   â€¢ è¾“å‡ºæ–‡ä»¶æ•°: {summary['output_summary']['total_output_files']}")
            
            # ä¸‹ä¸€æ­¥å»ºè®®
            self._print_next_steps_recommendations()
            
        except Exception as e:
            logger.error(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}")
            summary['error'] = str(e)
        
        return summary
    
    def _print_next_steps_recommendations(self):
        """æ‰“å°ä¸‹ä¸€æ­¥å»ºè®®"""
        logger.info("\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
        
        if self.data is None or len(self.data) == 0:
            logger.info("   1. æ£€æŸ¥08_variable_constructionæ¨¡å—æ˜¯å¦æˆåŠŸç”Ÿæˆanalytical_panel.csv")
            logger.info("   2. ç¡®è®¤æ ¸å¿ƒå˜é‡(Node-DLI, Vul_US, OVIç­‰)æ•°æ®å®Œæ•´æ€§")
            logger.info("   3. æ•°æ®å°±ä½åé‡æ–°è¿è¡Œæœ¬æ¨¡å—è·å–å®è´¨æ€§ç»“æœ")
        else:
            if self.model_results and self.model_results.get('overview', {}).get('completed_models', 0) == 0:
                logger.info("   1. æ£€æŸ¥æ•°æ®è´¨é‡ï¼Œç¡®ä¿æ»¡è¶³æœ€å°‘è§‚æµ‹æ•°è¦æ±‚")
                logger.info("   2. éªŒè¯å…³é”®å˜é‡æ˜¯å¦å­˜åœ¨å¼‚å¸¸å€¼æˆ–ç¼–ç é—®é¢˜")
                logger.info("   3. è€ƒè™‘è°ƒæ•´æ¨¡å‹è§„èŒƒä»¥é€‚åº”å½“å‰æ•°æ®ç‰¹å¾")
            else:
                logger.info("   1. æŸ¥çœ‹ç”Ÿæˆçš„åˆ†ææŠ¥å‘Šäº†è§£è¯¦ç»†ç»“æœ")
                logger.info("   2. å®æ–½ç¨³å¥æ€§æ£€éªŒéªŒè¯ç»“æœå¯é æ€§")
                logger.info("   3. åŸºäºç»“æœæ’°å†™å­¦æœ¯è®ºæ–‡æˆ–æ”¿ç­–æŠ¥å‘Š")
        
        logger.info("   4. å®‰è£…statsmodelså’Œlinearmodelsåº“ä»¥å¯ç”¨å®Œæ•´è®¡é‡åˆ†æåŠŸèƒ½")
        logger.info("   5. å®‰è£…matplotlibå’Œseabornåº“ä»¥ç”Ÿæˆä¸“ä¸šå›¾è¡¨")

    def run_quick_diagnostic(self) -> Dict[str, Any]:
        """
        è¿è¡Œå¿«é€Ÿè¯Šæ–­æ£€æŸ¥
        
        Returns:
            è¯Šæ–­ç»“æœå­—å…¸
        """
        logger.info("ğŸ”§ è¿è¡Œå¿«é€Ÿè¯Šæ–­æ£€æŸ¥...")
        
        diagnostic_results = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'module_status': 'operational',
            'dependencies': self._check_dependencies(),
            'data_availability': self._check_data_availability(),
            'configuration': self._check_configuration(),
            'recommendations': []
        }
        
        # åŸºäºæ£€æŸ¥ç»“æœç»™å‡ºå»ºè®®
        if not diagnostic_results['dependencies']['all_available']:
            diagnostic_results['recommendations'].append("å®‰è£…ç¼ºå¤±çš„Pythonä¾èµ–åº“")
        
        if not diagnostic_results['data_availability']['data_exists']:
            diagnostic_results['recommendations'].append("æ£€æŸ¥08æ¨¡å—çš„æ•°æ®ç”ŸæˆçŠ¶æ€")
        
        if not diagnostic_results['configuration']['paths_valid']:
            diagnostic_results['recommendations'].append("æ£€æŸ¥è¾“å‡ºç›®å½•æƒé™è®¾ç½®")
        
        logger.info(f"âœ… è¯Šæ–­å®Œæˆï¼Œå‘ç° {len(diagnostic_results['recommendations'])} ä¸ªå»ºè®®")
        
        return diagnostic_results
    
    def _check_dependencies(self) -> Dict[str, bool]:
        """æ£€æŸ¥ä¾èµ–åº“å¯ç”¨æ€§"""
        dependencies = {}
        
        try:
            import statsmodels
            dependencies['statsmodels'] = True
        except ImportError:
            dependencies['statsmodels'] = False
        
        try:
            from linearmodels import PanelOLS
            dependencies['linearmodels'] = True
        except ImportError:
            dependencies['linearmodels'] = False
        
        try:
            import matplotlib.pyplot as plt
            dependencies['matplotlib'] = True
        except ImportError:
            dependencies['matplotlib'] = False
        
        try:
            import seaborn as sns
            dependencies['seaborn'] = True
        except ImportError:
            dependencies['seaborn'] = False
        
        dependencies['all_available'] = all(dependencies.values())
        
        return dependencies
    
    def _check_data_availability(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®å¯ç”¨æ€§"""
        data_check = {}
        
        analytical_panel_path = self.data_loader.analytical_panel_path
        data_check['data_exists'] = analytical_panel_path.exists()
        data_check['data_path'] = str(analytical_panel_path)
        
        if data_check['data_exists']:
            try:
                df = pd.read_csv(analytical_panel_path)
                data_check['data_shape'] = df.shape
                data_check['data_empty'] = len(df) == 0
            except Exception as e:
                data_check['data_readable'] = False
                data_check['error'] = str(e)
        
        return data_check
    
    def _check_configuration(self) -> Dict[str, bool]:
        """æ£€æŸ¥é…ç½®æœ‰æ•ˆæ€§"""
        config_check = {}
        
        # æ£€æŸ¥è¾“å‡ºç›®å½•
        try:
            output_dir = self.config.output.OUTPUT_PATHS['regression_results'].parent
            figures_dir = self.config.output.FIGURE_PATHS['coefficient_comparison'].parent
            
            config_check['output_dir_exists'] = output_dir.exists()
            config_check['figures_dir_exists'] = figures_dir.exists()
            config_check['paths_valid'] = config_check['output_dir_exists'] and config_check['figures_dir_exists']
        except Exception as e:
            config_check['paths_valid'] = False
            config_check['error'] = str(e)
        
        return config_check


def main():
    """ä¸»å‡½æ•°å…¥å£"""
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler(config.logging.LOG_FILE, encoding='utf-8')
        ]
    )
    
    print("ğŸ”¬ 09_econometric_analysis - è®¡é‡ç»æµå­¦åˆ†ææ¡†æ¶")
    print("=" * 60)
    
    # æ‰“å°é…ç½®æ‘˜è¦
    print_config_summary()
    print()
    
    # åˆ›å»ºå¹¶è¿è¡Œåˆ†ææµæ°´çº¿
    pipeline = EconometricAnalysisPipeline()
    
    try:
        # å¯é€‰: è¿è¡Œå¿«é€Ÿè¯Šæ–­
        if '--diagnostic' in sys.argv:
            diagnostic_results = pipeline.run_quick_diagnostic()
            print(f"\nğŸ”§ è¯Šæ–­ç»“æœ: å‘ç° {len(diagnostic_results['recommendations'])} ä¸ªå»ºè®®")
            return
        
        # è¿è¡Œå®Œæ•´æµæ°´çº¿
        results = pipeline.run_full_pipeline()
        
        # æ‰“å°æœ€ç»ˆçŠ¶æ€
        print(f"\nğŸ¯ æµæ°´çº¿æ‰§è¡Œå®Œæˆ!")
        print(f"çŠ¶æ€: {results['status']}")
        print(f"è€—æ—¶: {results['total_duration_seconds']:.2f} ç§’")
        print(f"å®Œæˆæ­¥éª¤: {results['steps_completed']}/{results['steps_total']}")
        
        if results.get('pipeline_success'):
            print("âœ… æ‰€æœ‰æ­¥éª¤æ‰§è¡ŒæˆåŠŸ")
            print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶ä½ç½®:")
            print(f"  æŠ¥å‘Š: {config.output.OUTPUT_PATHS['regression_results'].parent}")
            print(f"  å›¾è¡¨: {config.output.FIGURE_PATHS['coefficient_comparison'].parent}")
        else:
            print("âš ï¸ éƒ¨åˆ†æ­¥éª¤æ‰§è¡Œå¤±è´¥ï¼Œä½†æ¡†æ¶æ¼”ç¤ºå®Œæˆ")
            print("è¯·æ£€æŸ¥æ—¥å¿—äº†è§£è¯¦ç»†ä¿¡æ¯")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {str(e)}")
        logger.exception("ç¨‹åºæ‰§è¡Œå¼‚å¸¸")
    finally:
        print(f"\nğŸ“Š æ—¥å¿—æ–‡ä»¶: {config.logging.LOG_FILE}")


if __name__ == "__main__":
    main()