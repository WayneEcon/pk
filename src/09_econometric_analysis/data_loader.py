#!/usr/bin/env python3
"""
æ•°æ®åŠ è½½æ¨¡å— (Data Loader Module)
============================================

09_econometric_analysis æ¨¡å—çš„æ•°æ®åŠ è½½ç»„ä»¶

ä½œè€…ï¼šEnergy Network Analysis Team
ç‰ˆæœ¬ï¼šv1.0 - è®¡é‡åˆ†ææ¡†æ¶
"""

import pandas as pd
import numpy as np
from pathlib import Path
import logging
from typing import Optional, Dict, List

logger = logging.getLogger(__name__)

class DataLoader:
    """
    æ•°æ®åŠ è½½å™¨ - ä¸“é—¨å¤„ç†ç©ºæ•°æ®å’Œç¼ºå¤±æ–‡ä»¶çš„å¥å£®åŠ è½½é€»è¾‘
    """
    
    def __init__(self, project_root: Optional[Path] = None):
        """
        åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        
        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨æ¨æ–­
        """
        if project_root is None:
            # ä»å½“å‰æ–‡ä»¶å‘ä¸Šè¿½æº¯æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
            self.project_root = Path(__file__).parent.parent.parent.parent
        else:
            self.project_root = Path(project_root)
        
        # å®šä¹‰æ•°æ®æ–‡ä»¶è·¯å¾„
        self.analytical_panel_path = self.project_root / "data" / "processed_data" / "analytical_panel.csv"
        
        logger.info(f"æ•°æ®åŠ è½½å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        logger.info(f"åˆ†æé¢æ¿è·¯å¾„: {self.analytical_panel_path}")
        
        # å®šä¹‰é¢„æœŸçš„åˆ—åï¼ˆåŸºäº08æ¨¡å—çš„è¾“å‡ºè§„èŒƒï¼‰
        self.expected_columns = self._get_expected_columns()
    
    def _get_expected_columns(self) -> List[str]:
        """
        å®šä¹‰é¢„æœŸçš„æ•°æ®åˆ—å
        
        Returns:
            é¢„æœŸçš„åˆ—ååˆ—è¡¨
        """
        return [
            # åŸºç¡€æ ‡è¯†å˜é‡
            'year', 'country', 'country_name',
            
            # å®è§‚ç»æµæ§åˆ¶å˜é‡
            'gdp_current_usd', 'population_total', 'trade_openness_gdp_pct',
            'log_gdp', 'log_population',
            
            # æ ¸å¿ƒç ”ç©¶å˜é‡ï¼ˆæ¥è‡ª08æ¨¡å—ï¼‰
            'node_dli_us',         # Node-DLI_US: ç¾å›½é”šå®šåŠ¨æ€é”å®šæŒ‡æ•°
            'vul_us',              # Vul_US: ç¾å›½é”šå®šè„†å¼±æ€§æŒ‡æ•°
            'ovi',                 # OVI: ç‰©ç†å†—ä½™æŒ‡æ•°
            'us_prod_shock',       # US_ProdShock: ç¾å›½äº§é‡å†²å‡»
            
            # ç½‘ç»œæ‹“æ‰‘æŒ‡æ ‡ï¼ˆæ¥è‡ª03æ¨¡å—ï¼‰
            'betweenness_centrality', 'eigenvector_centrality',
            'in_degree', 'out_degree', 'total_degree',
            'in_strength', 'out_strength', 'total_strength',
            'pagerank_centrality',
            
            # è¾…åŠ©å˜é‡
            'import_share_from_us', 'us_import_share', 'hhi_imports',
            'lng_capacity', 'pipeline_capacity', 'energy_demand',
            'us_production_oil', 'us_production_gas'
        ]
    
    def load_analytical_panel(self) -> pd.DataFrame:
        """
        åŠ è½½åˆ†æé¢æ¿æ•°æ® - æ ¸å¿ƒåŠŸèƒ½ï¼Œå¿…é¡»èƒ½å¤„ç†ç©ºæ•°æ®æƒ…å†µ
        
        Returns:
            åˆ†æé¢æ¿DataFrameï¼Œå¦‚æœæ•°æ®ç¼ºå¤±åˆ™è¿”å›ç©ºä½†ç»“æ„æ­£ç¡®çš„DataFrame
        """
        logger.info("ğŸ” å¼€å§‹åŠ è½½åˆ†æé¢æ¿æ•°æ®...")
        
        # æƒ…å†µ1: æ–‡ä»¶ä¸å­˜åœ¨
        if not self.analytical_panel_path.exists():
            logger.warning(f"âš ï¸ åˆ†æé¢æ¿æ–‡ä»¶ä¸å­˜åœ¨: {self.analytical_panel_path}")
            logger.info("   åˆ›å»ºç©ºçš„DataFrameæ¡†æ¶...")
            return self._create_empty_dataframe()
        
        try:
            # æƒ…å†µ2: æ–‡ä»¶å­˜åœ¨ï¼Œå°è¯•åŠ è½½
            logger.info(f"   ä»æ–‡ä»¶åŠ è½½: {self.analytical_panel_path}")
            df = pd.read_csv(self.analytical_panel_path)
            
            # æƒ…å†µ3: æ–‡ä»¶å­˜åœ¨ä½†ä¸ºç©º
            if len(df) == 0:
                logger.warning("âš ï¸ åˆ†æé¢æ¿æ–‡ä»¶ä¸ºç©º")
                logger.info("   åˆ›å»ºç©ºçš„DataFrameæ¡†æ¶...")
                return self._create_empty_dataframe()
            
            # æƒ…å†µ4: æ–‡ä»¶å­˜åœ¨æœ‰æ•°æ®ä½†æ‰€æœ‰å…³é”®å˜é‡éƒ½æ˜¯NaN
            key_variables = ['node_dli_us', 'vul_us', 'ovi', 'us_prod_shock']
            all_key_vars_missing = all(
                col not in df.columns or df[col].isna().all() 
                for col in key_variables
            )
            
            if all_key_vars_missing:
                logger.warning("âš ï¸ æ‰€æœ‰å…³é”®ç ”ç©¶å˜é‡éƒ½ç¼ºå¤±æˆ–ä¸ºNaN")
                logger.info(f"   æ•°æ®å½¢çŠ¶: {df.shape}ï¼Œä½†å…³é”®å˜é‡ä¸å¯ç”¨")
            else:
                logger.info(f"âœ… æˆåŠŸåŠ è½½åˆ†æé¢æ¿æ•°æ®")
                logger.info(f"   æ•°æ®å½¢çŠ¶: {df.shape}")
                
                # æ£€æŸ¥å…³é”®å˜é‡çš„å¯ç”¨æ€§
                available_vars = [col for col in key_variables if col in df.columns and not df[col].isna().all()]
                if available_vars:
                    logger.info(f"   å¯ç”¨å…³é”®å˜é‡: {available_vars}")
                else:
                    logger.warning("   æ²¡æœ‰å¯ç”¨çš„å…³é”®å˜é‡æ•°æ®")
            
            # ç¡®ä¿DataFrameåŒ…å«æ‰€æœ‰é¢„æœŸåˆ—
            df = self._ensure_expected_columns(df)
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½åˆ†æé¢æ¿æ•°æ®å¤±è´¥: {str(e)}")
            logger.info("   åˆ›å»ºç©ºçš„DataFrameæ¡†æ¶...")
            return self._create_empty_dataframe()
    
    def _create_empty_dataframe(self) -> pd.DataFrame:
        """
        åˆ›å»ºç©ºä½†ç»“æ„æ­£ç¡®çš„DataFrame
        
        Returns:
            åŒ…å«æ‰€æœ‰é¢„æœŸåˆ—ä½†æ— æ•°æ®çš„DataFrame
        """
        logger.info("   æ„å»ºç©ºDataFrameæ¡†æ¶...")
        
        # åˆ›å»ºç©ºDataFrameä½†åŒ…å«æ‰€æœ‰é¢„æœŸåˆ—
        df = pd.DataFrame(columns=self.expected_columns)
        
        # è®¾ç½®æ­£ç¡®çš„æ•°æ®ç±»å‹
        type_mapping = {
            'year': 'int64',
            'country': 'str',
            'country_name': 'str',
            'gdp_current_usd': 'float64',
            'population_total': 'float64',
            'trade_openness_gdp_pct': 'float64',
            'log_gdp': 'float64',
            'log_population': 'float64',
            'node_dli_us': 'float64',
            'vul_us': 'float64',
            'ovi': 'float64',
            'us_prod_shock': 'float64'
        }
        
        for col, dtype in type_mapping.items():
            if col in df.columns:
                if dtype == 'str':
                    df[col] = df[col].astype('object')
                else:
                    df[col] = df[col].astype(dtype)
        
        logger.info(f"   ç©ºDataFrameæ¡†æ¶åˆ›å»ºå®Œæˆ: {len(self.expected_columns)} åˆ—")
        return df
    
    def _ensure_expected_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ç¡®ä¿DataFrameåŒ…å«æ‰€æœ‰é¢„æœŸåˆ—
        
        Args:
            df: è¾“å…¥DataFrame
            
        Returns:
            åŒ…å«æ‰€æœ‰é¢„æœŸåˆ—çš„DataFrame
        """
        missing_cols = set(self.expected_columns) - set(df.columns)
        
        if missing_cols:
            logger.info(f"   æ·»åŠ ç¼ºå¤±åˆ—: {sorted(missing_cols)}")
            for col in missing_cols:
                df[col] = np.nan
        
        # é‡æ–°æ’åºåˆ—ä»¥åŒ¹é…é¢„æœŸé¡ºåº
        available_expected_cols = [col for col in self.expected_columns if col in df.columns]
        other_cols = [col for col in df.columns if col not in self.expected_columns]
        df = df[available_expected_cols + other_cols]
        
        return df
    
    def get_data_summary(self, df: pd.DataFrame) -> Dict:
        """
        è·å–æ•°æ®æ‘˜è¦ç»Ÿè®¡
        
        Args:
            df: è¾“å…¥DataFrame
            
        Returns:
            æ•°æ®æ‘˜è¦å­—å…¸
        """
        if len(df) == 0:
            return {
                'total_rows': 0,
                'total_cols': len(df.columns),
                'year_range': 'N/A',
                'countries': 0,
                'key_variables_available': [],
                'data_status': 'empty'
            }
        
        key_variables = ['node_dli_us', 'vul_us', 'ovi', 'us_prod_shock']
        available_key_vars = []
        
        for var in key_variables:
            if var in df.columns and not df[var].isna().all():
                non_missing_count = df[var].notna().sum()
                available_key_vars.append(f"{var} ({non_missing_count}/{len(df)})")
        
        summary = {
            'total_rows': len(df),
            'total_cols': len(df.columns),
            'year_range': f"{df['year'].min()}-{df['year'].max()}" if 'year' in df.columns else 'N/A',
            'countries': df['country'].nunique() if 'country' in df.columns else 0,
            'key_variables_available': available_key_vars,
            'data_status': 'available' if available_key_vars else 'missing_key_vars'
        }
        
        return summary
    
    def validate_data_for_analysis(self, df: pd.DataFrame) -> Dict:
        """
        éªŒè¯æ•°æ®æ˜¯å¦é€‚åˆè¿›è¡Œè®¡é‡åˆ†æ
        
        Args:
            df: è¾“å…¥DataFrame
            
        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        validation_results = {
            'is_valid_for_analysis': False,
            'issues': [],
            'recommendations': []
        }
        
        # æ£€æŸ¥1: æ•°æ®æ˜¯å¦ä¸ºç©º
        if len(df) == 0:
            validation_results['issues'].append("æ•°æ®é›†ä¸ºç©º")
            validation_results['recommendations'].append("ç­‰å¾…08æ¨¡å—ç”Ÿæˆæ•°æ®")
            return validation_results
        
        # æ£€æŸ¥2: å…³é”®å˜é‡æ˜¯å¦å¯ç”¨
        key_variables = ['node_dli_us', 'vul_us', 'ovi', 'us_prod_shock']
        missing_key_vars = []
        
        for var in key_variables:
            if var not in df.columns or df[var].isna().all():
                missing_key_vars.append(var)
        
        if missing_key_vars:
            validation_results['issues'].append(f"å…³é”®å˜é‡ç¼ºå¤±: {missing_key_vars}")
            validation_results['recommendations'].append("æ£€æŸ¥08æ¨¡å—æ•°æ®æ„å»ºçŠ¶æ€")
        
        # æ£€æŸ¥3: æ§åˆ¶å˜é‡æ˜¯å¦å¯ç”¨
        control_variables = ['log_gdp', 'log_population', 'trade_openness_gdp_pct']
        missing_controls = []
        
        for var in control_variables:
            if var not in df.columns or df[var].isna().all():
                missing_controls.append(var)
        
        if missing_controls:
            validation_results['issues'].append(f"æ§åˆ¶å˜é‡ç¼ºå¤±: {missing_controls}")
        
        # æ£€æŸ¥4: é¢æ¿æ•°æ®ç»“æ„
        if 'year' not in df.columns or 'country' not in df.columns:
            validation_results['issues'].append("ç¼ºå°‘é¢æ¿æ•°æ®å¿…éœ€çš„å¹´ä»½æˆ–å›½å®¶æ ‡è¯†")
        elif len(df) > 0:
            year_count = df['year'].nunique()
            country_count = df['country'].nunique()
            if year_count < 2:
                validation_results['issues'].append("å¹´ä»½ç»´åº¦ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œé¢æ¿åˆ†æ")
            if country_count < 2:
                validation_results['issues'].append("å›½å®¶ç»´åº¦ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œé¢æ¿åˆ†æ")
        
        # æœ€ç»ˆåˆ¤æ–­
        validation_results['is_valid_for_analysis'] = len(validation_results['issues']) == 0
        
        if not validation_results['is_valid_for_analysis']:
            validation_results['recommendations'].append("å½“å‰æ•°æ®ä¸é€‚åˆè®¡é‡åˆ†æï¼Œå»ºè®®ç­‰å¾…æ•°æ®å®Œå–„")
        
        return validation_results


def load_data() -> pd.DataFrame:
    """
    ä¾¿æ·å‡½æ•°ï¼šåŠ è½½åˆ†ææ•°æ®
    
    Returns:
        åˆ†æé¢æ¿DataFrame
    """
    loader = DataLoader()
    return loader.load_analytical_panel()


def get_data_status() -> Dict:
    """
    ä¾¿æ·å‡½æ•°ï¼šè·å–æ•°æ®çŠ¶æ€
    
    Returns:
        æ•°æ®çŠ¶æ€æ‘˜è¦
    """
    loader = DataLoader()
    df = loader.load_analytical_panel()
    summary = loader.get_data_summary(df)
    validation = loader.validate_data_for_analysis(df)
    
    return {
        'summary': summary,
        'validation': validation
    }


if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®åŠ è½½åŠŸèƒ½
    import logging
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    print("ğŸ”¬ 09_econometric_analysis æ•°æ®åŠ è½½å™¨æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    loader = DataLoader()
    df = loader.load_analytical_panel()
    
    print(f"\nğŸ“Š æ•°æ®åŠ è½½ç»“æœ:")
    print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"åˆ—å: {list(df.columns)}")
    
    # æ•°æ®æ‘˜è¦
    summary = loader.get_data_summary(df)
    print(f"\nğŸ“ˆ æ•°æ®æ‘˜è¦:")
    for key, value in summary.items():
        print(f"  {key}: {value}")
    
    # æ•°æ®éªŒè¯
    validation = loader.validate_data_for_analysis(df)
    print(f"\nâœ… æ•°æ®éªŒè¯:")
    print(f"  é€‚åˆåˆ†æ: {validation['is_valid_for_analysis']}")
    if validation['issues']:
        print(f"  é—®é¢˜: {validation['issues']}")
    if validation['recommendations']:
        print(f"  å»ºè®®: {validation['recommendations']}")
    
    print("\nğŸ‰ æ•°æ®åŠ è½½å™¨æµ‹è¯•å®Œæˆ!")