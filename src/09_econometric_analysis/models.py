#!/usr/bin/env python3
"""
è®¡é‡æ¨¡å‹æ¨¡å— (Econometric Models Module)
=====================================

09_econometric_analysis æ¨¡å—çš„æ ¸å¿ƒè®¡é‡æ¨¡å‹å®ç°

ä½œè€…ï¼šEnergy Network Analysis Team
ç‰ˆæœ¬ï¼šv1.0 - è®¡é‡åˆ†ææ¡†æ¶
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
import logging
from pathlib import Path
import warnings

# è®¡é‡åˆ†æåº“å¯¼å…¥ (æ¡ä»¶å¯¼å…¥ä»¥å¤„ç†ç¼ºå¤±ä¾èµ–)
try:
    import statsmodels.api as sm
    from statsmodels.formula.api import ols
    from statsmodels.stats.diagnostic import het_breuschpagan, het_white
    from statsmodels.stats.stattools import durbin_watson
    HAS_STATSMODELS = True
except ImportError:
    HAS_STATSMODELS = False

try:
    from linearmodels import PanelOLS, PooledOLS
    HAS_LINEARMODELS = True
except ImportError:
    HAS_LINEARMODELS = False

from .config import config

logger = logging.getLogger(__name__)

class EconometricModels:
    """
    è®¡é‡åˆ†ææ¨¡å‹ç±» - å®ç°ç©ºæ•°æ®å…¼å®¹çš„è®¡é‡åˆ†ææ¡†æ¶
    """
    
    def __init__(self):
        """åˆå§‹åŒ–è®¡é‡æ¨¡å‹åˆ†æå™¨"""
        self.config = config
        self.results = {}
        
        logger.info("ğŸ”¬ è®¡é‡æ¨¡å‹åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        
        # æ£€æŸ¥ä¾èµ–åº“å¯ç”¨æ€§
        if not HAS_STATSMODELS:
            logger.warning("âš ï¸ statsmodelsåº“ä¸å¯ç”¨ï¼Œéƒ¨åˆ†åŠŸèƒ½å—é™")
        if not HAS_LINEARMODELS:
            logger.warning("âš ï¸ linearmodelsåº“ä¸å¯ç”¨ï¼Œé¢æ¿æ•°æ®åˆ†æå—é™")
    
    def _check_data_availability(self, df: pd.DataFrame, required_vars: List[str]) -> Dict[str, Any]:
        """
        æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
        
        Args:
            df: è¾“å…¥æ•°æ®
            required_vars: å¿…éœ€å˜é‡åˆ—è¡¨
            
        Returns:
            æ•°æ®å¯ç”¨æ€§æ£€æŸ¥ç»“æœ
        """
        check_result = {
            'data_available': False,
            'missing_vars': [],
            'empty_vars': [],
            'total_obs': 0,
            'usable_obs': 0,
            'status_message': ''
        }
        
        # åŸºç¡€æ£€æŸ¥ï¼šæ•°æ®æ˜¯å¦ä¸ºç©º
        if df is None or len(df) == 0:
            check_result['status_message'] = 'æ•°æ®é›†ä¸ºç©ºæˆ–ä¸å­˜åœ¨'
            return check_result
        
        check_result['total_obs'] = len(df)
        
        # æ£€æŸ¥å˜é‡æ˜¯å¦å­˜åœ¨
        missing_vars = [var for var in required_vars if var not in df.columns]
        if missing_vars:
            check_result['missing_vars'] = missing_vars
            check_result['status_message'] = f'ç¼ºå°‘å¿…éœ€å˜é‡: {missing_vars}'
            return check_result
        
        # æ£€æŸ¥å˜é‡æ˜¯å¦å…¨ä¸ºç©º
        empty_vars = [var for var in required_vars if df[var].isna().all()]
        if empty_vars:
            check_result['empty_vars'] = empty_vars
            check_result['status_message'] = f'å˜é‡æ•°æ®å…¨ä¸ºç©º: {empty_vars}'
            return check_result
        
        # æ£€æŸ¥å¯ç”¨è§‚æµ‹æ•°
        subset_df = df[required_vars].dropna()
        check_result['usable_obs'] = len(subset_df)
        
        if check_result['usable_obs'] < self.config.validation.DATA_QUALITY_THRESHOLDS['min_observations']:
            check_result['status_message'] = f'å¯ç”¨è§‚æµ‹æ•°ä¸è¶³: {check_result["usable_obs"]} < {self.config.validation.DATA_QUALITY_THRESHOLDS["min_observations"]}'
            return check_result
        
        # æ•°æ®å¯ç”¨
        check_result['data_available'] = True
        check_result['status_message'] = 'æ•°æ®å¯ç”¨äºåˆ†æ'
        
        return check_result
    
    def _create_empty_result(self, model_name: str, status_message: str) -> Dict[str, Any]:
        """
        åˆ›å»ºç©ºç»“æœå­—å…¸
        
        Args:
            model_name: æ¨¡å‹åç§°
            status_message: çŠ¶æ€ä¿¡æ¯
            
        Returns:
            ç©ºç»“æœå­—å…¸
        """
        return {
            'model_name': model_name,
            'model_type': self.config.analysis.RESEARCH_MODELS.get(model_name, {}).get('method', 'unknown'),
            'status': 'failed',
            'status_message': status_message,
            'coefficients': {},
            'std_errors': {},
            'p_values': {},
            'r_squared': np.nan,
            'n_obs': 0,
            'n_entities': 0,
            'diagnostics': {},
            'estimation_time': 0.0,
            'formula': self.config.analysis.RESEARCH_MODELS.get(model_name, {}).get('formula', ''),
            'data_available': False
        }
    
    def run_dli_vul_association(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        æ¨¡å‹1: DLI-è„†å¼±æ€§å…³è”æ£€éªŒ
        åŒå‘å›ºå®šæ•ˆåº”é¢æ¿æ¨¡å‹: vul_us ~ node_dli_us + Controls + FE(country,year)
        
        Args:
            df: åˆ†ææ•°æ®
            
        Returns:
            æ¨¡å‹ç»“æœå­—å…¸
        """
        model_name = 'model_1_dli_vul_association'
        logger.info(f"ğŸ” è¿è¡Œæ¨¡å‹1: DLI-è„†å¼±æ€§å…³è”æ£€éªŒ...")
        
        # å®šä¹‰å¿…éœ€å˜é‡
        required_vars = ['vul_us', 'node_dli_us', 'year', 'country'] + self.config.get_control_variables('macro_controls')
        
        # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
        data_check = self._check_data_availability(df, required_vars)
        if not data_check['data_available']:
            logger.warning(f"   âš ï¸ {data_check['status_message']}")
            return self._create_empty_result(model_name, data_check['status_message'])
        
        logger.info(f"   æ•°æ®æ£€æŸ¥é€šè¿‡: {data_check['usable_obs']} ä¸ªå¯ç”¨è§‚æµ‹")
        
        # å¦‚æœæ²¡æœ‰statsmodelsæˆ–linearmodelsï¼Œè¿”å›ç©ºç»“æœ
        if not HAS_STATSMODELS or not HAS_LINEARMODELS:
            return self._create_empty_result(model_name, 'ç¼ºå°‘å¿…éœ€çš„è®¡é‡åˆ†æåº“')
        
        try:
            # å‡†å¤‡æ•°æ®
            analysis_data = df[required_vars].dropna().copy()
            
            # è®¾ç½®é¢æ¿æ•°æ®ç´¢å¼•
            analysis_data = analysis_data.set_index(['country', 'year'])
            
            # æ„å»ºæ¨¡å‹å…¬å¼
            dependent_var = 'vul_us'
            explanatory_vars = ['node_dli_us'] + self.config.get_control_variables('macro_controls')
            
            # è¿è¡ŒåŒå‘å›ºå®šæ•ˆåº”æ¨¡å‹
            logger.info(f"   ä¼°è®¡åŒå‘å›ºå®šæ•ˆåº”æ¨¡å‹...")
            
            model = PanelOLS(
                dependent=analysis_data[dependent_var],
                exog=analysis_data[explanatory_vars],
                entity_effects=True,    # ä¸ªä½“å›ºå®šæ•ˆåº”
                time_effects=True,      # æ—¶é—´å›ºå®šæ•ˆåº”
                check_rank=False        # è·³è¿‡rankæ£€æŸ¥ä»¥å¤„ç†å°æ ·æœ¬
            )
            
            results = model.fit(cov_type='clustered', cluster_entity=True)
            
            # æå–ç»“æœ
            result_dict = {
                'model_name': model_name,
                'model_type': 'two_way_fixed_effects',
                'status': 'success',
                'status_message': 'æ¨¡å‹ä¼°è®¡æˆåŠŸ',
                'coefficients': dict(results.params),
                'std_errors': dict(results.std_errors),
                'p_values': dict(results.pvalues),
                'r_squared': float(results.rsquared),
                'r_squared_within': float(results.rsquared_within) if hasattr(results, 'rsquared_within') else np.nan,
                'n_obs': int(results.nobs),
                'n_entities': len(analysis_data.index.get_level_values('country').unique()),
                'f_statistic': float(results.f_statistic.stat) if hasattr(results, 'f_statistic') else np.nan,
                'formula': f"{dependent_var} ~ {' + '.join(explanatory_vars)} + EntityEffects + TimeEffects",
                'data_available': True,
                'estimation_time': 0.0,  # å¯ä»¥æ·»åŠ è®¡æ—¶åŠŸèƒ½
                'diagnostics': self._run_model_diagnostics(analysis_data, results)
            }
            
            logger.info(f"   âœ… æ¨¡å‹1ä¼°è®¡å®Œæˆ: RÂ²={result_dict['r_squared']:.4f}, N={result_dict['n_obs']}")
            
            return result_dict
            
        except Exception as e:
            error_msg = f"æ¨¡å‹ä¼°è®¡å¤±è´¥: {str(e)}"
            logger.error(f"   âŒ {error_msg}")
            return self._create_empty_result(model_name, error_msg)
    
    def run_ovi_dli_causality(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        æ¨¡å‹2: OVIå¯¹DLIçš„å› æœæ•ˆåº”
        åŒå‘å›ºå®šæ•ˆåº”é¢æ¿æ¨¡å‹: node_dli_us ~ ovi(t-1) + Controls + FE(country,year)
        
        Args:
            df: åˆ†ææ•°æ®
            
        Returns:
            æ¨¡å‹ç»“æœå­—å…¸
        """
        model_name = 'model_2_ovi_dli_causality'
        logger.info(f"ğŸ” è¿è¡Œæ¨¡å‹2: OVIå¯¹DLIçš„å› æœæ•ˆåº”...")
        
        # å®šä¹‰å¿…éœ€å˜é‡
        required_vars = ['node_dli_us', 'ovi', 'year', 'country'] + self.config.get_control_variables('macro_controls')
        
        # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
        data_check = self._check_data_availability(df, required_vars)
        if not data_check['data_available']:
            logger.warning(f"   âš ï¸ {data_check['status_message']}")
            return self._create_empty_result(model_name, data_check['status_message'])
        
        logger.info(f"   æ•°æ®æ£€æŸ¥é€šè¿‡: {data_check['usable_obs']} ä¸ªå¯ç”¨è§‚æµ‹")
        
        if not HAS_STATSMODELS or not HAS_LINEARMODELS:
            return self._create_empty_result(model_name, 'ç¼ºå°‘å¿…éœ€çš„è®¡é‡åˆ†æåº“')
        
        try:
            # å‡†å¤‡æ•°æ®å¹¶åˆ›å»ºæ»åå˜é‡
            analysis_data = df[required_vars].dropna().copy()
            analysis_data = analysis_data.sort_values(['country', 'year'])
            
            # åˆ›å»ºOVIçš„æ»åé¡¹
            analysis_data['ovi_lag1'] = analysis_data.groupby('country')['ovi'].shift(1)
            
            # åˆ é™¤æ— æ³•è®¡ç®—æ»åçš„è§‚æµ‹
            analysis_data = analysis_data.dropna(subset=['ovi_lag1'])
            
            if len(analysis_data) < self.config.validation.DATA_QUALITY_THRESHOLDS['min_observations']:
                return self._create_empty_result(model_name, 'åˆ›å»ºæ»åå˜é‡åè§‚æµ‹æ•°ä¸è¶³')
            
            # è®¾ç½®é¢æ¿æ•°æ®ç´¢å¼•
            analysis_data = analysis_data.set_index(['country', 'year'])
            
            # æ„å»ºæ¨¡å‹
            dependent_var = 'node_dli_us'
            explanatory_vars = ['ovi_lag1'] + self.config.get_control_variables('macro_controls')
            
            logger.info(f"   ä¼°è®¡OVIæ»åæ•ˆåº”æ¨¡å‹...")
            
            model = PanelOLS(
                dependent=analysis_data[dependent_var],
                exog=analysis_data[explanatory_vars],
                entity_effects=True,
                time_effects=True,
                check_rank=False
            )
            
            results = model.fit(cov_type='clustered', cluster_entity=True)
            
            # æå–ç»“æœ
            result_dict = {
                'model_name': model_name,
                'model_type': 'two_way_fixed_effects_lagged',
                'status': 'success',
                'status_message': 'æ¨¡å‹ä¼°è®¡æˆåŠŸ',
                'coefficients': dict(results.params),
                'std_errors': dict(results.std_errors),
                'p_values': dict(results.pvalues),
                'r_squared': float(results.rsquared),
                'r_squared_within': float(results.rsquared_within) if hasattr(results, 'rsquared_within') else np.nan,
                'n_obs': int(results.nobs),
                'n_entities': len(analysis_data.index.get_level_values('country').unique()),
                'f_statistic': float(results.f_statistic.stat) if hasattr(results, 'f_statistic') else np.nan,
                'formula': f"{dependent_var} ~ {' + '.join(explanatory_vars)} + EntityEffects + TimeEffects",
                'data_available': True,
                'lag_structure': 'ovi_lag1',
                'estimation_time': 0.0,
                'diagnostics': self._run_model_diagnostics(analysis_data, results)
            }
            
            logger.info(f"   âœ… æ¨¡å‹2ä¼°è®¡å®Œæˆ: RÂ²={result_dict['r_squared']:.4f}, N={result_dict['n_obs']}")
            
            return result_dict
            
        except Exception as e:
            error_msg = f"æ¨¡å‹ä¼°è®¡å¤±è´¥: {str(e)}"
            logger.error(f"   âŒ {error_msg}")
            return self._create_empty_result(model_name, error_msg)
    
    def run_local_projection_shock_validation(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        æ¨¡å‹3: å±€éƒ¨æŠ•å½±å› æœéªŒè¯
        å±€éƒ¨æŠ•å½±æ¨¡å‹: Î”Y(t+h) ~ US_ProdShock(t) * OVI(t-1) + Controls
        
        Args:
            df: åˆ†ææ•°æ®
            
        Returns:
            æ¨¡å‹ç»“æœå­—å…¸
        """
        model_name = 'model_3_local_projection_validation'
        logger.info(f"ğŸ” è¿è¡Œæ¨¡å‹3: å±€éƒ¨æŠ•å½±å› æœéªŒè¯...")
        
        # å®šä¹‰å¿…éœ€å˜é‡
        required_vars = ['vul_us', 'us_prod_shock', 'ovi', 'year', 'country'] + self.config.get_control_variables('macro_controls')
        
        # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
        data_check = self._check_data_availability(df, required_vars)
        if not data_check['data_available']:
            logger.warning(f"   âš ï¸ {data_check['status_message']}")
            return self._create_empty_result(model_name, data_check['status_message'])
        
        logger.info(f"   æ•°æ®æ£€æŸ¥é€šè¿‡: {data_check['usable_obs']} ä¸ªå¯ç”¨è§‚æµ‹")
        
        if not HAS_STATSMODELS or not HAS_LINEARMODELS:
            return self._create_empty_result(model_name, 'ç¼ºå°‘å¿…éœ€çš„è®¡é‡åˆ†æåº“')
        
        try:
            # å‡†å¤‡æ•°æ®
            analysis_data = df[required_vars].dropna().copy()
            analysis_data = analysis_data.sort_values(['country', 'year'])
            
            # åˆ›å»ºæ»åå˜é‡å’Œæœªæ¥å˜åŒ–
            analysis_data['ovi_lag1'] = analysis_data.groupby('country')['ovi'].shift(1)
            
            # è·å–é¢„æµ‹æœŸæ•°è®¾å®š
            horizons = self.config.analysis.RESEARCH_MODELS[model_name].get('horizons', [0, 1, 2, 3])
            
            # ä¸ºä¸åŒé¢„æµ‹æœŸåˆ›å»ºå› å˜é‡
            for h in horizons:
                if h == 0:
                    analysis_data[f'delta_vul_h{h}'] = analysis_data.groupby('country')['vul_us'].diff()
                else:
                    analysis_data[f'delta_vul_h{h}'] = (
                        analysis_data.groupby('country')['vul_us'].shift(-h) - 
                        analysis_data['vul_us']
                    )
            
            # åˆ›å»ºäº¤äº’é¡¹
            analysis_data['us_prod_shock_x_ovi_lag1'] = (
                analysis_data['us_prod_shock'] * analysis_data['ovi_lag1']
            )
            
            # åˆ é™¤ç¼ºå¤±æ•°æ®
            required_for_lp = ['us_prod_shock', 'ovi_lag1', 'us_prod_shock_x_ovi_lag1'] + self.config.get_control_variables('macro_controls')
            analysis_data = analysis_data.dropna(subset=required_for_lp)
            
            if len(analysis_data) < self.config.validation.DATA_QUALITY_THRESHOLDS['min_observations']:
                return self._create_empty_result(model_name, 'åˆ›å»ºå±€éƒ¨æŠ•å½±å˜é‡åè§‚æµ‹æ•°ä¸è¶³')
            
            logger.info(f"   ä¼°è®¡å±€éƒ¨æŠ•å½±æ¨¡å‹ï¼Œé¢„æµ‹æœŸæ•°: {horizons}")
            
            # è¿è¡Œä¸åŒæ—¶é—´çª—å£çš„å±€éƒ¨æŠ•å½±
            horizon_results = {}
            overall_diagnostics = {}
            
            for h in horizons:
                dependent_var = f'delta_vul_h{h}'
                
                # æ£€æŸ¥è¯¥æœŸæ•°çš„å› å˜é‡æ˜¯å¦å¯ç”¨
                if dependent_var not in analysis_data.columns or analysis_data[dependent_var].isna().all():
                    logger.warning(f"   è·³è¿‡é¢„æµ‹æœŸ h={h}: å› å˜é‡ä¸å¯ç”¨")
                    continue
                
                # å‡†å¤‡è¯¥æœŸæ•°çš„æ•°æ®
                horizon_data = analysis_data.dropna(subset=[dependent_var])
                
                if len(horizon_data) < 20:  # æœ€å°‘è§‚æµ‹æ•°
                    logger.warning(f"   è·³è¿‡é¢„æµ‹æœŸ h={h}: è§‚æµ‹æ•°ä¸è¶³({len(horizon_data)})")
                    continue
                
                # è®¾ç½®ç´¢å¼•
                horizon_data = horizon_data.set_index(['country', 'year'])
                
                # ä¼°è®¡æ¨¡å‹
                explanatory_vars = ['us_prod_shock', 'ovi_lag1', 'us_prod_shock_x_ovi_lag1'] + self.config.get_control_variables('macro_controls')
                
                try:
                    model = PanelOLS(
                        dependent=horizon_data[dependent_var],
                        exog=horizon_data[explanatory_vars],
                        entity_effects=True,
                        time_effects=False,  # å±€éƒ¨æŠ•å½±é€šå¸¸ä¸åŒ…å«æ—¶é—´æ•ˆåº”
                        check_rank=False
                    )
                    
                    results = model.fit(cov_type='clustered', cluster_entity=True)
                    
                    horizon_results[f'h{h}'] = {
                        'horizon': h,
                        'coefficients': dict(results.params),
                        'std_errors': dict(results.std_errors),
                        'p_values': dict(results.pvalues),
                        'r_squared': float(results.rsquared),
                        'n_obs': int(results.nobs)
                    }
                    
                    logger.info(f"     âœ“ h={h}: RÂ²={results.rsquared:.4f}, N={results.nobs}")
                    
                except Exception as e:
                    logger.warning(f"     âœ— h={h}: ä¼°è®¡å¤±è´¥ - {str(e)}")
                    continue
            
            if not horizon_results:
                return self._create_empty_result(model_name, 'æ‰€æœ‰é¢„æµ‹æœŸæ•°çš„æ¨¡å‹ä¼°è®¡éƒ½å¤±è´¥')
            
            # èšåˆç»“æœ
            result_dict = {
                'model_name': model_name,
                'model_type': 'local_projections',
                'status': 'success',
                'status_message': f'å±€éƒ¨æŠ•å½±æ¨¡å‹ä¼°è®¡æˆåŠŸï¼Œ{len(horizon_results)}ä¸ªé¢„æµ‹æœŸ',
                'horizon_results': horizon_results,
                'horizons_estimated': list(horizon_results.keys()),
                'n_horizons': len(horizon_results),
                'formula': f"Î”vul_us(t+h) ~ us_prod_shock(t) * ovi_lag1(t-1) + Controls + EntityEffects",
                'data_available': True,
                'estimation_time': 0.0,
                'diagnostics': overall_diagnostics
            }
            
            logger.info(f"   âœ… æ¨¡å‹3ä¼°è®¡å®Œæˆ: {len(horizon_results)} ä¸ªé¢„æµ‹æœŸ")
            
            return result_dict
            
        except Exception as e:
            error_msg = f"å±€éƒ¨æŠ•å½±æ¨¡å‹ä¼°è®¡å¤±è´¥: {str(e)}"
            logger.error(f"   âŒ {error_msg}")
            return self._create_empty_result(model_name, error_msg)
    
    def _run_model_diagnostics(self, data: pd.DataFrame, results) -> Dict[str, Any]:
        """
        è¿è¡Œæ¨¡å‹è¯Šæ–­æ£€éªŒ
        
        Args:
            data: åˆ†ææ•°æ®
            results: æ¨¡å‹ç»“æœ
            
        Returns:
            è¯Šæ–­ç»“æœå­—å…¸
        """
        diagnostics = {}
        
        try:
            # åŸºç¡€ç»Ÿè®¡
            diagnostics['n_obs'] = len(data)
            diagnostics['n_vars'] = len(data.columns)
            
            # å¦‚æœæœ‰æ®‹å·®ï¼Œè¿›è¡Œè¿›ä¸€æ­¥è¯Šæ–­
            if hasattr(results, 'resids'):
                residuals = results.resids
                
                # æ®‹å·®åŸºç¡€ç»Ÿè®¡
                diagnostics['residual_mean'] = float(residuals.mean())
                diagnostics['residual_std'] = float(residuals.std())
                
                # Durbin-Watsonæ£€éªŒ (å¦‚æœæœ‰statsmodels)
                if HAS_STATSMODELS:
                    try:
                        diagnostics['durbin_watson'] = float(durbin_watson(residuals))
                    except:
                        diagnostics['durbin_watson'] = np.nan
            
        except Exception as e:
            logger.warning(f"è¯Šæ–­æ£€éªŒå¤±è´¥: {str(e)}")
            diagnostics['error'] = str(e)
        
        return diagnostics
    
    def run_all_models(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        è¿è¡Œæ‰€æœ‰æ ¸å¿ƒæ¨¡å‹
        
        Args:
            df: åˆ†ææ•°æ®
            
        Returns:
            æ‰€æœ‰æ¨¡å‹ç»“æœçš„æ±‡æ€»å­—å…¸
        """
        logger.info("ğŸš€ å¼€å§‹è¿è¡Œæ‰€æœ‰æ ¸å¿ƒè®¡é‡æ¨¡å‹...")
        
        all_results = {
            'overview': {
                'total_models': 3,
                'completed_models': 0,
                'failed_models': 0,
                'data_available': len(df) > 0 if df is not None else False
            },
            'models': {}
        }
        
        # æ¨¡å‹1: DLI-è„†å¼±æ€§å…³è”
        try:
            result1 = self.run_dli_vul_association(df)
            all_results['models']['model_1_dli_vul_association'] = result1
            if result1['status'] == 'success':
                all_results['overview']['completed_models'] += 1
            else:
                all_results['overview']['failed_models'] += 1
        except Exception as e:
            logger.error(f"æ¨¡å‹1è¿è¡Œå¼‚å¸¸: {str(e)}")
            all_results['models']['model_1_dli_vul_association'] = self._create_empty_result('model_1_dli_vul_association', f'è¿è¡Œå¼‚å¸¸: {str(e)}')
            all_results['overview']['failed_models'] += 1
        
        # æ¨¡å‹2: OVIå› æœæ•ˆåº”
        try:
            result2 = self.run_ovi_dli_causality(df)
            all_results['models']['model_2_ovi_dli_causality'] = result2
            if result2['status'] == 'success':
                all_results['overview']['completed_models'] += 1
            else:
                all_results['overview']['failed_models'] += 1
        except Exception as e:
            logger.error(f"æ¨¡å‹2è¿è¡Œå¼‚å¸¸: {str(e)}")
            all_results['models']['model_2_ovi_dli_causality'] = self._create_empty_result('model_2_ovi_dli_causality', f'è¿è¡Œå¼‚å¸¸: {str(e)}')
            all_results['overview']['failed_models'] += 1
        
        # æ¨¡å‹3: å±€éƒ¨æŠ•å½±éªŒè¯
        try:
            result3 = self.run_local_projection_shock_validation(df)
            all_results['models']['model_3_local_projection_validation'] = result3
            if result3['status'] == 'success':
                all_results['overview']['completed_models'] += 1
            else:
                all_results['overview']['failed_models'] += 1
        except Exception as e:
            logger.error(f"æ¨¡å‹3è¿è¡Œå¼‚å¸¸: {str(e)}")
            all_results['models']['model_3_local_projection_validation'] = self._create_empty_result('model_3_local_projection_validation', f'è¿è¡Œå¼‚å¸¸: {str(e)}')
            all_results['overview']['failed_models'] += 1
        
        logger.info(f"âœ… æ‰€æœ‰æ¨¡å‹è¿è¡Œå®Œæˆ: æˆåŠŸ {all_results['overview']['completed_models']}/{all_results['overview']['total_models']}")
        
        return all_results


# ä¾¿æ·å‡½æ•°
def run_single_model(model_name: str, df: pd.DataFrame) -> Dict[str, Any]:
    """
    è¿è¡Œå•ä¸ªæ¨¡å‹çš„ä¾¿æ·å‡½æ•°
    
    Args:
        model_name: æ¨¡å‹åç§°
        df: åˆ†ææ•°æ®
        
    Returns:
        æ¨¡å‹ç»“æœ
    """
    models = EconometricModels()
    
    if model_name == 'model_1_dli_vul_association':
        return models.run_dli_vul_association(df)
    elif model_name == 'model_2_ovi_dli_causality':
        return models.run_ovi_dli_causality(df)
    elif model_name == 'model_3_local_projection_validation':
        return models.run_local_projection_shock_validation(df)
    else:
        raise ValueError(f"æœªçŸ¥æ¨¡å‹åç§°: {model_name}")


if __name__ == "__main__":
    # æµ‹è¯•æ¨¡å‹æ¨¡å—
    import logging
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    print("ğŸ”¬ 09_econometric_analysis æ¨¡å‹æ¨¡å—æµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºç©ºDataFrameæµ‹è¯•
    test_df = pd.DataFrame()
    
    models = EconometricModels()
    results = models.run_all_models(test_df)
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"æ€»æ¨¡å‹æ•°: {results['overview']['total_models']}")
    print(f"å®Œæˆæ¨¡å‹æ•°: {results['overview']['completed_models']}")
    print(f"å¤±è´¥æ¨¡å‹æ•°: {results['overview']['failed_models']}")
    
    for model_name, result in results['models'].items():
        print(f"\nâ€¢ {model_name}:")
        print(f"  çŠ¶æ€: {result['status']}")
        print(f"  ä¿¡æ¯: {result['status_message']}")
    
    print("\nğŸ‰ æ¨¡å‹æ¨¡å—æµ‹è¯•å®Œæˆ!")