#!/usr/bin/env python3
"""
ç»“æœæŠ¥å‘Šæ¨¡å— (Reporting Module)
==============================

09_econometric_analysis æ¨¡å—çš„ç»“æœæŠ¥å‘Šç”Ÿæˆç»„ä»¶

ä½œè€…ï¼šEnergy Network Analysis Team
ç‰ˆæœ¬ï¼šv1.0 - è®¡é‡åˆ†ææ¡†æ¶
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
import logging
from pathlib import Path
import json
from datetime import datetime

try:
    from .config import config
except ImportError:
    import config
    config = config.config

logger = logging.getLogger(__name__)

class ReportGenerator:
    """
    æŠ¥å‘Šç”Ÿæˆå™¨ - ä¸“é—¨å¤„ç†ç©ºç»“æœå’Œç¼ºå¤±æ•°æ®çš„æŠ¥å‘Šç”Ÿæˆé€»è¾‘
    """
    
    def __init__(self, output_dir: Optional[Path] = None):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤ç›®å½•
        """
        self.config = config
        self.output_dir = output_dir or self.config.output.OUTPUT_PATHS['regression_results'].parent
        self.output_dir.mkdir(exist_ok=True)
        
        logger.info(f"ğŸ“ æŠ¥å‘Šç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        
        self.timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    def generate_regression_results_csv(self, model_results: Dict[str, Any]) -> Path:
        """
        ç”Ÿæˆå›å½’ç»“æœCSVæ–‡ä»¶
        
        Args:
            model_results: æ¨¡å‹ç»“æœå­—å…¸
            
        Returns:
            CSVæ–‡ä»¶è·¯å¾„
        """
        logger.info("ğŸ“Š ç”Ÿæˆå›å½’ç»“æœCSV...")
        
        # å‡†å¤‡ç»“æœæ•°æ®åˆ—è¡¨
        results_data = []
        
        if 'models' in model_results:
            models_dict = model_results['models']
        else:
            models_dict = model_results
        
        for model_name, result in models_dict.items():
            
            # å¤„ç†æ™®é€šæ¨¡å‹ç»“æœ
            if model_name != 'model_3_local_projection_validation':
                row_data = self._extract_model_row(model_name, result)
                results_data.append(row_data)
            
            # å¤„ç†å±€éƒ¨æŠ•å½±æ¨¡å‹çš„å¤šæœŸç»“æœ
            else:
                if result.get('status') == 'success' and 'horizon_results' in result:
                    for horizon_key, horizon_result in result['horizon_results'].items():
                        row_data = self._extract_horizon_row(model_name, horizon_key, horizon_result)
                        results_data.append(row_data)
                else:
                    # å±€éƒ¨æŠ•å½±æ¨¡å‹å¤±è´¥çš„æƒ…å†µ
                    row_data = self._extract_model_row(model_name, result)
                    results_data.append(row_data)
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•ç»“æœï¼Œåˆ›å»ºç©ºè¡Œ
        if not results_data:
            results_data.append(self._create_empty_row())
        
        # è½¬æ¢ä¸ºDataFrame
        results_df = pd.DataFrame(results_data)
        
        # ä¿å­˜CSV
        csv_path = self.output_dir / "regression_results.csv"
        results_df.to_csv(csv_path, index=False)
        
        logger.info(f"âœ… å›å½’ç»“æœCSVå·²ç”Ÿæˆ: {csv_path}")
        logger.info(f"   åŒ…å« {len(results_df)} è¡Œç»“æœ")
        
        return csv_path
    
    def _extract_model_row(self, model_name: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä»æ¨¡å‹ç»“æœä¸­æå–ä¸€è¡Œæ•°æ®
        
        Args:
            model_name: æ¨¡å‹åç§°
            result: æ¨¡å‹ç»“æœ
            
        Returns:
            è¡Œæ•°æ®å­—å…¸
        """
        # è·å–æ¨¡å‹é…ç½®ä¿¡æ¯
        model_config = self.config.analysis.RESEARCH_MODELS.get(model_name, {})
        
        row_data = {
            'model_name': model_name,
            'model_description': model_config.get('name', model_name),
            'chapter': model_config.get('chapter', 'N/A'),
            'method': result.get('model_type', 'N/A'),
            'status': result.get('status', 'unknown'),
            'status_message': result.get('status_message', ''),
            'formula': result.get('formula', model_config.get('formula', '')),
            'n_obs': result.get('n_obs', 0),
            'n_entities': result.get('n_entities', 0),
            'r_squared': result.get('r_squared', np.nan),
            'r_squared_within': result.get('r_squared_within', np.nan),
            'f_statistic': result.get('f_statistic', np.nan)
        }
        
        # æå–å…³é”®ç³»æ•°
        coefficients = result.get('coefficients', {})
        std_errors = result.get('std_errors', {})
        p_values = result.get('p_values', {})
        
        # å®šä¹‰å…³é”®å˜é‡
        key_vars = ['node_dli_us', 'ovi', 'ovi_lag1', 'us_prod_shock', 'us_prod_shock_x_ovi_lag1']
        
        for var in key_vars:
            row_data[f'{var}_coef'] = coefficients.get(var, np.nan)
            row_data[f'{var}_se'] = std_errors.get(var, np.nan)
            row_data[f'{var}_pvalue'] = p_values.get(var, np.nan)
            
            # è®¡ç®—æ˜¾è‘—æ€§æ˜Ÿå·
            p_val = p_values.get(var, np.nan)
            if pd.isna(p_val):
                row_data[f'{var}_significance'] = ''
            elif p_val < 0.01:
                row_data[f'{var}_significance'] = '***'
            elif p_val < 0.05:
                row_data[f'{var}_significance'] = '**'
            elif p_val < 0.10:
                row_data[f'{var}_significance'] = '*'
            else:
                row_data[f'{var}_significance'] = ''
        
        return row_data
    
    def _extract_horizon_row(self, model_name: str, horizon_key: str, horizon_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä»å±€éƒ¨æŠ•å½±æ¨¡å‹çš„å•æœŸç»“æœä¸­æå–ä¸€è¡Œæ•°æ®
        
        Args:
            model_name: æ¨¡å‹åç§°
            horizon_key: æœŸæ•°æ ‡è¯†
            horizon_result: è¯¥æœŸç»“æœ
            
        Returns:
            è¡Œæ•°æ®å­—å…¸
        """
        model_config = self.config.analysis.RESEARCH_MODELS.get(model_name, {})
        
        row_data = {
            'model_name': f"{model_name}_{horizon_key}",
            'model_description': f"{model_config.get('name', model_name)} - {horizon_key}",
            'chapter': model_config.get('chapter', 'N/A'),
            'method': 'local_projection',
            'status': 'success',
            'status_message': f'å±€éƒ¨æŠ•å½±ä¼°è®¡æˆåŠŸ - {horizon_key}',
            'formula': f"Î”vul_us(t+{horizon_result.get('horizon', 0)}) ~ us_prod_shock(t) * ovi_lag1(t-1) + Controls",
            'n_obs': horizon_result.get('n_obs', 0),
            'n_entities': 0,  # å±€éƒ¨æŠ•å½±ç»“æœä¸­å¯èƒ½æ²¡æœ‰è¿™ä¸ªä¿¡æ¯
            'r_squared': horizon_result.get('r_squared', np.nan),
            'r_squared_within': np.nan,  # å±€éƒ¨æŠ•å½±é€šå¸¸æ²¡æœ‰within RÂ²
            'f_statistic': np.nan,
            'horizon': horizon_result.get('horizon', 0)
        }
        
        # æå–ç³»æ•°
        coefficients = horizon_result.get('coefficients', {})
        std_errors = horizon_result.get('std_errors', {})
        p_values = horizon_result.get('p_values', {})
        
        key_vars = ['us_prod_shock', 'ovi_lag1', 'us_prod_shock_x_ovi_lag1']
        
        for var in key_vars:
            row_data[f'{var}_coef'] = coefficients.get(var, np.nan)
            row_data[f'{var}_se'] = std_errors.get(var, np.nan)
            row_data[f'{var}_pvalue'] = p_values.get(var, np.nan)
            
            # æ˜¾è‘—æ€§æ˜Ÿå·
            p_val = p_values.get(var, np.nan)
            if pd.isna(p_val):
                row_data[f'{var}_significance'] = ''
            elif p_val < 0.01:
                row_data[f'{var}_significance'] = '***'
            elif p_val < 0.05:
                row_data[f'{var}_significance'] = '**'
            elif p_val < 0.10:
                row_data[f'{var}_significance'] = '*'
            else:
                row_data[f'{var}_significance'] = ''
        
        return row_data
    
    def _create_empty_row(self) -> Dict[str, Any]:
        """
        åˆ›å»ºç©ºç»“æœè¡Œ
        
        Returns:
            ç©ºè¡Œæ•°æ®å­—å…¸
        """
        return {
            'model_name': 'no_models_run',
            'model_description': 'æ²¡æœ‰è¿è¡Œä»»ä½•æ¨¡å‹',
            'chapter': 'N/A',
            'method': 'N/A',
            'status': 'no_data',
            'status_message': 'æ•°æ®ä¸å¯ç”¨ï¼Œæœªè¿è¡Œä»»ä½•æ¨¡å‹',
            'formula': 'N/A',
            'n_obs': 0,
            'n_entities': 0,
            'r_squared': np.nan,
            'r_squared_within': np.nan,
            'f_statistic': np.nan,
            **{f'{var}_{stat}': np.nan for var in ['node_dli_us', 'ovi', 'ovi_lag1', 'us_prod_shock', 'us_prod_shock_x_ovi_lag1'] 
               for stat in ['coef', 'se', 'pvalue']},
            **{f'{var}_significance': '' for var in ['node_dli_us', 'ovi', 'ovi_lag1', 'us_prod_shock', 'us_prod_shock_x_ovi_lag1']}
        }
    
    def generate_analysis_report_md(self, model_results: Dict[str, Any], data_summary: Optional[Dict] = None) -> Path:
        """
        ç”ŸæˆMarkdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š
        
        Args:
            model_results: æ¨¡å‹ç»“æœå­—å…¸
            data_summary: æ•°æ®æ‘˜è¦ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Markdownæ–‡ä»¶è·¯å¾„
        """
        logger.info("ğŸ“„ ç”ŸæˆMarkdownåˆ†ææŠ¥å‘Š...")
        
        # å¼€å§‹æ„å»ºæŠ¥å‘Šå†…å®¹
        report_content = self._build_markdown_report(model_results, data_summary)
        
        # ä¿å­˜Markdownæ–‡ä»¶
        md_path = self.output_dir / "analysis_report.md"
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"âœ… MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: {md_path}")
        
        return md_path
    
    def _build_markdown_report(self, model_results: Dict[str, Any], data_summary: Optional[Dict] = None) -> str:
        """
        æ„å»ºMarkdownæŠ¥å‘Šå†…å®¹
        
        Args:
            model_results: æ¨¡å‹ç»“æœå­—å…¸
            data_summary: æ•°æ®æ‘˜è¦
            
        Returns:
            MarkdownæŠ¥å‘Šæ–‡æœ¬
        """
        report_lines = [
            "# è®¡é‡ç»æµå­¦åˆ†ææŠ¥å‘Š",
            "## Econometric Analysis Report",
            "",
            f"**ç”Ÿæˆæ—¶é—´**: {self.timestamp}",
            f"**æ¨¡å—ç‰ˆæœ¬**: 09_econometric_analysis v1.0",
            "",
            "---",
            ""
        ]
        
        # 1. æ‰§è¡Œæ‘˜è¦
        report_lines.extend(self._build_executive_summary(model_results))
        
        # 2. æ•°æ®æ¦‚å†µ
        if data_summary:
            report_lines.extend(self._build_data_overview(data_summary))
        
        # 3. æ¨¡å‹ç»“æœ
        report_lines.extend(self._build_model_results_section(model_results))
        
        # 4. ç¨³å¥æ€§æ£€éªŒï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        report_lines.extend(self._build_robustness_section(model_results))
        
        # 5. ç»“è®ºä¸æ”¿ç­–å«ä¹‰
        report_lines.extend(self._build_conclusions_section(model_results))
        
        # 6. æŠ€æœ¯é™„å½•
        report_lines.extend(self._build_technical_appendix(model_results))
        
        return "\n".join(report_lines)
    
    def _build_executive_summary(self, model_results: Dict[str, Any]) -> List[str]:
        """æ„å»ºæ‰§è¡Œæ‘˜è¦éƒ¨åˆ†"""
        section = [
            "## 1. æ‰§è¡Œæ‘˜è¦ (Executive Summary)",
            ""
        ]
        
        if 'overview' in model_results:
            overview = model_results['overview']
            section.extend([
                f"æœ¬ç ”ç©¶è¿è¡Œäº† **{overview.get('total_models', 0)}** ä¸ªæ ¸å¿ƒè®¡é‡æ¨¡å‹ï¼Œå…¶ä¸­:",
                f"- âœ… æˆåŠŸä¼°è®¡: {overview.get('completed_models', 0)} ä¸ª",
                f"- âŒ ä¼°è®¡å¤±è´¥: {overview.get('failed_models', 0)} ä¸ª",
                f"- ğŸ“Š æ•°æ®å¯ç”¨æ€§: {'æ˜¯' if overview.get('data_available', False) else 'å¦'}",
                ""
            ])
            
            if overview.get('completed_models', 0) == 0:
                section.extend([
                    "âš ï¸ **é‡è¦æç¤º**: ç”±äºæ•°æ®ä¸å¯ç”¨æˆ–ä¸å®Œæ•´ï¼Œæ‰€æœ‰æ¨¡å‹ä¼°è®¡å‡å¤±è´¥ã€‚",
                    "è¿™é€šå¸¸è¡¨æ˜08æ¨¡å—çš„æ•°æ®æ„å»ºè¿‡ç¨‹å°šæœªå®Œæˆæˆ–å­˜åœ¨é—®é¢˜ã€‚",
                    "å»ºè®®æ£€æŸ¥æ•°æ®æ„å»ºæµç¨‹åé‡æ–°è¿è¡Œåˆ†æã€‚",
                    ""
                ])
        else:
            section.extend([
                "âš ï¸ **æ•°æ®çŠ¶æ€**: æ¨¡å‹ç»“æœä¸å¯ç”¨ï¼Œå¯èƒ½ç”±äºæ•°æ®ç¼ºå¤±æˆ–æ¨¡å—è¿è¡Œå¼‚å¸¸ã€‚",
                ""
            ])
        
        section.extend([
            "### 1.1 ç ”ç©¶æ¨¡å‹æ¦‚è§ˆ",
            "",
            "| æ¨¡å‹ | ç ”ç©¶é—®é¢˜ | æ–¹æ³• | çŠ¶æ€ |",
            "|------|----------|------|------|"
        ])
        
        models_dict = model_results.get('models', {})
        for model_name, result in models_dict.items():
            model_config = self.config.analysis.RESEARCH_MODELS.get(model_name, {})
            status_emoji = "âœ…" if result.get('status') == 'success' else "âŒ"
            section.append(f"| {model_config.get('name', model_name)} | {model_config.get('description', 'N/A')} | {result.get('model_type', 'N/A')} | {status_emoji} {result.get('status', 'unknown')} |")
        
        section.extend(["", "---", ""])
        
        return section
    
    def _build_data_overview(self, data_summary: Dict) -> List[str]:
        """æ„å»ºæ•°æ®æ¦‚è§ˆéƒ¨åˆ†"""
        section = [
            "## 2. æ•°æ®æ¦‚è§ˆ (Data Overview)",
            ""
        ]
        
        if 'summary' in data_summary:
            summary = data_summary['summary']
            section.extend([
                "### 2.1 åŸºç¡€ç»Ÿè®¡",
                "",
                f"- **æ€»è¡Œæ•°**: {summary.get('total_rows', 0):,}",
                f"- **æ€»åˆ—æ•°**: {summary.get('total_cols', 0)}",
                f"- **å¹´ä»½èŒƒå›´**: {summary.get('year_range', 'N/A')}",
                f"- **å›½å®¶æ•°é‡**: {summary.get('countries', 0)}",
                f"- **æ•°æ®çŠ¶æ€**: {summary.get('data_status', 'unknown')}",
                ""
            ])
            
            # å…³é”®å˜é‡å¯ç”¨æ€§
            key_vars = summary.get('key_variables_available', [])
            if key_vars:
                section.extend([
                    "### 2.2 å…³é”®å˜é‡å¯ç”¨æ€§",
                    ""
                ])
                for var_info in key_vars:
                    section.append(f"- {var_info}")
                section.append("")
            else:
                section.extend([
                    "### 2.2 å…³é”®å˜é‡å¯ç”¨æ€§",
                    "",
                    "âŒ **å…³é”®ç ”ç©¶å˜é‡å‡ä¸å¯ç”¨**",
                    "",
                    "æ ¸å¿ƒå˜é‡ (node_dli_us, vul_us, ovi, us_prod_shock) æ•°æ®ç¼ºå¤±æˆ–å…¨ä¸ºç©ºå€¼ã€‚",
                    "å»ºè®®æ£€æŸ¥08_variable_constructionæ¨¡å—çš„è¿è¡ŒçŠ¶æ€ã€‚",
                    ""
                ])
        
        if 'validation' in data_summary:
            validation = data_summary['validation']
            section.extend([
                "### 2.3 æ•°æ®éªŒè¯ç»“æœ",
                "",
                f"- **é€‚åˆè®¡é‡åˆ†æ**: {'æ˜¯' if validation.get('is_valid_for_analysis', False) else 'å¦'}",
                ""
            ])
            
            issues = validation.get('issues', [])
            if issues:
                section.extend(["**å‘ç°çš„é—®é¢˜**:", ""])
                for issue in issues:
                    section.append(f"- âŒ {issue}")
                section.append("")
            
            recommendations = validation.get('recommendations', [])
            if recommendations:
                section.extend(["**å»ºè®®**:", ""])
                for rec in recommendations:
                    section.append(f"- ğŸ’¡ {rec}")
                section.append("")
        
        section.extend(["---", ""])
        return section
    
    def _build_model_results_section(self, model_results: Dict[str, Any]) -> List[str]:
        """æ„å»ºæ¨¡å‹ç»“æœéƒ¨åˆ†"""
        section = [
            "## 3. æ¨¡å‹ç»“æœ (Model Results)",
            ""
        ]
        
        models_dict = model_results.get('models', {})
        
        if not models_dict:
            section.extend([
                "âš ï¸ **æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ç»“æœ**",
                "",
                "åŸå› å¯èƒ½åŒ…æ‹¬:",
                "- åˆ†ææ•°æ®ä¸å¯ç”¨æˆ–ä¸ºç©º",
                "- å…³é”®å˜é‡ç¼ºå¤±",
                "- æ¨¡å‹ä¼°è®¡è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯",
                ""
            ])
            return section
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºè¯¦ç»†ç»“æœ
        for i, (model_name, result) in enumerate(models_dict.items(), 1):
            model_config = self.config.analysis.RESEARCH_MODELS.get(model_name, {})
            
            section.extend([
                f"### 3.{i} {model_config.get('name', model_name)}",
                "",
                f"**ç ”ç©¶é—®é¢˜**: {model_config.get('description', 'N/A')}",
                f"**ä¼°è®¡æ–¹æ³•**: {result.get('model_type', 'N/A')}",
                f"**çŠ¶æ€**: {result.get('status', 'unknown')}",
                ""
            ])
            
            if result.get('status') == 'success':
                section.extend(self._format_successful_model_result(result))
            else:
                section.extend([
                    f"âŒ **ä¼°è®¡å¤±è´¥**: {result.get('status_message', 'æœªçŸ¥é”™è¯¯')}",
                    "",
                    "**å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ**:",
                    "- æ£€æŸ¥æ•°æ®çš„å®Œæ•´æ€§å’Œè´¨é‡",
                    "- ç¡®è®¤æ‰€éœ€å˜é‡éƒ½å·²æ­£ç¡®æ„å»º",
                    "- æ£€æŸ¥æ ·æœ¬é‡æ˜¯å¦æ»¡è¶³æœ€å°‘è§‚æµ‹è¦æ±‚",
                    ""
                ])
        
        section.extend(["---", ""])
        return section
    
    def _format_successful_model_result(self, result: Dict[str, Any]) -> List[str]:
        """æ ¼å¼åŒ–æˆåŠŸçš„æ¨¡å‹ç»“æœ"""
        section = []
        
        # åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
        section.extend([
            "#### åŸºç¡€ç»Ÿè®¡",
            "",
            f"- **è§‚æµ‹æ•°**: {result.get('n_obs', 0):,}",
            f"- **ä¸ªä½“æ•°**: {result.get('n_entities', 0)}",
            f"- **RÂ²**: {result.get('r_squared', np.nan):.4f}" if not pd.isna(result.get('r_squared', np.nan)) else "- **RÂ²**: N/A",
            ""
        ])
        
        # å…³é”®ç³»æ•°è¡¨æ ¼
        coefficients = result.get('coefficients', {})
        std_errors = result.get('std_errors', {})
        p_values = result.get('p_values', {})
        
        if coefficients:
            section.extend([
                "#### å…³é”®ç³»æ•°ä¼°è®¡",
                "",
                "| å˜é‡ | ç³»æ•° | æ ‡å‡†è¯¯ | På€¼ | æ˜¾è‘—æ€§ |",
                "|------|------|--------|-----|--------|"
            ])
            
            # åªå±•ç¤ºå…³é”®å˜é‡
            key_vars = ['node_dli_us', 'ovi', 'ovi_lag1', 'us_prod_shock', 'us_prod_shock_x_ovi_lag1']
            
            for var in key_vars:
                if var in coefficients:
                    coef = coefficients[var]
                    se = std_errors.get(var, np.nan)
                    p_val = p_values.get(var, np.nan)
                    
                    # æ ¼å¼åŒ–ç³»æ•°
                    coef_str = f"{coef:.4f}" if not pd.isna(coef) else "N/A"
                    se_str = f"({se:.4f})" if not pd.isna(se) else "(N/A)"
                    p_str = f"{p_val:.3f}" if not pd.isna(p_val) else "N/A"
                    
                    # æ˜¾è‘—æ€§æ˜Ÿå·
                    if not pd.isna(p_val):
                        if p_val < 0.01:
                            sig = "***"
                        elif p_val < 0.05:
                            sig = "**"
                        elif p_val < 0.10:
                            sig = "*"
                        else:
                            sig = ""
                    else:
                        sig = ""
                    
                    section.append(f"| {var} | {coef_str} | {se_str} | {p_str} | {sig} |")
            
            section.extend([
                "",
                "*æ³¨: *** p<0.01, ** p<0.05, * p<0.10*",
                ""
            ])
        
        # å¤„ç†å±€éƒ¨æŠ•å½±çš„ç‰¹æ®Šæƒ…å†µ
        if 'horizon_results' in result:
            section.extend([
                "#### å±€éƒ¨æŠ•å½±ç»“æœ",
                "",
                f"ä¼°è®¡äº† {len(result['horizon_results'])} ä¸ªé¢„æµ‹æœŸçš„è„‰å†²å“åº”ã€‚",
                ""
            ])
        
        return section
    
    def _build_robustness_section(self, model_results: Dict[str, Any]) -> List[str]:
        """æ„å»ºç¨³å¥æ€§æ£€éªŒéƒ¨åˆ†"""
        return [
            "## 4. ç¨³å¥æ€§æ£€éªŒ (Robustness Checks)",
            "",
            "âš ï¸ **ç¨³å¥æ€§æ£€éªŒåŠŸèƒ½å¾…å®ç°**",
            "",
            "è®¡åˆ’åŒ…å«çš„ç¨³å¥æ€§æ£€éªŒ:",
            "- æ’é™¤å¼‚å¸¸å€¼é‡æ–°ä¼°è®¡",
            "- å˜é‡ç¼©å°¾å¤„ç†",
            "- æ›¿ä»£æ§åˆ¶å˜é‡",
            "- åˆ†æ—¶æœŸå­æ ·æœ¬åˆ†æ",
            "- Bootstrapæ¨æ–­",
            "",
            "---",
            ""
        ]
    
    def _build_conclusions_section(self, model_results: Dict[str, Any]) -> List[str]:
        """æ„å»ºç»“è®ºéƒ¨åˆ†"""
        section = [
            "## 5. ç»“è®ºä¸æ”¿ç­–å«ä¹‰ (Conclusions & Policy Implications)",
            ""
        ]
        
        overview = model_results.get('overview', {})
        completed = overview.get('completed_models', 0)
        total = overview.get('total_models', 0)
        
        if completed == 0:
            section.extend([
                "### 5.1 ä¸»è¦å‘ç°",
                "",
                "âŒ **ç”±äºæ•°æ®ä¸å¯ç”¨ï¼Œæš‚æ—¶æ— æ³•å¾—å‡ºå®è´¨æ€§ç»“è®ºã€‚**",
                "",
                "å½“å‰çŠ¶æ€è¡¨æ˜:",
                "- 08_variable_constructionæ¨¡å—çš„æ•°æ®æ„å»ºè¿‡ç¨‹å¯èƒ½å°šæœªå®Œæˆ",
                "- éœ€è¦ç­‰å¾…æ ¸å¿ƒç ”ç©¶å˜é‡ (Node-DLI, Vul_US, OVIç­‰) çš„æ•°æ®å¡«å……",
                "- åˆ†ææ¡†æ¶å·²å°±ç»ªï¼Œä¸€æ—¦æ•°æ®åˆ°ä½å³å¯äº§å‡ºç»“æœ",
                "",
                "### 5.2 ä¸‹ä¸€æ­¥å·¥ä½œ",
                "",
                "1. **æ•°æ®å®Œå–„**: ç¡®ä¿08æ¨¡å—æˆåŠŸç”Ÿæˆå®Œæ•´çš„analytical_panel.csv",
                "2. **æ¨¡å‹éªŒè¯**: æ•°æ®åˆ°ä½åé‡æ–°è¿è¡Œæœ¬æ¨¡å—éªŒè¯æ¨¡å‹æ¡†æ¶",
                "3. **ç»“æœè§£è¯»**: åŸºäºå®é™…ä¼°è®¡ç»“æœè§£è¯»ç»æµå­¦å«ä¹‰",
                "4. **ç¨³å¥æ€§æ£€éªŒ**: å®æ–½å¤šç§ç¨³å¥æ€§æ£€éªŒç¡®ä¿ç»“æœå¯é ",
                ""
            ])
        else:
            section.extend([
                "### 5.1 ä¸»è¦å‘ç°",
                "",
                f"åŸºäº {completed}/{total} ä¸ªæˆåŠŸä¼°è®¡çš„æ¨¡å‹ï¼Œä¸»è¦å‘ç°åŒ…æ‹¬:",
                "",
                "**æ ¸å¿ƒç»“æœ** (å¾…æ•°æ®å®Œå–„åæ›´æ–°):",
                "- DLIä¸èƒ½æºè„†å¼±æ€§çš„å…³è”æ€§",
                "- OVIå¯¹DLIçš„å› æœæ•ˆåº”",
                "- ç¾å›½äº§é‡å†²å‡»çš„åŠ¨æ€å½±å“",
                "",
                "### 5.2 æ”¿ç­–å«ä¹‰",
                "",
                "**èƒ½æºå®‰å…¨æ”¿ç­–å»ºè®®** (åŸºäºåˆ†ææ¡†æ¶):",
                "- å¤šå…ƒåŒ–èƒ½æºè¿›å£æ¥æºä»¥é™ä½ä¾èµ–æ€§é”å®š",
                "- æŠ•èµ„ç‰©ç†å†—ä½™åŸºç¡€è®¾æ–½ä»¥å¢å¼ºéŸ§æ€§",
                "- å»ºç«‹æ—©æœŸé¢„è­¦æœºåˆ¶åº”å¯¹ä¾›ç»™å†²å‡»",
                ""
            ])
        
        section.extend(["---", ""])
        return section
    
    def _build_technical_appendix(self, model_results: Dict[str, Any]) -> List[str]:
        """æ„å»ºæŠ€æœ¯é™„å½•"""
        return [
            "## 6. æŠ€æœ¯é™„å½• (Technical Appendix)",
            "",
            "### 6.1 æ¨¡å‹è§„èŒƒ",
            "",
            "**æ¨¡å‹1: DLI-è„†å¼±æ€§å…³è”æ£€éªŒ**",
            "```",
            "vul_us_it = Î²â‚€ + Î²â‚ Ã— node_dli_us_it + Î²â‚‚ Ã— Controls_it + Î±_i + Î´_t + Îµ_it",
            "```",
            "",
            "**æ¨¡å‹2: OVIå› æœæ•ˆåº”**",
            "```", 
            "node_dli_us_it = Î³â‚€ + Î³â‚ Ã— ovi_i(t-1) + Î³â‚‚ Ã— Controls_it + Î±_i + Î´_t + Îµ_it",
            "```",
            "",
            "**æ¨¡å‹3: å±€éƒ¨æŠ•å½±éªŒè¯**",
            "```",
            "Î”vul_us_i(t+h) = Î¸â‚€áµ¸ + Î¸â‚áµ¸ Ã— us_prod_shock_t Ã— ovi_i(t-1) + Î¸â‚‚áµ¸ Ã— Controls_it + Î±_i + Îµ_it",
            "```",
            "",
            "### 6.2 ä¼°è®¡æ–¹æ³•",
            "",
            "- **é¢æ¿æ•°æ®**: åŒå‘å›ºå®šæ•ˆåº”æ¨¡å‹ (Two-Way Fixed Effects)",
            "- **æ ‡å‡†è¯¯**: ä¸ªä½“èšç±»ç¨³å¥æ ‡å‡†è¯¯",
            "- **å±€éƒ¨æŠ•å½±**: JordÃ  (2005) æ–¹æ³•",
            "- **è½¯ä»¶**: Python + linearmodels + statsmodels",
            "",
            "### 6.3 æ•°æ®æ¥æº",
            "",
            "- **åŸºç¡€æ•°æ®**: 08_variable_constructionæ¨¡å—è¾“å‡º",
            "- **æ—¶é—´èŒƒå›´**: 2000-2024",
            "- **å›½å®¶èŒƒå›´**: åŸºäºè´¸æ˜“ç½‘ç»œåˆ†æçš„é‡è¦èƒ½æºå›½å®¶",
            "",
            "---",
            "",
            f"*æœ¬æŠ¥å‘Šç”± 09_econometric_analysis æ¨¡å—è‡ªåŠ¨ç”Ÿæˆäº {self.timestamp}*",
            "",
            f"*Energy Network Analysis Team - Claude Code Framework*"
        ]
    
    def generate_model_diagnostics_json(self, model_results: Dict[str, Any]) -> Path:
        """
        ç”Ÿæˆæ¨¡å‹è¯Šæ–­JSONæ–‡ä»¶
        
        Args:
            model_results: æ¨¡å‹ç»“æœå­—å…¸
            
        Returns:
            JSONæ–‡ä»¶è·¯å¾„
        """
        logger.info("ğŸ”§ ç”Ÿæˆæ¨¡å‹è¯Šæ–­JSON...")
        
        diagnostics_data = {
            'timestamp': self.timestamp,
            'module_version': '09_econometric_analysis v1.0',
            'overview': model_results.get('overview', {}),
            'model_diagnostics': {}
        }
        
        models_dict = model_results.get('models', {})
        for model_name, result in models_dict.items():
            diagnostics_data['model_diagnostics'][model_name] = {
                'status': result.get('status', 'unknown'),
                'estimation_method': result.get('model_type', 'unknown'),
                'sample_size': result.get('n_obs', 0),
                'r_squared': result.get('r_squared', None),
                'diagnostics': result.get('diagnostics', {}),
                'data_available': result.get('data_available', False)
            }
        
        # ä¿å­˜JSON
        json_path = self.output_dir / "model_diagnostics.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(diagnostics_data, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"âœ… æ¨¡å‹è¯Šæ–­JSONå·²ç”Ÿæˆ: {json_path}")
        
        return json_path
    
    def generate_all_reports(self, model_results: Dict[str, Any], data_summary: Optional[Dict] = None) -> Dict[str, Path]:
        """
        ç”Ÿæˆæ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
        
        Args:
            model_results: æ¨¡å‹ç»“æœå­—å…¸
            data_summary: æ•°æ®æ‘˜è¦
            
        Returns:
            ç”Ÿæˆæ–‡ä»¶è·¯å¾„å­—å…¸
        """
        logger.info("ğŸ“š å¼€å§‹ç”Ÿæˆæ‰€æœ‰æŠ¥å‘Š...")
        
        generated_files = {}
        
        try:
            # 1. CSVç»“æœè¡¨
            generated_files['csv'] = self.generate_regression_results_csv(model_results)
        except Exception as e:
            logger.error(f"CSVæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
        
        try:
            # 2. MarkdownæŠ¥å‘Š
            generated_files['markdown'] = self.generate_analysis_report_md(model_results, data_summary)
        except Exception as e:
            logger.error(f"MarkdownæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
        
        try:
            # 3. è¯Šæ–­JSON
            generated_files['diagnostics'] = self.generate_model_diagnostics_json(model_results)
        except Exception as e:
            logger.error(f"è¯Šæ–­JSONç”Ÿæˆå¤±è´¥: {str(e)}")
        
        logger.info(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œå…± {len(generated_files)} ä¸ªæ–‡ä»¶")
        
        return generated_files


# ä¾¿æ·å‡½æ•°
def generate_reports(model_results: Dict[str, Any], data_summary: Optional[Dict] = None, output_dir: Optional[Path] = None) -> Dict[str, Path]:
    """
    ç”ŸæˆæŠ¥å‘Šçš„ä¾¿æ·å‡½æ•°
    
    Args:
        model_results: æ¨¡å‹ç»“æœå­—å…¸
        data_summary: æ•°æ®æ‘˜è¦
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        ç”Ÿæˆæ–‡ä»¶è·¯å¾„å­—å…¸
    """
    reporter = ReportGenerator(output_dir)
    return reporter.generate_all_reports(model_results, data_summary)


if __name__ == "__main__":
    # æµ‹è¯•æŠ¥å‘Šç”ŸæˆåŠŸèƒ½
    import logging
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    print("ğŸ“ 09_econometric_analysis æŠ¥å‘Šæ¨¡å—æµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•ç”¨çš„ç©ºç»“æœ
    test_results = {
        'overview': {
            'total_models': 3,
            'completed_models': 0,
            'failed_models': 3,
            'data_available': False
        },
        'models': {
            'model_1_dli_vul_association': {
                'status': 'failed',
                'status_message': 'æ•°æ®ä¸å¯ç”¨',
                'model_type': 'two_way_fixed_effects',
                'data_available': False,
                'n_obs': 0,
                'coefficients': {},
                'std_errors': {},
                'p_values': {}
            },
            'model_2_ovi_dli_causality': {
                'status': 'failed', 
                'status_message': 'æ•°æ®ä¸å¯ç”¨',
                'model_type': 'two_way_fixed_effects_lagged',
                'data_available': False,
                'n_obs': 0,
                'coefficients': {},
                'std_errors': {},
                'p_values': {}
            },
            'model_3_local_projection_validation': {
                'status': 'failed',
                'status_message': 'æ•°æ®ä¸å¯ç”¨',
                'model_type': 'local_projections',
                'data_available': False,
                'horizon_results': {}
            }
        }
    }
    
    test_data_summary = {
        'summary': {
            'total_rows': 0,
            'total_cols': 25,
            'year_range': 'N/A',
            'countries': 0,
            'key_variables_available': [],
            'data_status': 'empty'
        },
        'validation': {
            'is_valid_for_analysis': False,
            'issues': ['æ•°æ®é›†ä¸ºç©º'],
            'recommendations': ['ç­‰å¾…08æ¨¡å—ç”Ÿæˆæ•°æ®']
        }
    }
    
    # æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
    reporter = ReportGenerator()
    files = reporter.generate_all_reports(test_results, test_data_summary)
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    for report_type, file_path in files.items():
        print(f"  {report_type}: {file_path}")
    
    print("\nğŸ‰ æŠ¥å‘Šæ¨¡å—æµ‹è¯•å®Œæˆ!")