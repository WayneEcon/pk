#!/usr/bin/env python3
"""
å› æœéªŒè¯åˆ†æå¯è§†åŒ–æ¨¡å— (Causal Validation Visualization Module)
=============================================================

æœ¬æ¨¡å—æä¾›å› æœåˆ†æç»“æœçš„ä¸“ä¸šçº§å¯è§†åŒ–åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. éŸ§æ€§æŒ‡æ ‡æ—¶é—´åºåˆ—å›¾
2. å› æœå…³ç³»è¯Šæ–­å›¾è¡¨
3. å›å½’è¯Šæ–­å›¾
4. ç½‘ç»œéŸ§æ€§åˆ†å¸ƒå›¾
5. DLIä¸éŸ§æ€§å…³ç³»æ•£ç‚¹å›¾

ä½œè€…ï¼šEnergy Network Analysis Team
ç‰ˆæœ¬ï¼šv1.0 (Academic Visualization Edition)
"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
import logging
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibå­—ä½“æ”¯æŒä¸­æ–‡
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®seabornæ ·å¼
sns.set_style("whitegrid")
sns.set_palette("husl")

logger = logging.getLogger(__name__)

class CausalVisualization:
    """å› æœåˆ†æå¯è§†åŒ–ç±»"""
    
    def __init__(self, output_dir: str = "outputs"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºå›¾è¡¨å­ç›®å½•
        self.figures_dir = self.output_dir / "figures"
        self.figures_dir.mkdir(exist_ok=True)
        
        logger.info(f"ğŸ“Š åˆå§‹åŒ–å¯è§†åŒ–æ¨¡å—ï¼Œè¾“å‡ºç›®å½•: {self.figures_dir}")
    
    def plot_resilience_time_series(self, resilience_data: pd.DataFrame, 
                                  countries: List[str] = None,
                                  save_path: str = None) -> str:
        """ç»˜åˆ¶éŸ§æ€§æŒ‡æ ‡æ—¶é—´åºåˆ—å›¾"""
        
        if countries is None:
            countries = ['USA', 'CHN', 'RUS', 'SAU', 'DEU', 'JPN']
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('ç½‘ç»œéŸ§æ€§æŒ‡æ ‡æ—¶é—´åºåˆ—åˆ†æ\nNetwork Resilience Indicators Time Series', 
                    fontsize=16, fontweight='bold')
        
        # 1. ç»¼åˆéŸ§æ€§æŒ‡æ ‡
        ax1 = axes[0, 0]
        for country in countries:
            country_data = resilience_data[resilience_data['country'] == country]
            if not country_data.empty:
                ax1.plot(country_data['year'], country_data['comprehensive_resilience'], 
                        marker='o', label=country, linewidth=2, markersize=4)
        
        ax1.set_title('ç»¼åˆéŸ§æ€§æŒ‡æ ‡ (Comprehensive Resilience)', fontweight='bold')
        ax1.set_xlabel('å¹´ä»½ (Year)')
        ax1.set_ylabel('éŸ§æ€§å¾—åˆ† (Resilience Score)')
        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax1.grid(True, alpha=0.3)
        
        # 2. æ‹“æ‰‘éŸ§æ€§æŒ‡æ ‡
        ax2 = axes[0, 1]
        for country in countries:
            country_data = resilience_data[resilience_data['country'] == country]
            if not country_data.empty:
                ax2.plot(country_data['year'], country_data['topological_resilience_avg'], 
                        marker='s', label=country, linewidth=2, markersize=4)
        
        ax2.set_title('æ‹“æ‰‘éŸ§æ€§æŒ‡æ ‡ (Topological Resilience)', fontweight='bold')
        ax2.set_xlabel('å¹´ä»½ (Year)')
        ax2.set_ylabel('æ‹“æ‰‘éŸ§æ€§ (Topological Resilience)')
        ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax2.grid(True, alpha=0.3)
        
        # 3. ä¾›åº”å¸æ”¶ç‡
        ax3 = axes[1, 0]
        for country in countries:
            country_data = resilience_data[resilience_data['country'] == country]
            if not country_data.empty:
                ax3.plot(country_data['year'], country_data['supply_absorption_rate'], 
                        marker='^', label=country, linewidth=2, markersize=4)
        
        ax3.set_title('ä¾›åº”å¸æ”¶ç‡ (Supply Absorption Rate)', fontweight='bold')
        ax3.set_xlabel('å¹´ä»½ (Year)')
        ax3.set_ylabel('å¸æ”¶ç‡ (Absorption Rate)')
        ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax3.grid(True, alpha=0.3)
        
        # 4. ç½‘ç»œä½ç½®ç¨³å®šæ€§
        ax4 = axes[1, 1]
        for country in countries:
            country_data = resilience_data[resilience_data['country'] == country]
            if not country_data.empty:
                ax4.plot(country_data['year'], country_data['network_position_stability'], 
                        marker='d', label=country, linewidth=2, markersize=4)
        
        ax4.set_title('ç½‘ç»œä½ç½®ç¨³å®šæ€§ (Network Position Stability)', fontweight='bold')
        ax4.set_xlabel('å¹´ä»½ (Year)')
        ax4.set_ylabel('ç¨³å®šæ€§ (Stability)')
        ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path is None:
            save_path = self.figures_dir / "resilience_time_series.png"
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        logger.info(f"âœ… éŸ§æ€§æ—¶é—´åºåˆ—å›¾å·²ä¿å­˜: {save_path}")
        return str(save_path)
    
    def plot_dli_resilience_scatter(self, merged_data: pd.DataFrame,
                                   save_path: str = None) -> str:
        """ç»˜åˆ¶DLIä¸éŸ§æ€§å…³ç³»æ•£ç‚¹å›¾"""
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('DLIä¸ç½‘ç»œéŸ§æ€§å…³ç³»åˆ†æ\nDLI vs Network Resilience Analysis', 
                    fontsize=16, fontweight='bold')
        
        # 1. DLI vs ç»¼åˆéŸ§æ€§
        ax1 = axes[0, 0]
        countries = merged_data['country'].unique()
        colors = plt.cm.Set3(np.linspace(0, 1, len(countries)))
        
        for i, country in enumerate(countries):
            country_data = merged_data[merged_data['country'] == country]
            ax1.scatter(country_data['dli_score'], country_data['comprehensive_resilience'],
                       alpha=0.7, s=50, label=country, color=colors[i])
        
        # æ·»åŠ å›å½’çº¿
        z = np.polyfit(merged_data['dli_score'], merged_data['comprehensive_resilience'], 1)
        p = np.poly1d(z)
        x_reg = np.linspace(merged_data['dli_score'].min(), merged_data['dli_score'].max(), 100)
        ax1.plot(x_reg, p(x_reg), "r--", alpha=0.8, linewidth=2)
        
        # è®¡ç®—ç›¸å…³ç³»æ•°
        corr = merged_data[['dli_score', 'comprehensive_resilience']].corr().iloc[0, 1]
        ax1.text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {corr:.3f}', transform=ax1.transAxes, 
                bbox=dict(boxstyle="round", facecolor='wheat', alpha=0.5))
        
        ax1.set_xlabel('DLIå¾—åˆ† (DLI Score)')
        ax1.set_ylabel('ç»¼åˆéŸ§æ€§ (Comprehensive Resilience)')
        ax1.set_title('DLI vs ç»¼åˆéŸ§æ€§', fontweight='bold')
        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax1.grid(True, alpha=0.3)
        
        # 2. DLI vs æ‹“æ‰‘éŸ§æ€§
        ax2 = axes[0, 1]
        for i, country in enumerate(countries):
            country_data = merged_data[merged_data['country'] == country]
            ax2.scatter(country_data['dli_score'], country_data['topological_resilience_avg'],
                       alpha=0.7, s=50, label=country, color=colors[i])
        
        z2 = np.polyfit(merged_data['dli_score'], merged_data['topological_resilience_avg'], 1)
        p2 = np.poly1d(z2)
        ax2.plot(x_reg, p2(x_reg), "r--", alpha=0.8, linewidth=2)
        
        corr2 = merged_data[['dli_score', 'topological_resilience_avg']].corr().iloc[0, 1]
        ax2.text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {corr2:.3f}', transform=ax2.transAxes,
                bbox=dict(boxstyle="round", facecolor='wheat', alpha=0.5))
        
        ax2.set_xlabel('DLIå¾—åˆ† (DLI Score)')
        ax2.set_ylabel('æ‹“æ‰‘éŸ§æ€§ (Topological Resilience)')
        ax2.set_title('DLI vs æ‹“æ‰‘éŸ§æ€§', fontweight='bold')
        ax2.grid(True, alpha=0.3)
        
        # 3. DLI vs ä¾›åº”å¸æ”¶ç‡
        ax3 = axes[1, 0]
        for i, country in enumerate(countries):
            country_data = merged_data[merged_data['country'] == country]
            ax3.scatter(country_data['dli_score'], country_data['supply_absorption_rate'],
                       alpha=0.7, s=50, label=country, color=colors[i])
        
        z3 = np.polyfit(merged_data['dli_score'], merged_data['supply_absorption_rate'], 1)
        p3 = np.poly1d(z3)
        ax3.plot(x_reg, p3(x_reg), "r--", alpha=0.8, linewidth=2)
        
        corr3 = merged_data[['dli_score', 'supply_absorption_rate']].corr().iloc[0, 1]
        ax3.text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {corr3:.3f}', transform=ax3.transAxes,
                bbox=dict(boxstyle="round", facecolor='wheat', alpha=0.5))
        
        ax3.set_xlabel('DLIå¾—åˆ† (DLI Score)')
        ax3.set_ylabel('ä¾›åº”å¸æ”¶ç‡ (Supply Absorption Rate)')
        ax3.set_title('DLI vs ä¾›åº”å¸æ”¶ç‡', fontweight='bold')
        ax3.grid(True, alpha=0.3)
        
        # 4. å¹´ä»½åˆ†å¸ƒçƒ­åŠ›å›¾
        ax4 = axes[1, 1]
        pivot_data = merged_data.pivot_table(values='comprehensive_resilience', 
                                           index='country', columns='year', 
                                           aggfunc='mean')
        
        sns.heatmap(pivot_data, ax=ax4, cmap='RdYlBu_r', cbar=True, 
                   fmt='.3f', square=False, linewidths=0.5)
        ax4.set_title('ç»¼åˆéŸ§æ€§å¹´åº¦çƒ­åŠ›å›¾', fontweight='bold')
        ax4.set_xlabel('å¹´ä»½ (Year)')
        ax4.set_ylabel('å›½å®¶ (Country)')
        
        plt.tight_layout()
        
        if save_path is None:
            save_path = self.figures_dir / "dli_resilience_scatter.png"
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        logger.info(f"âœ… DLI-éŸ§æ€§æ•£ç‚¹å›¾å·²ä¿å­˜: {save_path}")
        return str(save_path)
    
    def plot_regression_diagnostics(self, causal_results: Dict[str, Any],
                                   save_path: str = None) -> str:
        """ç»˜åˆ¶å›å½’è¯Šæ–­å›¾"""
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('å›å½’æ¨¡å‹è¯Šæ–­å›¾è¡¨\nRegression Model Diagnostics', 
                    fontsize=16, fontweight='bold')
        
        # æå–å›å½’ç»“æœ
        try:
            fe_results = causal_results.get('fixed_effects_results', {})
            iv_results = causal_results.get('instrumental_variables_results', {})
            
            # 1. ç³»æ•°æ¯”è¾ƒå›¾
            ax1 = axes[0, 0]
            models = []
            coefficients = []
            conf_intervals = []
            
            if 'coefficient' in fe_results:
                models.append('Fixed Effects')
                coefficients.append(fe_results['coefficient'])
                ci_lower = fe_results['coefficient'] - 1.96 * fe_results.get('std_error', 0)
                ci_upper = fe_results['coefficient'] + 1.96 * fe_results.get('std_error', 0)
                conf_intervals.append((ci_lower, ci_upper))
            
            if 'coefficient' in iv_results:
                models.append('IV (2SLS)')
                coefficients.append(iv_results['coefficient'])
                ci_lower = iv_results['coefficient'] - 1.96 * iv_results.get('std_error', 0)
                ci_upper = iv_results['coefficient'] + 1.96 * iv_results.get('std_error', 0)
                conf_intervals.append((ci_lower, ci_upper))
            
            if models:
                y_pos = np.arange(len(models))
                ax1.barh(y_pos, coefficients, alpha=0.7, color=['#1f77b4', '#ff7f0e'])
                
                # æ·»åŠ ç½®ä¿¡åŒºé—´
                for i, (lower, upper) in enumerate(conf_intervals):
                    ax1.plot([lower, upper], [i, i], 'k-', linewidth=2)
                    ax1.plot([lower, lower], [i-0.1, i+0.1], 'k-', linewidth=2)
                    ax1.plot([upper, upper], [i-0.1, i+0.1], 'k-', linewidth=2)
                
                ax1.axvline(x=0, color='red', linestyle='--', alpha=0.7)
                ax1.set_yticks(y_pos)
                ax1.set_yticklabels(models)
                ax1.set_xlabel('ç³»æ•°ä¼°è®¡å€¼ (Coefficient Estimate)')
                ax1.set_title('æ¨¡å‹ç³»æ•°æ¯”è¾ƒ', fontweight='bold')
                ax1.grid(True, alpha=0.3)
            
            # 2. æ˜¾è‘—æ€§æµ‹è¯•ç»“æœ
            ax2 = axes[0, 1]
            if models:
                p_values = []
                if 'p_value' in fe_results:
                    p_values.append(fe_results['p_value'])
                if 'p_value' in iv_results:
                    p_values.append(iv_results['p_value'])
                
                colors = ['red' if p < 0.05 else 'gray' for p in p_values]
                bars = ax2.bar(models, p_values, color=colors, alpha=0.7)
                
                ax2.axhline(y=0.05, color='red', linestyle='--', label='Î±=0.05')
                ax2.axhline(y=0.01, color='orange', linestyle='--', label='Î±=0.01')
                ax2.set_ylabel('På€¼ (P-value)')
                ax2.set_title('ç»Ÿè®¡æ˜¾è‘—æ€§æµ‹è¯•', fontweight='bold')
                ax2.legend()
                ax2.grid(True, alpha=0.3)
                
                # æ·»åŠ på€¼æ ‡ç­¾
                for bar, p_val in zip(bars, p_values):
                    height = bar.get_height()
                    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                            f'{p_val:.4f}', ha='center', va='bottom')
            
            # 3. æ¨¡å‹æ‹Ÿåˆåº¦æ¯”è¾ƒ
            ax3 = axes[0, 2]
            if models:
                r_squared_values = []
                if 'r_squared' in fe_results:
                    r_squared_values.append(fe_results['r_squared'])
                if 'r_squared' in iv_results:
                    r_squared_values.append(iv_results['r_squared'])
                
                if r_squared_values:
                    ax3.bar(models, r_squared_values, color=['#2ca02c', '#d62728'], alpha=0.7)
                    ax3.set_ylabel('RÂ² å€¼')
                    ax3.set_title('æ¨¡å‹æ‹Ÿåˆåº¦', fontweight='bold')
                    ax3.set_ylim(0, 1)
                    ax3.grid(True, alpha=0.3)
                    
                    # æ·»åŠ RÂ²æ ‡ç­¾
                    for i, r2 in enumerate(r_squared_values):
                        ax3.text(i, r2 + 0.02, f'{r2:.3f}', ha='center', va='bottom')
            
            # 4. è¯Šæ–­ç»Ÿè®¡
            ax4 = axes[1, 0]
            diagnostics = causal_results.get('diagnostics', {})
            
            diag_names = []
            diag_values = []
            
            for key, value in diagnostics.items():
                if isinstance(value, (int, float)) and not np.isnan(value):
                    diag_names.append(key.replace('_', ' ').title())
                    diag_values.append(value)
            
            if diag_names:
                ax4.barh(range(len(diag_names)), diag_values, alpha=0.7)
                ax4.set_yticks(range(len(diag_names)))
                ax4.set_yticklabels(diag_names)
                ax4.set_xlabel('ç»Ÿè®¡é‡å€¼')
                ax4.set_title('è¯Šæ–­ç»Ÿè®¡é‡', fontweight='bold')
                ax4.grid(True, alpha=0.3)
            
            # 5. ç¨³å¥æ€§æ£€éªŒ
            ax5 = axes[1, 1]
            robustness = causal_results.get('robustness_tests', {})
            
            if robustness:
                rob_methods = list(robustness.keys())
                rob_coeffs = [robustness[method].get('coefficient', 0) for method in rob_methods]
                
                ax5.scatter(range(len(rob_methods)), rob_coeffs, s=100, alpha=0.7)
                ax5.set_xticks(range(len(rob_methods)))
                ax5.set_xticklabels(rob_methods, rotation=45)
                ax5.set_ylabel('ç³»æ•°ä¼°è®¡å€¼')
                ax5.set_title('ç¨³å¥æ€§æ£€éªŒ', fontweight='bold')
                ax5.grid(True, alpha=0.3)
                
                # æ·»åŠ åŸºå‡†çº¿
                if coefficients:
                    ax5.axhline(y=coefficients[0], color='red', linestyle='--', 
                               label=f'åŸºå‡†æ¨¡å‹: {coefficients[0]:.3f}')
                    ax5.legend()
            
            # 6. æ€»ä½“è¯„ä¼°
            ax6 = axes[1, 2]
            overall = causal_results.get('overall_assessment', {})
            
            assessment_items = [
                ('ç»Ÿè®¡æ˜¾è‘—æ€§', overall.get('statistical_significance', False)),
                ('ç»æµæ˜¾è‘—æ€§', overall.get('economic_significance', False)),
                ('ç¨³å¥æ€§', overall.get('robustness', False)),
                ('å·¥å…·å˜é‡æœ‰æ•ˆæ€§', overall.get('instrument_validity', False))
            ]
            
            colors = ['green' if item[1] else 'red' for item in assessment_items]
            values = [1 if item[1] else 0 for item in assessment_items]
            labels = [item[0] for item in assessment_items]
            
            wedges, texts, autotexts = ax6.pie(values, labels=labels, colors=colors, 
                                              autopct='%1.0f%%', startangle=90)
            ax6.set_title('æ€»ä½“è¯„ä¼°', fontweight='bold')
            
        except Exception as e:
            logger.warning(f"ç»˜åˆ¶è¯Šæ–­å›¾æ—¶å‡ºé”™: {e}")
            # å¦‚æœå‡ºé”™ï¼Œæ˜¾ç¤ºå ä½å›¾
            for ax in axes.flat:
                ax.text(0.5, 0.5, 'æ•°æ®ä¸å¯ç”¨\nData Not Available', 
                       transform=ax.transAxes, ha='center', va='center',
                       fontsize=12, bbox=dict(boxstyle="round", facecolor='lightgray'))
                ax.set_xticks([])
                ax.set_yticks([])
        
        plt.tight_layout()
        
        if save_path is None:
            save_path = self.figures_dir / "regression_diagnostics.png"
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        logger.info(f"âœ… å›å½’è¯Šæ–­å›¾å·²ä¿å­˜: {save_path}")
        return str(save_path)
    
    def plot_network_resilience_distribution(self, resilience_data: pd.DataFrame,
                                           save_path: str = None) -> str:
        """ç»˜åˆ¶ç½‘ç»œéŸ§æ€§åˆ†å¸ƒå›¾"""
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('ç½‘ç»œéŸ§æ€§åˆ†å¸ƒåˆ†æ\nNetwork Resilience Distribution Analysis', 
                    fontsize=16, fontweight='bold')
        
        # 1. ç»¼åˆéŸ§æ€§åˆ†å¸ƒç®±çº¿å›¾
        ax1 = axes[0, 0]
        countries = resilience_data['country'].unique()
        resilience_by_country = [resilience_data[resilience_data['country'] == country]['comprehensive_resilience'].values 
                               for country in countries]
        
        box_plot = ax1.boxplot(resilience_by_country, labels=countries, patch_artist=True)
        colors = plt.cm.Set3(np.linspace(0, 1, len(countries)))
        for patch, color in zip(box_plot['boxes'], colors):
            patch.set_facecolor(color)
            patch.set_alpha(0.7)
        
        ax1.set_title('ç»¼åˆéŸ§æ€§åˆ†å¸ƒ (æŒ‰å›½å®¶)', fontweight='bold')
        ax1.set_ylabel('ç»¼åˆéŸ§æ€§å¾—åˆ†')
        ax1.tick_params(axis='x', rotation=45)
        ax1.grid(True, alpha=0.3)
        
        # 2. éŸ§æ€§æŒ‡æ ‡ç›¸å…³æ€§çƒ­åŠ›å›¾
        ax2 = axes[0, 1]
        resilience_cols = [col for col in resilience_data.columns 
                          if 'resilience' in col or 'supply' in col or 'stability' in col]
        corr_matrix = resilience_data[resilience_cols].corr()
        
        sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, 
                   square=True, ax=ax2, cbar_kws={'shrink': 0.8})
        ax2.set_title('éŸ§æ€§æŒ‡æ ‡ç›¸å…³æ€§', fontweight='bold')
        ax2.tick_params(axis='x', rotation=45)
        ax2.tick_params(axis='y', rotation=0)
        
        # 3. å¹´åº¦éŸ§æ€§å˜åŒ–è¶‹åŠ¿
        ax3 = axes[1, 0]
        yearly_stats = resilience_data.groupby('year')['comprehensive_resilience'].agg(['mean', 'std'])
        
        ax3.fill_between(yearly_stats.index, 
                        yearly_stats['mean'] - yearly_stats['std'],
                        yearly_stats['mean'] + yearly_stats['std'],
                        alpha=0.3, label='Â±1Ïƒ åŒºé—´')
        ax3.plot(yearly_stats.index, yearly_stats['mean'], 'o-', 
                linewidth=2, markersize=6, label='å¹³å‡å€¼')
        
        ax3.set_title('å¹´åº¦éŸ§æ€§å˜åŒ–è¶‹åŠ¿', fontweight='bold')
        ax3.set_xlabel('å¹´ä»½')
        ax3.set_ylabel('ç»¼åˆéŸ§æ€§å¾—åˆ†')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. éŸ§æ€§å¾—åˆ†åˆ†å¸ƒç›´æ–¹å›¾
        ax4 = axes[1, 1]
        ax4.hist(resilience_data['comprehensive_resilience'], bins=20, 
                alpha=0.7, color='skyblue', edgecolor='black')
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        mean_val = resilience_data['comprehensive_resilience'].mean()
        std_val = resilience_data['comprehensive_resilience'].std()
        ax4.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'å‡å€¼: {mean_val:.3f}')
        ax4.axvline(mean_val + std_val, color='orange', linestyle='--', alpha=0.7, label=f'+1Ïƒ: {mean_val + std_val:.3f}')
        ax4.axvline(mean_val - std_val, color='orange', linestyle='--', alpha=0.7, label=f'-1Ïƒ: {mean_val - std_val:.3f}')
        
        ax4.set_title('ç»¼åˆéŸ§æ€§å¾—åˆ†åˆ†å¸ƒ', fontweight='bold')
        ax4.set_xlabel('ç»¼åˆéŸ§æ€§å¾—åˆ†')
        ax4.set_ylabel('é¢‘æ¬¡')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path is None:
            save_path = self.figures_dir / "resilience_distribution.png"
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        logger.info(f"âœ… éŸ§æ€§åˆ†å¸ƒå›¾å·²ä¿å­˜: {save_path}")
        return str(save_path)
    
    def generate_visualization_summary(self, causal_results: Dict[str, Any],
                                     resilience_data: pd.DataFrame,
                                     dli_data: pd.DataFrame) -> Dict[str, str]:
        """ç”Ÿæˆå®Œæ•´çš„å¯è§†åŒ–æŠ¥å‘Š"""
        
        logger.info("ğŸ¨ ç”Ÿæˆå®Œæ•´å¯è§†åŒ–æŠ¥å‘Š...")
        
        # åˆå¹¶æ•°æ®ç”¨äºæ•£ç‚¹å›¾
        merged_data = pd.merge(resilience_data, dli_data, 
                             on=['year', 'country'], how='inner')
        
        visualization_files = {}
        
        try:
            # 1. éŸ§æ€§æ—¶é—´åºåˆ—å›¾
            resilience_ts_path = self.plot_resilience_time_series(resilience_data)
            visualization_files['resilience_time_series'] = resilience_ts_path
            
            # 2. DLI-éŸ§æ€§å…³ç³»å›¾
            dli_scatter_path = self.plot_dli_resilience_scatter(merged_data)
            visualization_files['dli_resilience_scatter'] = dli_scatter_path
            
            # 3. å›å½’è¯Šæ–­å›¾
            diagnostics_path = self.plot_regression_diagnostics(causal_results)
            visualization_files['regression_diagnostics'] = diagnostics_path
            
            # 4. éŸ§æ€§åˆ†å¸ƒå›¾
            distribution_path = self.plot_network_resilience_distribution(resilience_data)
            visualization_files['resilience_distribution'] = distribution_path
            
            logger.info(f"âœ… å¯è§†åŒ–æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œå…± {len(visualization_files)} ä¸ªå›¾è¡¨")
            
        except Exception as e:
            logger.error(f"âŒ å¯è§†åŒ–ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            
        return visualization_files

def create_visualizations(causal_results: Dict[str, Any],
                         resilience_data: pd.DataFrame,
                         dli_data: pd.DataFrame,
                         output_dir: str = "outputs") -> Dict[str, str]:
    """ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨"""
    
    visualizer = CausalVisualization(output_dir)
    return visualizer.generate_visualization_summary(
        causal_results, resilience_data, dli_data
    )