#!/usr/bin/env python3
"""
ç½‘ç»œéŸ§æ€§è®¡ç®—å™¨ (Network Resilience Calculator)
=============================================

å®ç°åŒè½¨éŸ§æ€§æµ‹é‡åŸåˆ™ï¼Œç¡®ä¿å› æœæ¨æ–­ç»“è®ºçš„ç¨³å¥æ€§ï¼š

1. æ‹“æ‰‘æŠ—æ¯æ€§ (Topological Resilience)
   - é€šè¿‡æ¨¡æ‹Ÿæ”»å‡»æµ‹é‡ç½‘ç»œè¿é€šæ€§æŸå¤±é€Ÿåº¦
   - åŸºäºç½‘ç»œç§‘å­¦ç†è®ºçš„ç»“æ„ç¨³å®šæ€§åˆ†æ

2. ä¾›åº”ç¼ºå£å¸æ”¶ç‡ (Supply Gap Absorption Rate)  
   - æ¨¡æ‹Ÿä¸»è¦ä¾›åº”å•†ä¸­æ–­åçš„è¡¥å……ä¾›åº”èƒ½åŠ›
   - åŸºäºç»æµéŸ§æ€§ç†è®ºçš„å®é™…é€‚åº”èƒ½åŠ›

ä½œè€…ï¼šEnergy Network Analysis Team
"""

import numpy as np
import pandas as pd
import networkx as nx
from typing import Dict, List, Tuple, Optional, Union, Any
import logging
from pathlib import Path
from itertools import combinations
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore', category=FutureWarning)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class NetworkResilienceCalculator:
    """
    ç½‘ç»œéŸ§æ€§è®¡ç®—å™¨
    
    å®ç°ä¸¤ç§äº’è¡¥çš„éŸ§æ€§æµ‹é‡æ–¹æ³•ï¼š
    1. æ‹“æ‰‘æŠ—æ¯æ€§ - åŸºäºç½‘ç»œè¿é€šæ€§çš„ç»“æ„éŸ§æ€§
    2. ä¾›åº”ç¼ºå£å¸æ”¶ç‡ - åŸºäºä¾›éœ€åŒ¹é…çš„åŠŸèƒ½éŸ§æ€§
    """
    
    def __init__(self, 
                 attack_strategies: List[str] = None,
                 attack_proportions: List[float] = None):
        """
        åˆå§‹åŒ–éŸ§æ€§è®¡ç®—å™¨
        
        Args:
            attack_strategies: æ”»å‡»ç­–ç•¥åˆ—è¡¨ ['degree', 'betweenness', 'random']
            attack_proportions: æ”»å‡»æ¯”ä¾‹åˆ—è¡¨ï¼Œé»˜è®¤[0.05, 0.10, 0.15, 0.20, 0.25]
        """
        self.attack_strategies = attack_strategies or ['degree', 'betweenness', 'random']
        self.attack_proportions = attack_proportions or [0.05, 0.10, 0.15, 0.20, 0.25]
        
        logger.info(f"ğŸ›¡ï¸ åˆå§‹åŒ–ç½‘ç»œéŸ§æ€§è®¡ç®—å™¨")
        logger.info(f"   æ”»å‡»ç­–ç•¥: {self.attack_strategies}")
        logger.info(f"   æ”»å‡»æ¯”ä¾‹: {self.attack_proportions}")

    def calculate_topological_resilience(self, 
                                       G: nx.Graph,
                                       node_id: str,
                                       year: int = None) -> Dict[str, float]:
        """
        è®¡ç®—èŠ‚ç‚¹çš„æ‹“æ‰‘æŠ—æ¯æ€§
        
        æ–¹æ³•ï¼šæ¨¡æ‹Ÿç§»é™¤Top-KèŠ‚ç‚¹ï¼Œæµ‹é‡è¯¥èŠ‚ç‚¹æ‰€åœ¨è¿é€šåˆ†é‡è§„æ¨¡çš„ä¸‹é™é€Ÿåº¦
        
        Args:
            G: ç½‘ç»œå›¾
            node_id: ç›®æ ‡èŠ‚ç‚¹ID
            year: å¹´ä»½ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            
        Returns:
            åŒ…å«å„ç§éŸ§æ€§æŒ‡æ ‡çš„å­—å…¸
        """
        
        if node_id not in G.nodes():
            return {
                'topological_resilience_avg': 0.0,
                'topological_resilience_degree': 0.0,
                'topological_resilience_betweenness': 0.0,
                'topological_resilience_random': 0.0,
                'network_position_stability': 0.0
            }
        
        logger.debug(f"ğŸ¯ è®¡ç®—{node_id}æ‹“æ‰‘æŠ—æ¯æ€§ ({year}å¹´)" if year else f"ğŸ¯ è®¡ç®—{node_id}æ‹“æ‰‘æŠ—æ¯æ€§")
        
        # è®°å½•åˆå§‹çŠ¶æ€
        original_nodes = set(G.nodes())
        
        # å¤„ç†æœ‰å‘å›¾å’Œæ— å‘å›¾çš„è¿é€šåˆ†é‡
        if isinstance(G, nx.DiGraph):
            # å¯¹æœ‰å‘å›¾ï¼Œä½¿ç”¨å¼±è¿é€šåˆ†é‡
            original_component_size = len(nx.node_connected_component(G.to_undirected(), node_id))
        else:
            original_component_size = len(nx.node_connected_component(G, node_id))
            
        original_network_size = G.number_of_nodes()
        
        resilience_scores = {}
        
        # å¯¹æ¯ç§æ”»å‡»ç­–ç•¥è®¡ç®—éŸ§æ€§
        for strategy in self.attack_strategies:
            strategy_scores = []
            
            # ç¡®å®šæ”»å‡»ä¼˜å…ˆçº§
            if strategy == 'degree':
                # æŒ‰åº¦ä¸­å¿ƒæ€§æ’åºï¼ˆé™åºï¼‰
                centrality = dict(G.degree(weight='weight'))
            elif strategy == 'betweenness':
                # æŒ‰ä»‹æ•°ä¸­å¿ƒæ€§æ’åºï¼ˆé™åºï¼‰
                centrality = nx.betweenness_centrality(G, weight='weight')
            elif strategy == 'random':
                # éšæœºæ”»å‡» - è¿›è¡Œå¤šæ¬¡æ¨¡æ‹Ÿå–å¹³å‡
                random_scores = []
                for _ in range(10):  # 10æ¬¡éšæœºæ¨¡æ‹Ÿ
                    nodes_list = list(original_nodes)
                    np.random.shuffle(nodes_list)
                    random_centrality = {node: np.random.random() for node in nodes_list}
                    random_score = self._simulate_attack(G, node_id, random_centrality, 
                                                       original_component_size)
                    random_scores.append(random_score)
                resilience_scores[f'topological_resilience_{strategy}'] = np.mean(random_scores)
                continue
            else:
                logger.warning(f"æœªçŸ¥æ”»å‡»ç­–ç•¥: {strategy}")
                continue
                
            # æ¨¡æ‹Ÿæ”»å‡»è¿‡ç¨‹
            attack_score = self._simulate_attack(G, node_id, centrality, original_component_size)
            resilience_scores[f'topological_resilience_{strategy}'] = attack_score
        
        # è®¡ç®—ç»¼åˆéŸ§æ€§å¾—åˆ†ï¼ˆä¸‰ç§ç­–ç•¥çš„å¹³å‡å€¼ï¼‰
        strategy_values = [resilience_scores.get(f'topological_resilience_{s}', 0) 
                          for s in self.attack_strategies]
        resilience_scores['topological_resilience_avg'] = np.mean(strategy_values)
        
        # è®¡ç®—ç½‘ç»œä½ç½®ç¨³å®šæ€§ï¼ˆåŸºäºåº¦ä¸­å¿ƒæ€§çš„ç›¸å¯¹ä½ç½®ï¼‰
        degree_centrality = dict(G.degree(weight='weight'))
        sorted_nodes = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)
        node_rank = next((i+1 for i, (node, _) in enumerate(sorted_nodes) if node == node_id), 
                        len(sorted_nodes))
        position_stability = 1 - (node_rank - 1) / max(1, len(sorted_nodes) - 1)
        resilience_scores['network_position_stability'] = position_stability
        
        return resilience_scores
    
    def _simulate_attack(self, 
                        G: nx.Graph,
                        target_node: str, 
                        centrality: Dict[str, float],
                        original_component_size: int) -> float:
        """
        æ¨¡æ‹Ÿæ”»å‡»è¿‡ç¨‹ï¼Œè®¡ç®—ç›®æ ‡èŠ‚ç‚¹è¿é€šåˆ†é‡çš„éŸ§æ€§å¾—åˆ†
        
        Args:
            G: ç½‘ç»œå›¾
            target_node: ç›®æ ‡èŠ‚ç‚¹
            centrality: èŠ‚ç‚¹ä¸­å¿ƒæ€§å­—å…¸
            original_component_size: åŸå§‹è¿é€šåˆ†é‡å¤§å°
            
        Returns:
            éŸ§æ€§å¾—åˆ†ï¼ˆ0-1ä¹‹é—´ï¼Œè¶Šé«˜è¶ŠéŸ§æ€§ï¼‰
        """
        
        # æ’é™¤ç›®æ ‡èŠ‚ç‚¹æœ¬èº«ï¼ˆä¸èƒ½æ”»å‡»è‡ªå·±ï¼‰
        attack_centrality = {node: score for node, score in centrality.items() 
                           if node != target_node}
        
        if not attack_centrality:
            return 1.0  # å¦‚æœæ²¡æœ‰å…¶ä»–èŠ‚ç‚¹å¯æ”»å‡»ï¼ŒéŸ§æ€§æœ€å¤§
            
        # æŒ‰ä¸­å¿ƒæ€§æ’åºç¡®å®šæ”»å‡»é¡ºåº
        sorted_attackable = sorted(attack_centrality.items(), key=lambda x: x[1], reverse=True)
        
        resilience_over_attacks = []
        G_attack = G.copy()
        
        # æ¨¡æ‹Ÿé€æ­¥æ”»å‡»
        for attack_ratio in self.attack_proportions:
            num_attacks = max(1, int(len(sorted_attackable) * attack_ratio))
            
            # ç§»é™¤å‰num_attacksä¸ªèŠ‚ç‚¹
            nodes_to_remove = [node for node, _ in sorted_attackable[:num_attacks]]
            G_attack.remove_nodes_from(nodes_to_remove)
            
            # æ£€æŸ¥ç›®æ ‡èŠ‚ç‚¹æ˜¯å¦ä»åœ¨å›¾ä¸­
            if target_node not in G_attack.nodes():
                resilience_over_attacks.append(0.0)
                continue
                
            # è®¡ç®—ç›®æ ‡èŠ‚ç‚¹æ‰€åœ¨è¿é€šåˆ†é‡çš„å½“å‰å¤§å°
            try:
                if isinstance(G_attack, nx.DiGraph):
                    current_component_size = len(nx.node_connected_component(G_attack.to_undirected(), target_node))
                else:
                    current_component_size = len(nx.node_connected_component(G_attack, target_node))
                # éŸ§æ€§ = å½“å‰è¿é€šåˆ†é‡å¤§å° / åŸå§‹è¿é€šåˆ†é‡å¤§å°
                resilience = current_component_size / max(1, original_component_size)
            except:
                resilience = 0.0
                
            resilience_over_attacks.append(resilience)
        
        # è¿”å›æ”»å‡»è¿‡ç¨‹ä¸­éŸ§æ€§çš„å¹³å‡å€¼ï¼ˆä»£è¡¨æ•´ä½“æŠ—æ”»å‡»èƒ½åŠ›ï¼‰
        return np.mean(resilience_over_attacks) if resilience_over_attacks else 0.0

    def calculate_supply_absorption(self, 
                                  G: nx.Graph,
                                  node_id: str,
                                  year: int = None,
                                  top_suppliers: int = 3) -> Dict[str, float]:
        """
        è®¡ç®—ä¾›åº”ç¼ºå£å¸æ”¶ç‡
        
        æ–¹æ³•ï¼šæ¨¡æ‹Ÿä¸»è¦ä¾›åº”å•†ä¸­æ–­åï¼Œä»ç½‘ç»œå…¶ä»–èŠ‚ç‚¹è·å¾—è¡¥å……ä¾›åº”çš„èƒ½åŠ›
        
        Args:
            G: ç½‘ç»œå›¾ï¼ˆæœ‰å‘å›¾ï¼Œè¾¹æƒé‡ä»£è¡¨ä¾›åº”æµé‡ï¼‰
            node_id: ç›®æ ‡èŠ‚ç‚¹ID  
            year: å¹´ä»½ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            top_suppliers: è€ƒè™‘çš„ä¸»è¦ä¾›åº”å•†æ•°é‡
            
        Returns:
            ä¾›åº”å¸æ”¶èƒ½åŠ›ç›¸å…³æŒ‡æ ‡
        """
        
        if node_id not in G.nodes():
            return {
                'supply_absorption_rate': 0.0,
                'supply_diversification_index': 0.0, 
                'supply_network_depth': 0.0,
                'alternative_suppliers_count': 0.0
            }
        
        logger.debug(f"ğŸ“¦ è®¡ç®—{node_id}ä¾›åº”ç¼ºå£å¸æ”¶ç‡ ({year}å¹´)" if year else f"ğŸ“¦ è®¡ç®—{node_id}ä¾›åº”ç¼ºå£å¸æ”¶ç‡")
        
        # 1. è¯†åˆ«å½“å‰ä¸»è¦ä¾›åº”å•†ï¼ˆå…¥è¾¹æƒé‡æœ€å¤§çš„èŠ‚ç‚¹ï¼‰
        if isinstance(G, nx.DiGraph):
            suppliers = [(supplier, data.get('weight', 0)) 
                        for supplier, _, data in G.in_edges(node_id, data=True)]
        else:
            # å¯¹äºæ— å‘å›¾ï¼Œè€ƒè™‘æ‰€æœ‰é‚»å±…
            suppliers = [(neighbor, data.get('weight', 0)) 
                        for neighbor, data in G[node_id].items()]
        
        if not suppliers:
            return {
                'supply_absorption_rate': 0.0,
                'supply_diversification_index': 0.0,
                'supply_network_depth': 0.0, 
                'alternative_suppliers_count': 0.0
            }
        
        # æŒ‰ä¾›åº”é‡æ’åºï¼Œå–å‰top_suppliersä¸ª
        suppliers.sort(key=lambda x: x[1], reverse=True)
        major_suppliers = suppliers[:top_suppliers]
        total_major_supply = sum(weight for _, weight in major_suppliers)
        
        # 2. è®¡ç®—ä¾›åº”å¤šæ ·åŒ–æŒ‡æ•° (HHIçš„å€’æ•°)
        if total_major_supply > 0:
            supply_shares = [weight/total_major_supply for _, weight in major_suppliers]
            hhi = sum(share**2 for share in supply_shares)
            diversification_index = 1 / hhi if hhi > 0 else 1.0
        else:
            diversification_index = 1.0
            
        # 3. æ¨¡æ‹Ÿä¸»è¦ä¾›åº”å•†ä¸­æ–­ï¼Œè®¡ç®—æ›¿ä»£ä¾›åº”èƒ½åŠ›
        absorption_scores = []
        
        for disrupted_supplier, disrupted_supply in major_suppliers:
            # åˆ›å»ºä¸­æ–­æƒ…å†µä¸‹çš„ç½‘ç»œå‰¯æœ¬
            G_disrupted = G.copy()
            if isinstance(G, nx.DiGraph):
                if G_disrupted.has_edge(disrupted_supplier, node_id):
                    G_disrupted.remove_edge(disrupted_supplier, node_id)
            else:
                if G_disrupted.has_edge(disrupted_supplier, node_id):
                    G_disrupted.remove_edge(disrupted_supplier, node_id)
            
            # å¯»æ‰¾æ›¿ä»£ä¾›åº”æ¥æº
            alternative_supply = self._find_alternative_supply(
                G_disrupted, node_id, disrupted_supply
            )
            
            # è®¡ç®—å¸æ”¶ç‡ = å¯è·å¾—çš„æ›¿ä»£ä¾›åº” / ä¸­æ–­çš„ä¾›åº”
            absorption_rate = alternative_supply / disrupted_supply if disrupted_supply > 0 else 1.0
            absorption_scores.append(min(1.0, absorption_rate))  # é™åˆ¶åœ¨[0,1]
        
        # 4. è®¡ç®—ä¾›åº”ç½‘ç»œæ·±åº¦ï¼ˆäºŒåº¦ä¾›åº”å•†çš„æ•°é‡å’Œå¼ºåº¦ï¼‰
        second_tier_suppliers = set()
        second_tier_supply = 0
        
        for supplier, _ in suppliers:
            if isinstance(G, nx.DiGraph):
                for second_supplier, _, data in G.in_edges(supplier, data=True):
                    if second_supplier != node_id:  # é¿å…å¾ªç¯
                        second_tier_suppliers.add(second_supplier)
                        second_tier_supply += data.get('weight', 0)
            else:
                for second_supplier, data in G[supplier].items():
                    if second_supplier != node_id:  # é¿å…å¾ªç¯
                        second_tier_suppliers.add(second_supplier) 
                        second_tier_supply += data.get('weight', 0)
        
        supply_network_depth = len(second_tier_suppliers) / max(1, G.number_of_nodes() - 1)
        
        # 5. è®¡ç®—å¯æ›¿ä»£ä¾›åº”å•†æ•°é‡
        all_potential_suppliers = set()
        if isinstance(G, nx.DiGraph):
            # å¯¹æœ‰å‘å›¾ï¼Œæ‰¾æ‰€æœ‰å¯èƒ½çš„ä¾›åº”è·¯å¾„ï¼ˆæœ€çŸ­è·¯å¾„é•¿åº¦<=2ï¼‰
            try:
                shortest_paths = nx.single_source_shortest_path_length(
                    G.reverse(), node_id, cutoff=2
                )
                all_potential_suppliers = set(shortest_paths.keys()) - {node_id}
            except:
                all_potential_suppliers = set(G.nodes()) - {node_id}
        else:
            # å¯¹æ— å‘å›¾ï¼Œè€ƒè™‘æ‰€æœ‰è·ç¦»<=2çš„èŠ‚ç‚¹
            try:
                shortest_paths = nx.single_source_shortest_path_length(
                    G, node_id, cutoff=2
                )
                all_potential_suppliers = set(shortest_paths.keys()) - {node_id}
            except:
                all_potential_suppliers = set(G.nodes()) - {node_id}
        
        alternative_suppliers_count = len(all_potential_suppliers) / max(1, G.number_of_nodes() - 1)
        
        return {
            'supply_absorption_rate': np.mean(absorption_scores) if absorption_scores else 0.0,
            'supply_diversification_index': min(1.0, diversification_index / top_suppliers),  # æ ‡å‡†åŒ–
            'supply_network_depth': supply_network_depth,
            'alternative_suppliers_count': alternative_suppliers_count
        }
    
    def _find_alternative_supply(self, 
                               G_disrupted: nx.Graph, 
                               target_node: str,
                               needed_supply: float) -> float:
        """
        å¯»æ‰¾æ›¿ä»£ä¾›åº”æ¥æº
        
        Args:
            G_disrupted: ä¾›åº”ä¸­æ–­åçš„ç½‘ç»œ
            target_node: ç›®æ ‡èŠ‚ç‚¹
            needed_supply: éœ€è¦çš„ä¾›åº”é‡
            
        Returns:
            å¯è·å¾—çš„æ›¿ä»£ä¾›åº”é‡
        """
        
        alternative_supply = 0
        
        if isinstance(G_disrupted, nx.DiGraph):
            # è®¡ç®—æ‰€æœ‰æ½œåœ¨ä¾›åº”å•†çš„å¯ç”¨ä¾›åº”èƒ½åŠ›
            potential_suppliers = []
            for supplier in G_disrupted.predecessors(target_node):
                supply_capacity = G_disrupted[supplier][target_node].get('weight', 0)
                potential_suppliers.append((supplier, supply_capacity))
                
            # å°è¯•é€šè¿‡çŸ­è·¯å¾„å¢åŠ ä¾›åº”
            try:
                for node in G_disrupted.nodes():
                    if node != target_node and not G_disrupted.has_edge(node, target_node):
                        try:
                            path_length = nx.shortest_path_length(G_disrupted, node, target_node)
                            if path_length <= 2:  # æœ€å¤šé€šè¿‡1ä¸ªä¸­ä»‹
                                # ä¼°ç®—é€šè¿‡è¯¥è·¯å¾„çš„æ½œåœ¨ä¾›åº”èƒ½åŠ›
                                path_supply = self._estimate_path_capacity(G_disrupted, node, target_node)
                                potential_suppliers.append((node, path_supply))
                        except nx.NetworkXNoPath:
                            continue
            except:
                pass
                
        else:
            # æ— å‘å›¾æƒ…å†µ
            for neighbor, data in G_disrupted[target_node].items():
                supply_capacity = data.get('weight', 0)
                potential_suppliers.append((neighbor, supply_capacity))
        
        # æŒ‰ä¾›åº”èƒ½åŠ›æ’åºï¼Œä¼˜å…ˆä½¿ç”¨ä¾›åº”èƒ½åŠ›å¼ºçš„æ›¿ä»£è€…
        if 'potential_suppliers' in locals():
            potential_suppliers.sort(key=lambda x: x[1], reverse=True)
            alternative_supply = sum(capacity for _, capacity in potential_suppliers)
        
        return alternative_supply
    
    def _estimate_path_capacity(self, G: nx.DiGraph, source: str, target: str) -> float:
        """
        ä¼°ç®—é€šè¿‡æœ€çŸ­è·¯å¾„çš„ä¾›åº”èƒ½åŠ›ï¼ˆç“¶é¢ˆå®¹é‡ï¼‰
        
        Args:
            G: ç½‘ç»œå›¾
            source: æºèŠ‚ç‚¹
            target: ç›®æ ‡èŠ‚ç‚¹
            
        Returns:
            è·¯å¾„å®¹é‡ä¼°ç®—å€¼
        """
        try:
            path = nx.shortest_path(G, source, target, weight='weight')
            if len(path) < 2:
                return 0
                
            # æ‰¾åˆ°è·¯å¾„ä¸Šçš„æœ€å°æƒé‡ï¼ˆç“¶é¢ˆï¼‰
            path_capacities = []
            for i in range(len(path) - 1):
                edge_weight = G[path[i]][path[i+1]].get('weight', 0)
                path_capacities.append(edge_weight)
                
            return min(path_capacities) if path_capacities else 0
            
        except:
            return 0

def calculate_topological_resilience(networks: Dict[int, nx.Graph],
                                   countries: List[str] = None,
                                   attack_strategies: List[str] = None) -> pd.DataFrame:
    """
    æ‰¹é‡è®¡ç®—å¤šå¹´ç½‘ç»œçš„æ‹“æ‰‘æŠ—æ¯æ€§
    
    Args:
        networks: å¹´ä»½åˆ°ç½‘ç»œå›¾çš„æ˜ å°„
        countries: è¦åˆ†æçš„å›½å®¶åˆ—è¡¨ï¼ŒNoneåˆ™åˆ†ææ‰€æœ‰å›½å®¶
        attack_strategies: æ”»å‡»ç­–ç•¥åˆ—è¡¨
        
    Returns:
        åŒ…å«æ‰€æœ‰å¹´ä»½ã€å›½å®¶çš„æ‹“æ‰‘éŸ§æ€§æ•°æ®æ¡†
    """
    
    logger.info("ğŸ›¡ï¸ å¼€å§‹æ‰¹é‡è®¡ç®—æ‹“æ‰‘æŠ—æ¯æ€§...")
    
    calculator = NetworkResilienceCalculator(attack_strategies=attack_strategies)
    results = []
    
    # ç¡®å®šè¦åˆ†æçš„å›½å®¶
    if countries is None:
        all_countries = set()
        for G in networks.values():
            all_countries.update(G.nodes())
        countries = sorted(list(all_countries))
    
    # é€å¹´é€å›½åˆ†æ
    for year in tqdm(sorted(networks.keys()), desc="å¹´ä»½è¿›åº¦"):
        G = networks[year]
        logger.info(f"ğŸ“… å¤„ç†{year}å¹´ç½‘ç»œ ({G.number_of_nodes()}èŠ‚ç‚¹, {G.number_of_edges()}è¾¹)")
        
        for country in countries:
            if country in G.nodes():
                resilience_scores = calculator.calculate_topological_resilience(G, country, year)
                
                result_row = {
                    'year': year,
                    'country': country,
                    **resilience_scores
                }
                results.append(result_row)
            else:
                logger.debug(f"âš ï¸ {country}ä¸åœ¨{year}å¹´ç½‘ç»œä¸­")
    
    df = pd.DataFrame(results)
    logger.info(f"âœ… æ‹“æ‰‘æŠ—æ¯æ€§è®¡ç®—å®Œæˆ: {len(df)}æ¡è®°å½•")
    
    return df

def calculate_supply_absorption(networks: Dict[int, nx.Graph],
                              countries: List[str] = None,
                              top_suppliers: int = 3) -> pd.DataFrame:
    """
    æ‰¹é‡è®¡ç®—ä¾›åº”ç¼ºå£å¸æ”¶ç‡
    
    Args:
        networks: å¹´ä»½åˆ°ç½‘ç»œå›¾çš„æ˜ å°„
        countries: è¦åˆ†æçš„å›½å®¶åˆ—è¡¨
        top_suppliers: è€ƒè™‘çš„ä¸»è¦ä¾›åº”å•†æ•°é‡
        
    Returns:
        åŒ…å«ä¾›åº”å¸æ”¶èƒ½åŠ›æ•°æ®çš„DataFrame
    """
    
    logger.info("ğŸ“¦ å¼€å§‹æ‰¹é‡è®¡ç®—ä¾›åº”ç¼ºå£å¸æ”¶ç‡...")
    
    calculator = NetworkResilienceCalculator()
    results = []
    
    # ç¡®å®šè¦åˆ†æçš„å›½å®¶
    if countries is None:
        all_countries = set()
        for G in networks.values():
            all_countries.update(G.nodes())
        countries = sorted(list(all_countries))
    
    # é€å¹´é€å›½åˆ†æ
    for year in tqdm(sorted(networks.keys()), desc="å¹´ä»½è¿›åº¦"):
        G = networks[year]
        logger.info(f"ğŸ“… å¤„ç†{year}å¹´ç½‘ç»œ ({G.number_of_nodes()}èŠ‚ç‚¹, {G.number_of_edges()}è¾¹)")
        
        for country in countries:
            if country in G.nodes():
                absorption_scores = calculator.calculate_supply_absorption(
                    G, country, year, top_suppliers
                )
                
                result_row = {
                    'year': year,
                    'country': country,
                    **absorption_scores
                }
                results.append(result_row)
            else:
                logger.debug(f"âš ï¸ {country}ä¸åœ¨{year}å¹´ç½‘ç»œä¸­")
    
    df = pd.DataFrame(results)
    logger.info(f"âœ… ä¾›åº”ç¼ºå£å¸æ”¶ç‡è®¡ç®—å®Œæˆ: {len(df)}æ¡è®°å½•")
    
    return df

def generate_resilience_database(networks: Dict[int, nx.Graph],
                               output_path: str = "network_resilience.csv",
                               countries: List[str] = None) -> pd.DataFrame:
    """
    ç”Ÿæˆå®Œæ•´çš„ç½‘ç»œéŸ§æ€§æ•°æ®åº“
    
    Args:
        networks: å¹´ä»½åˆ°ç½‘ç»œå›¾çš„æ˜ å°„
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        countries: è¦åˆ†æçš„å›½å®¶åˆ—è¡¨
        
    Returns:
        å®Œæ•´çš„éŸ§æ€§æ•°æ®åº“DataFrame
    """
    
    logger.info("ğŸ—ƒï¸ ç”Ÿæˆç½‘ç»œéŸ§æ€§æ•°æ®åº“...")
    
    # è®¡ç®—æ‹“æ‰‘æŠ—æ¯æ€§
    topo_resilience = calculate_topological_resilience(networks, countries)
    
    # è®¡ç®—ä¾›åº”ç¼ºå£å¸æ”¶ç‡
    supply_absorption = calculate_supply_absorption(networks, countries)
    
    # åˆå¹¶ä¸¤ç±»éŸ§æ€§æŒ‡æ ‡
    resilience_db = pd.merge(
        topo_resilience, 
        supply_absorption, 
        on=['year', 'country'], 
        how='outer'
    )
    
    # è®¡ç®—ç»¼åˆéŸ§æ€§æŒ‡æ•°ï¼ˆä¸¤ä¸ªç»´åº¦çš„åŠ æƒå¹³å‡ï¼‰
    resilience_db['comprehensive_resilience'] = (
        0.6 * resilience_db['topological_resilience_avg'] + 
        0.4 * resilience_db['supply_absorption_rate']
    )
    
    # æ’åºå¹¶ä¿å­˜
    resilience_db = resilience_db.sort_values(['year', 'country'])
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    output_file = Path(output_path)
    resilience_db.to_csv(output_file, index=False)
    
    logger.info(f"âœ… ç½‘ç»œéŸ§æ€§æ•°æ®åº“å·²ä¿å­˜: {output_file}")
    logger.info(f"   æ•°æ®ç»´åº¦: {resilience_db.shape}")
    logger.info(f"   å¹´ä»½èŒƒå›´: {resilience_db['year'].min()}-{resilience_db['year'].max()}")
    logger.info(f"   å›½å®¶æ•°é‡: {resilience_db['country'].nunique()}")
    
    return resilience_db

# ä¸ºmain.pyæä¾›çš„ç®€åŒ–æ¥å£
class SimpleResilienceCalculator:
    """ç®€åŒ–çš„éŸ§æ€§è®¡ç®—å™¨ï¼Œä¸“æ³¨äºæ‰¹é‡è®¡ç®—"""
    
    def __init__(self):
        self.calculator = NetworkResilienceCalculator()
        
    def calculate_resilience_for_all(self, networks: Dict[int, nx.Graph]) -> pd.DataFrame:
        """
        ä¸ºæ‰€æœ‰ç½‘ç»œè®¡ç®—éŸ§æ€§æŒ‡æ ‡
        
        Args:
            networks: å¹´ä»½åˆ°ç½‘ç»œå›¾çš„æ˜ å°„
            
        Returns:
            åŒ…å«æ‰€æœ‰éŸ§æ€§æŒ‡æ ‡çš„DataFrame
        """
        return generate_resilience_database(networks)

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logger.info("ğŸ§ª æµ‹è¯•ç½‘ç»œéŸ§æ€§è®¡ç®—å™¨...")
    
    # åˆ›å»ºæµ‹è¯•ç½‘ç»œ
    G_test = nx.DiGraph()
    
    # æ·»åŠ æµ‹è¯•è¾¹ï¼ˆæ¨¡æ‹Ÿèƒ½æºè´¸æ˜“ç½‘ç»œï¼‰
    edges = [
        ('USA', 'CHN', {'weight': 100}), 
        ('USA', 'JPN', {'weight': 80}),
        ('USA', 'DEU', {'weight': 60}),
        ('RUS', 'CHN', {'weight': 90}),
        ('RUS', 'DEU', {'weight': 70}),
        ('SAU', 'CHN', {'weight': 85}),
        ('SAU', 'JPN', {'weight': 75}),
        ('CAN', 'USA', {'weight': 95}),
        ('MEX', 'USA', {'weight': 50})
    ]
    
    G_test.add_edges_from([(s, t, d) for s, t, d in edges])
    
    # æµ‹è¯•éŸ§æ€§è®¡ç®—
    calculator = NetworkResilienceCalculator()
    
    # æµ‹è¯•ä¸­å›½çš„éŸ§æ€§
    topo_resilience = calculator.calculate_topological_resilience(G_test, 'CHN')
    supply_absorption = calculator.calculate_supply_absorption(G_test, 'CHN')
    
    print("\nğŸ‡¨ğŸ‡³ ä¸­å›½éŸ§æ€§æµ‹è¯•ç»“æœ:")
    print("æ‹“æ‰‘æŠ—æ¯æ€§:")
    for key, value in topo_resilience.items():
        print(f"  {key}: {value:.3f}")
        
    print("\nä¾›åº”ç¼ºå£å¸æ”¶ç‡:")  
    for key, value in supply_absorption.items():
        print(f"  {key}: {value:.3f}")
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")