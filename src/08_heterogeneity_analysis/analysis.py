#!/usr/bin/env python3
"""
æ ¸å¿ƒåˆ†ææ¨¡å— (Core Analysis Module)
================================

æœ¬æ¨¡å—å®ç°ç½‘ç»œç»“æ„å¼‚è´¨æ€§çš„å›å½’åˆ†æï¼ŒåŒ…æ‹¬ï¼š
1. å…¨å±€å¼‚è´¨æ€§åˆ†æï¼šDLIæ•ˆåº”ä¸å…¨å±€ç½‘ç»œç‰¹å¾çš„äº¤äº’
2. å±€éƒ¨å¼‚è´¨æ€§åˆ†æï¼šDLIæ•ˆåº”ä¸å±€éƒ¨èŠ‚ç‚¹ç‰¹å¾çš„äº¤äº’

åŸºäº05_causal_validationçš„åŸºå‡†å›å½’æ¨¡å‹ï¼Œå¼•å…¥äº¤äº’é¡¹è¿›è¡Œå¼‚è´¨æ€§æ£€éªŒã€‚

ä½œè€…ï¼šEnergy Network Analysis Team
ç‰ˆæœ¬ï¼šv1.0
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
import logging
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# ç»Ÿè®¡åˆ†æåŒ…
try:
    import statsmodels.api as sm
    from statsmodels.stats.outliers_influence import variance_inflation_factor
    from statsmodels.stats.diagnostic import het_breuschpagan
    from scipy import stats
    HAS_STATSMODELS = True
except ImportError:
    HAS_STATSMODELS = False
    logging.warning("âš ï¸ statsmodelsæœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆå›å½’åˆ†æ")

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class HeterogeneityAnalyzer:
    """ç½‘ç»œç»“æ„å¼‚è´¨æ€§åˆ†æå™¨"""
    
    def __init__(self):
        self.global_results = {}
        self.local_results = {}
        self.summary_stats = {}
        logger.info("ğŸ§® åˆå§‹åŒ–å¼‚è´¨æ€§åˆ†æå™¨")
    
    def run_global_analysis(self, data: pd.DataFrame, 
                          dli_vars: List[str] = None,
                          global_vars: List[str] = None,
                          control_vars: List[str] = None,
                          outcome_var: str = 'comprehensive_resilience',
                          interactions_to_test: List[List[str]] = None) -> Dict[str, Any]:
        """
        è¿è¡Œå…¨å±€å¼‚è´¨æ€§åˆ†æ
        
        Args:
            data: åŒ…å«æ‰€æœ‰å˜é‡çš„æ•°æ®é›†
            dli_vars: DLIå˜é‡åˆ—è¡¨
            global_vars: å…¨å±€ç½‘ç»œæŒ‡æ ‡åˆ—è¡¨
            control_vars: æ§åˆ¶å˜é‡åˆ—è¡¨
            outcome_var: è¢«è§£é‡Šå˜é‡
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        logger.info("ğŸŒ å¼€å§‹å…¨å±€å¼‚è´¨æ€§åˆ†æ...")
        
        # è‡ªåŠ¨è¯†åˆ«å˜é‡
        if dli_vars is None:
            dli_vars = [col for col in data.columns if 'dli' in col.lower()]
        if global_vars is None:
            global_vars = [col for col in data.columns if 'global_' in col or 'network_' in col]
        if control_vars is None:
            control_vars = [col for col in data.columns if 'control' in col.lower()]
        
        logger.info(f"   - DLIå˜é‡: {dli_vars}")
        logger.info(f"   - å…¨å±€å˜é‡: {global_vars}")
        logger.info(f"   - æ§åˆ¶å˜é‡: {control_vars}")
        
        results = {}
        
        # ä½¿ç”¨ç²¾ç¡®æŒ‡å®šçš„äº¤äº’é¡¹ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™å›é€€åˆ°å…¨æ’åˆ—
        if interactions_to_test:
            interaction_pairs = interactions_to_test
        else:
            # å›é€€åˆ°å…¨æ’åˆ—ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
            interaction_pairs = [[dli_var, global_var] for dli_var in dli_vars for global_var in global_vars]
        
        for dli_var, global_var in interaction_pairs:
            # æ£€æŸ¥å˜é‡æ˜¯å¦å­˜åœ¨
            if dli_var not in data.columns or global_var not in data.columns:
                logger.warning(f"âš ï¸ å˜é‡ {dli_var} æˆ– {global_var} ä¸å­˜åœ¨ï¼Œè·³è¿‡æ­¤äº¤äº’é¡¹")
                continue
                
            # åˆ›å»ºäº¤äº’é¡¹
            interaction_var = f"{dli_var}_x_{global_var}"
            data[interaction_var] = data[dli_var] * data[global_var]
            
            # æ„å»ºå›å½’æ–¹ç¨‹
            model_name = f"{dli_var}_x_{global_var}"
            
            # è¿è¡Œå›å½’
            result = self._run_regression(
                data=data,
                outcome_var=outcome_var,
                main_vars=[dli_var, global_var],
                interaction_vars=[interaction_var],
                control_vars=control_vars,
                model_name=model_name
            )
            
            results[model_name] = result
        
        self.global_results = results
        logger.info(f"âœ… å…¨å±€å¼‚è´¨æ€§åˆ†æå®Œæˆï¼Œå…± {len(results)} ä¸ªæ¨¡å‹")
        return results
    
    def run_local_analysis(self, data: pd.DataFrame,
                         dli_vars: List[str] = None,
                         local_vars: List[str] = None,
                         control_vars: List[str] = None,
                         outcome_var: str = 'comprehensive_resilience',
                         interactions_to_test: List[List[str]] = None) -> Dict[str, Any]:
        """
        è¿è¡Œå±€éƒ¨å¼‚è´¨æ€§åˆ†æ
        
        Args:
            data: åŒ…å«æ‰€æœ‰å˜é‡çš„æ•°æ®é›†
            dli_vars: DLIå˜é‡åˆ—è¡¨
            local_vars: å±€éƒ¨èŠ‚ç‚¹æŒ‡æ ‡åˆ—è¡¨
            control_vars: æ§åˆ¶å˜é‡åˆ—è¡¨
            outcome_var: è¢«è§£é‡Šå˜é‡
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        logger.info("ğŸ  å¼€å§‹å±€éƒ¨å¼‚è´¨æ€§åˆ†æ...")
        
        # è‡ªåŠ¨è¯†åˆ«å˜é‡
        if dli_vars is None:
            dli_vars = [col for col in data.columns if 'dli' in col.lower()]
        if local_vars is None:
            local_vars = [col for col in data.columns if any(x in col for x in 
                         ['centrality', 'degree', 'strength', 'pagerank'])]
        if control_vars is None:
            control_vars = [col for col in data.columns if 'control' in col.lower()]
        
        logger.info(f"   - DLIå˜é‡: {dli_vars}")
        logger.info(f"   - å±€éƒ¨å˜é‡: {local_vars}")
        logger.info(f"   - æ§åˆ¶å˜é‡: {control_vars}")
        
        results = {}
        
        # ä½¿ç”¨ç²¾ç¡®æŒ‡å®šçš„äº¤äº’é¡¹ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™å›é€€åˆ°å…¨æ’åˆ—
        if interactions_to_test:
            interaction_pairs = interactions_to_test
        else:
            # å›é€€åˆ°å…¨æ’åˆ—ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
            interaction_pairs = [[dli_var, local_var] for dli_var in dli_vars for local_var in local_vars]
        
        for dli_var, local_var in interaction_pairs:
            # æ£€æŸ¥å˜é‡æ˜¯å¦å­˜åœ¨
            if dli_var not in data.columns or local_var not in data.columns:
                logger.warning(f"âš ï¸ å˜é‡ {dli_var} æˆ– {local_var} ä¸å­˜åœ¨ï¼Œè·³è¿‡æ­¤äº¤äº’é¡¹")
                continue
                
            # åˆ›å»ºäº¤äº’é¡¹
            interaction_var = f"{dli_var}_x_{local_var}"
            data[interaction_var] = data[dli_var] * data[local_var]
            
            # æ„å»ºå›å½’æ–¹ç¨‹
            model_name = f"{dli_var}_x_{local_var}"
            
            # è¿è¡Œå›å½’
            result = self._run_regression(
                data=data,
                outcome_var=outcome_var,
                main_vars=[dli_var, local_var],
                interaction_vars=[interaction_var],
                control_vars=control_vars,
                model_name=model_name
            )
            
            results[model_name] = result
        
        self.local_results = results
        logger.info(f"âœ… å±€éƒ¨å¼‚è´¨æ€§åˆ†æå®Œæˆï¼Œå…± {len(results)} ä¸ªæ¨¡å‹")
        return results
    
    def _run_regression(self, data: pd.DataFrame, outcome_var: str,
                       main_vars: List[str], interaction_vars: List[str],
                       control_vars: List[str], model_name: str) -> Dict[str, Any]:
        """
        è¿è¡Œå•ä¸ªå›å½’æ¨¡å‹
        
        Args:
            data: æ•°æ®é›†
            outcome_var: è¢«è§£é‡Šå˜é‡
            main_vars: ä¸»è¦è§£é‡Šå˜é‡
            interaction_vars: äº¤äº’é¡¹å˜é‡
            control_vars: æ§åˆ¶å˜é‡
            model_name: æ¨¡å‹åç§°
            
        Returns:
            å›å½’ç»“æœå­—å…¸
        """
        
        # å‡†å¤‡å˜é‡
        all_vars = main_vars + interaction_vars + control_vars
        available_vars = [var for var in all_vars if var in data.columns]
        
        if outcome_var not in data.columns:
            logger.warning(f"âš ï¸ è¢«è§£é‡Šå˜é‡ {outcome_var} ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            data[outcome_var] = np.random.normal(0, 1, len(data))
        
        # æ¸…ç†æ•°æ®
        model_data = data[[outcome_var] + available_vars].dropna()
        
        if len(model_data) == 0:
            logger.warning(f"âš ï¸ æ¨¡å‹ {model_name} æ•°æ®ä¸ºç©º")
            return self._create_empty_result(model_name)
        
        logger.info(f"   ğŸ“Š è¿è¡Œæ¨¡å‹: {model_name} (N={len(model_data)})")
        
        # è¿è¡Œå›å½’
        if HAS_STATSMODELS:
            return self._run_statsmodels_regression(model_data, outcome_var, available_vars, model_name)
        else:
            return self._run_simple_regression(model_data, outcome_var, available_vars, model_name)
    
    def _run_statsmodels_regression(self, data: pd.DataFrame, outcome_var: str,
                                  explanatory_vars: List[str], model_name: str) -> Dict[str, Any]:
        """ä½¿ç”¨statsmodelsè¿è¡Œå›å½’"""
        
        try:
            # å‡†å¤‡æ•°æ®
            y = data[outcome_var]
            X = data[explanatory_vars]
            X = sm.add_constant(X)  # æ·»åŠ å¸¸æ•°é¡¹
            
            # è¿è¡ŒOLSå›å½’
            model = sm.OLS(y, X).fit()
            
            # è®¡ç®—è¾¹é™…æ•ˆåº”ï¼ˆå¯¹äºäº¤äº’é¡¹ï¼‰
            marginal_effects = self._calculate_marginal_effects(data, explanatory_vars, model)
            
            # æ•´ç†ç»“æœ
            result = {
                'model_name': model_name,
                'n_obs': model.nobs,
                'r_squared': model.rsquared,
                'adj_r_squared': model.rsquared_adj,
                'f_stat': model.fvalue,
                'f_pvalue': model.f_pvalue,
                'coefficients': model.params.to_dict(),
                'std_errors': model.bse.to_dict(),
                'p_values': model.pvalues.to_dict(),
                'conf_int': model.conf_int().to_dict(),
                'marginal_effects': marginal_effects,
                'summary': str(model.summary()),
                'model_object': model
            }
            
            # æ£€æŸ¥å¤šé‡å…±çº¿æ€§
            try:
                vif_data = pd.DataFrame()
                vif_data["Variable"] = X.columns
                vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
                result['vif'] = vif_data.to_dict('records')
            except:
                result['vif'] = None
            
            # å¼‚è´¨æ€§æ£€éªŒ
            try:
                lm, lm_pvalue, fvalue, f_pvalue = het_breuschpagan(model.resid, model.model.exog)
                result['heteroskedasticity_test'] = {
                    'lm_stat': lm,
                    'lm_pvalue': lm_pvalue,
                    'f_stat': fvalue,
                    'f_pvalue': f_pvalue
                }
            except:
                result['heteroskedasticity_test'] = None
                
            return result
            
        except Exception as e:
            logger.error(f"âŒ å›å½’åˆ†æå¤±è´¥ {model_name}: {str(e)}")
            return self._create_empty_result(model_name)
    
    def _run_simple_regression(self, data: pd.DataFrame, outcome_var: str,
                             explanatory_vars: List[str], model_name: str) -> Dict[str, Any]:
        """ç®€åŒ–ç‰ˆå›å½’åˆ†æï¼ˆå½“statsmodelsä¸å¯ç”¨æ—¶ï¼‰"""
        
        try:
            from sklearn.linear_model import LinearRegression
            from sklearn.metrics import r2_score
            
            y = data[outcome_var].values
            X = data[explanatory_vars].values
            
            model = LinearRegression().fit(X, y)
            y_pred = model.predict(X)
            
            result = {
                'model_name': model_name,
                'n_obs': len(data),
                'r_squared': r2_score(y, y_pred),
                'coefficients': {var: coef for var, coef in zip(explanatory_vars, model.coef_)},
                'intercept': model.intercept_,
                'summary': f"ç®€åŒ–å›å½’æ¨¡å‹ {model_name}ï¼ŒRÂ² = {r2_score(y, y_pred):.4f}",
                'marginal_effects': None
            }
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ç®€åŒ–å›å½’åˆ†æå¤±è´¥ {model_name}: {str(e)}")
            return self._create_empty_result(model_name)
    
    def _calculate_marginal_effects(self, data: pd.DataFrame, vars_list: List[str], 
                                  model) -> Dict[str, Any]:
        """è®¡ç®—äº¤äº’é¡¹çš„è¾¹é™…æ•ˆåº”"""
        
        marginal_effects = {}
        
        # æ‰¾åˆ°äº¤äº’é¡¹
        interaction_vars = [var for var in vars_list if '_x_' in var]
        
        for int_var in interaction_vars:
            try:
                # è§£æäº¤äº’é¡¹åç§°
                var1, var2 = int_var.split('_x_')
                
                if var1 in data.columns and var2 in data.columns:
                    # è®¡ç®—åœ¨ä¸åŒvar2æ°´å¹³ä¸‹var1çš„è¾¹é™…æ•ˆåº”
                    var2_values = np.percentile(data[var2], [10, 25, 50, 75, 90])
                    
                    effects = []
                    for val in var2_values:
                        # è¾¹é™…æ•ˆåº” = Î²1 + Î²_interaction * var2_value
                        if var1 in model.params.index and int_var in model.params.index:
                            marginal_effect = model.params[var1] + model.params[int_var] * val
                            effects.append({
                                f'{var2}_value': val,
                                'marginal_effect': marginal_effect,
                                'percentile': np.where(var2_values == val)[0][0] * 20 + 10
                            })
                    
                    marginal_effects[int_var] = effects
                    
            except Exception as e:
                logger.warning(f"âš ï¸ æ— æ³•è®¡ç®— {int_var} çš„è¾¹é™…æ•ˆåº”: {str(e)}")
        
        return marginal_effects
    
    def _create_empty_result(self, model_name: str) -> Dict[str, Any]:
        """åˆ›å»ºç©ºçš„ç»“æœå­—å…¸"""
        return {
            'model_name': model_name,
            'n_obs': 0,
            'r_squared': np.nan,
            'coefficients': {},
            'p_values': {},
            'summary': f"æ¨¡å‹ {model_name} è¿è¡Œå¤±è´¥",
            'marginal_effects': None,
            'error': True
        }
    
    def create_results_table(self) -> pd.DataFrame:
        """
        åˆ›å»ºç»“æœæ±‡æ€»è¡¨
        
        Returns:
            åŒ…å«æ‰€æœ‰æ¨¡å‹ç»“æœçš„DataFrame
        """
        logger.info("ğŸ“‹ åˆ›å»ºç»“æœæ±‡æ€»è¡¨...")
        
        all_results = {**self.global_results, **self.local_results}
        
        if not all_results:
            logger.warning("âš ï¸ æ²¡æœ‰åˆ†æç»“æœå¯ä¾›æ±‡æ€»")
            return pd.DataFrame()
        
        rows = []
        for model_name, result in all_results.items():
            if result.get('error'):
                continue
                
            # æå–ä¸»è¦ç³»æ•°
            coeffs = result.get('coefficients', {})
            p_values = result.get('p_values', {})
            
            # æ‰¾åˆ°äº¤äº’é¡¹
            interaction_vars = [var for var in coeffs.keys() if '_x_' in var]
            
            for int_var in interaction_vars:
                row = {
                    'model': model_name,
                    'interaction_term': int_var,
                    'coefficient': coeffs.get(int_var, np.nan),
                    'p_value': p_values.get(int_var, np.nan),
                    'significant': p_values.get(int_var, 1.0) < 0.05,
                    'n_obs': result.get('n_obs', 0),
                    'r_squared': result.get('r_squared', np.nan),
                    'analysis_type': 'Global' if any(x in model_name for x in ['global', 'network']) else 'Local'
                }
                rows.append(row)
        
        results_df = pd.DataFrame(rows)
        
        if len(results_df) > 0:
            # æŒ‰æ˜¾è‘—æ€§å’Œç³»æ•°å¤§å°æ’åº
            results_df = results_df.sort_values(['significant', 'coefficient'], ascending=[False, False])
            logger.info(f"âœ… ç»“æœè¡¨åˆ›å»ºå®Œæˆï¼Œå…± {len(results_df)} ä¸ªäº¤äº’é¡¹")
        else:
            logger.warning("âš ï¸ ç»“æœè¡¨ä¸ºç©º")
        
        return results_df
    
    def get_significant_interactions(self, alpha: float = 0.05) -> Dict[str, Any]:
        """
        è·å–æ˜¾è‘—çš„äº¤äº’æ•ˆåº”
        
        Args:
            alpha: æ˜¾è‘—æ€§æ°´å¹³
            
        Returns:
            æ˜¾è‘—äº¤äº’æ•ˆåº”çš„æ‘˜è¦
        """
        results_df = self.create_results_table()
        
        if len(results_df) == 0:
            return {
                'total_interactions': 0,
                'significant_interactions': 0,
                'significance_rate': 0,
                'significant_details': [],
                'strongest_effect': None,
                'summary': 'æ²¡æœ‰å‘ç°æ˜¾è‘—çš„äº¤äº’æ•ˆåº”'
            }
        
        significant = results_df[results_df['p_value'] < alpha]
        
        summary = {
            'total_interactions': len(results_df),
            'significant_interactions': len(significant),
            'significance_rate': len(significant) / len(results_df) if len(results_df) > 0 else 0,
            'significant_details': significant.to_dict('records') if len(significant) > 0 else [],
            'strongest_effect': {
                'interaction': significant.iloc[0]['interaction_term'] if len(significant) > 0 else None,
                'coefficient': significant.iloc[0]['coefficient'] if len(significant) > 0 else None,
                'p_value': significant.iloc[0]['p_value'] if len(significant) > 0 else None
            } if len(significant) > 0 else None
        }
        
        logger.info(f"ğŸ¯ å‘ç° {len(significant)} ä¸ªæ˜¾è‘—äº¤äº’æ•ˆåº”ï¼ˆÎ±={alpha}ï¼‰")
        
        return summary


def main():
    """æµ‹è¯•åˆ†æåŠŸèƒ½"""
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    np.random.seed(42)
    n = 100
    
    test_data = pd.DataFrame({
        'resilience_score': np.random.normal(0.7, 0.2, n),
        'dli_composite': np.random.normal(0.4, 0.15, n),
        'global_density': np.random.normal(0.3, 0.1, n),
        'betweenness_centrality': np.random.exponential(0.1, n),
        'control_var1': np.random.normal(0, 1, n),
        'control_var2': np.random.normal(0, 1, n)
    })
    
    # è¿è¡Œåˆ†æ
    analyzer = HeterogeneityAnalyzer()
    
    global_results = analyzer.run_global_analysis(test_data)
    local_results = analyzer.run_local_analysis(test_data)
    
    # æŸ¥çœ‹ç»“æœ
    results_table = analyzer.create_results_table()
    print("ğŸ“Š åˆ†æç»“æœæ±‡æ€»:")
    print(results_table)
    
    significant = analyzer.get_significant_interactions()
    print("\nğŸ¯ æ˜¾è‘—äº¤äº’æ•ˆåº”:")
    print(significant)


if __name__ == "__main__":
    main()