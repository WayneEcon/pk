#!/usr/bin/env python3
"""
ç½‘ç»œç»“æ„å¼‚è´¨æ€§åˆ†æä¸»ç¨‹åº (Network Heterogeneity Analysis Main)
==========================================================

æœ¬ç¨‹åºæ˜¯æ¨¡å—08çš„ä¸»æ‰§è¡Œæ¥å£ï¼Œæ•´åˆæ•°æ®åŠ è½½ã€æ ¸å¿ƒåˆ†æå’Œå¯è§†åŒ–åŠŸèƒ½ï¼Œ
å®Œæˆ"åŒå‘åŠ¨æ€é”å®šæ•ˆåº”(DLI)ç½‘ç»œç»“æ„å¼‚è´¨æ€§"çš„å®Œæ•´åˆ†ææµç¨‹ã€‚

æ ¸å¿ƒç ”ç©¶é—®é¢˜ï¼š
Q1 (å…¨å±€å¼‚è´¨æ€§): DLIå¯¹ç½‘ç»œéŸ§æ€§çš„å› æœæ•ˆåº”ï¼Œæ˜¯å¦åœ¨æ›´ç¨ å¯†ã€æ›´é›†èšã€æˆ–æ›´ä¸­å¿ƒåŒ–çš„ç½‘ç»œä¸­è¡¨ç°å¾—ä¸åŒï¼Ÿ
Q2 (å±€éƒ¨å¼‚è´¨æ€§): è´¸æ˜“å…³ç³»çš„é”å®šæ•ˆåº”ï¼Œæ˜¯å¦ä¼šå› è´¸æ˜“åŒæ–¹åœ¨ç½‘ç»œä¸­çš„é‡è¦æ€§è€Œå¾—åˆ°æ”¾å¤§æˆ–ç¼©å°ï¼Ÿ

æ‰§è¡Œæµç¨‹ï¼š
1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
2. å…¨å±€å¼‚è´¨æ€§åˆ†æ (DLI Ã— å…¨å±€ç½‘ç»œæŒ‡æ ‡)
3. å±€éƒ¨å¼‚è´¨æ€§åˆ†æ (DLI Ã— å±€éƒ¨èŠ‚ç‚¹æŒ‡æ ‡)
4. å¯è§†åŒ–ç”Ÿæˆ
5. ç»“æœè¾“å‡ºä¸æ±‡æ€»

ä½œè€…ï¼šEnergy Network Analysis Team
ç‰ˆæœ¬ï¼šv1.0
"""

import sys
import logging
import argparse
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List
import traceback

# å¯¼å…¥åˆ†ææ¨¡å—
from data_loader import HeterogeneityDataLoader
from analysis import HeterogeneityAnalyzer
from visualizer import HeterogeneityVisualizer

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class NetworkHeterogeneityPipeline:
    """ç½‘ç»œç»“æ„å¼‚è´¨æ€§åˆ†æç®¡é“"""
    
    def __init__(self, output_dir: str = "outputs"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        (self.output_dir / "tables").mkdir(exist_ok=True)
        (self.output_dir / "figures").mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.data_loader = HeterogeneityDataLoader()
        self.analyzer = HeterogeneityAnalyzer()
        self.visualizer = HeterogeneityVisualizer(str(self.output_dir / "figures"))
        
        self.results = {}
        self.execution_time = None
        
        logger.info(f"ğŸš€ åˆå§‹åŒ–ç½‘ç»œå¼‚è´¨æ€§åˆ†æç®¡é“ï¼Œè¾“å‡ºç›®å½•: {self.output_dir}")
    
    def run_complete_analysis(self, config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„å¼‚è´¨æ€§åˆ†æ
        
        Args:
            config: é…ç½®å‚æ•°å­—å…¸
            
        Returns:
            åˆ†æç»“æœæ‘˜è¦
        """
        start_time = datetime.now()
        logger.info("=" * 60)
        logger.info("ğŸ¯ å¼€å§‹ç½‘ç»œç»“æ„å¼‚è´¨æ€§åˆ†æ")
        logger.info("=" * 60)
        
        try:
            # 1. æ•°æ®åŠ è½½
            logger.info("\nğŸ“Š ç¬¬1æ­¥ï¼šæ•°æ®åŠ è½½ä¸é¢„å¤„ç†")
            global_data, local_data = self.data_loader.create_analysis_dataset()
            
            if len(global_data) == 0 or len(local_data) == 0:
                raise ValueError("æ•°æ®é›†ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            
            logger.info(f"   âœ… å…¨å±€åˆ†ææ•°æ®é›†: {len(global_data)} è¡Œ")
            logger.info(f"   âœ… å±€éƒ¨åˆ†ææ•°æ®é›†: {len(local_data)} è¡Œ")
            
            # 2. å…¨å±€å¼‚è´¨æ€§åˆ†æ
            logger.info("\nğŸŒ ç¬¬2æ­¥ï¼šå…¨å±€å¼‚è´¨æ€§åˆ†æ (DLI Ã— å…¨å±€ç½‘ç»œæŒ‡æ ‡)")
            global_results = self.analyzer.run_global_analysis(
                global_data,
                dli_vars=config.get('dli_vars') if config else None,
                global_vars=config.get('global_vars') if config else None,
                control_vars=config.get('control_vars') if config else None,
                interactions_to_test=config.get('interactions_to_test', {}).get('global') if config else None
            )
            
            # 3. å±€éƒ¨å¼‚è´¨æ€§åˆ†æ
            logger.info("\nğŸ  ç¬¬3æ­¥ï¼šå±€éƒ¨å¼‚è´¨æ€§åˆ†æ (DLI Ã— å±€éƒ¨èŠ‚ç‚¹æŒ‡æ ‡)")
            local_results = self.analyzer.run_local_analysis(
                local_data,
                dli_vars=config.get('dli_vars') if config else None,
                local_vars=config.get('local_vars') if config else None,
                control_vars=config.get('control_vars') if config else None,
                interactions_to_test=config.get('interactions_to_test', {}).get('local') if config else None
            )
            
            # 4. ç»“æœæ±‡æ€»
            logger.info("\nğŸ“‹ ç¬¬4æ­¥ï¼šç»“æœæ±‡æ€»ä¸åˆ†æ")
            results_table = self.analyzer.create_results_table()
            significant_interactions = self.analyzer.get_significant_interactions()
            
            # 5. å¯è§†åŒ–ç”Ÿæˆ
            logger.info("\nğŸ¨ ç¬¬5æ­¥ï¼šå¯è§†åŒ–ç”Ÿæˆ")
            self._generate_visualizations(global_results, local_results, results_table, significant_interactions)
            
            # 6. è¾“å‡ºç»“æœ
            logger.info("\nğŸ’¾ ç¬¬6æ­¥ï¼šä¿å­˜åˆ†æç»“æœ")
            self._save_results(global_results, local_results, results_table, significant_interactions)
            
            # è®°å½•æ‰§è¡Œæ—¶é—´
            end_time = datetime.now()
            self.execution_time = end_time - start_time
            
            # ç”Ÿæˆæ‘˜è¦
            summary = self._create_analysis_summary(significant_interactions, results_table)
            
            logger.info("=" * 60)
            logger.info(f"âœ… ç½‘ç»œç»“æ„å¼‚è´¨æ€§åˆ†æå®Œæˆï¼è€—æ—¶: {self.execution_time}")
            logger.info("=" * 60)
            
            return summary
            
        except Exception as e:
            logger.error(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            logger.error(traceback.format_exc())
            raise e
    
    def run_quick_demo(self) -> Dict[str, Any]:
        """
        è¿è¡Œå¿«é€Ÿæ¼”ç¤ºåˆ†æ
        
        Returns:
            æ¼”ç¤ºåˆ†æç»“æœ
        """
        logger.info("ğŸš€ è¿è¡Œå¿«é€Ÿæ¼”ç¤ºæ¨¡å¼...")
        
        # ä½¿ç”¨é»˜è®¤é…ç½®å’Œç¤ºä¾‹æ•°æ® - ç²¾ç¡®æŒ‡å®šè¦æµ‹è¯•çš„äº¤äº’é¡¹
        demo_config = {
            'dli_vars': ['dli_composite'],
            'global_vars': ['global_density'],
            'local_vars': ['betweenness_centrality'],
            'control_vars': [],
            # ç²¾ç¡®æŒ‡å®šè¦æµ‹è¯•çš„äº¤äº’é¡¹ç»„åˆ
            'interactions_to_test': {
                'global': [
                    ['dli_composite', 'global_density']
                ],
                'local': [
                    ['dli_composite', 'betweenness_centrality']
                ]
            }
        }
        
        return self.run_complete_analysis(demo_config)
    
    def _generate_visualizations(self, global_results: Dict, local_results: Dict,
                               results_table, significant_interactions: Dict):
        """ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨"""
        
        try:
            # åˆå¹¶ç»“æœ
            all_results = {**global_results, **local_results}
            
            # è¾¹é™…æ•ˆåº”å›¾
            if all_results:
                self.visualizer.plot_marginal_effects(all_results, self.data_loader.causal_data or {})
            
            # äº¤äº’æ•ˆåº”çƒ­åŠ›å›¾
            if len(results_table) > 0:
                self.visualizer.plot_interaction_heatmap(results_table)
            
            # æ˜¾è‘—æ€§æ¦‚è§ˆå›¾
            if len(results_table) > 0:
                self.visualizer.plot_significance_overview(results_table)
            
            # å›å½’è¯Šæ–­å›¾
            if all_results:
                self.visualizer.plot_regression_diagnostics(all_results)
            
            # æ‘˜è¦æŠ¥å‘Šå›¾
            if significant_interactions:
                self.visualizer.create_summary_report_figure(significant_interactions)
            
            logger.info("âœ… æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {str(e)}")
    
    def _save_results(self, global_results: Dict, local_results: Dict,
                     results_table, significant_interactions: Dict):
        """ä¿å­˜åˆ†æç»“æœ"""
        
        try:
            # ä¿å­˜ç»“æœè¡¨æ ¼
            if len(results_table) > 0:
                results_path = self.output_dir / "tables" / "heterogeneity_results.csv"
                results_table.to_csv(results_path, index=False)
                logger.info(f"ğŸ’¾ ä¿å­˜ç»“æœè¡¨æ ¼: {results_path}")
            
            # ä¿å­˜æ˜¾è‘—äº¤äº’æ•ˆåº”
            if significant_interactions:
                sig_path = self.output_dir / "tables" / "significant_interactions.json"
                with open(sig_path, 'w', encoding='utf-8') as f:
                    json.dump(significant_interactions, f, indent=2, ensure_ascii=False)
                logger.info(f"ğŸ’¾ ä¿å­˜æ˜¾è‘—äº¤äº’æ•ˆåº”: {sig_path}")
            
            # ä¿å­˜å…¨éƒ¨å›å½’ç»“æœ
            all_results = {**global_results, **local_results}
            if all_results:
                # ç®€åŒ–ç»“æœç”¨äºJSONä¿å­˜
                simplified_results = {}
                for model_name, result in all_results.items():
                    simplified_results[model_name] = {
                        'model_name': result.get('model_name'),
                        'n_obs': result.get('n_obs'),
                        'r_squared': result.get('r_squared'),
                        'coefficients': result.get('coefficients', {}),
                        'p_values': result.get('p_values', {}),
                        'summary_stats': {
                            'significant_interactions': len([p for p in result.get('p_values', {}).values() 
                                                           if isinstance(p, (int, float)) and p < 0.05])
                        }
                    }
                
                results_path = self.output_dir / "tables" / "full_regression_results.json"
                with open(results_path, 'w', encoding='utf-8') as f:
                    json.dump(simplified_results, f, indent=2, ensure_ascii=False, default=str)
                logger.info(f"ğŸ’¾ ä¿å­˜å®Œæ•´å›å½’ç»“æœ: {results_path}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")
    
    def _create_analysis_summary(self, significant_interactions: Dict, 
                               results_table) -> Dict[str, Any]:
        """åˆ›å»ºåˆ†ææ‘˜è¦"""
        
        summary = {
            'analysis_type': 'Network Structure Heterogeneity Analysis',
            'execution_time': str(self.execution_time),
            'timestamp': datetime.now().isoformat(),
            'total_models': len(self.analyzer.global_results) + len(self.analyzer.local_results),
            'global_models': len(self.analyzer.global_results),
            'local_models': len(self.analyzer.local_results),
            'data_summary': {
                'global_dataset_size': len(self.data_loader.global_metrics) if self.data_loader.global_metrics is not None else 0,
                'local_dataset_size': len(self.data_loader.local_metrics) if self.data_loader.local_metrics is not None else 0
            },
            'significant_interactions': significant_interactions,
            'key_findings': self._extract_key_findings(significant_interactions, results_table),
            'output_files': {
                'tables': list((self.output_dir / "tables").glob("*.csv")) + list((self.output_dir / "tables").glob("*.json")),
                'figures': list((self.output_dir / "figures").glob("*.png"))
            }
        }
        
        return summary
    
    def _extract_key_findings(self, significant_interactions: Dict, results_table) -> List[str]:
        """æå–å…³é”®å‘ç°"""
        
        findings = []
        
        if significant_interactions:
            total = significant_interactions.get('total_interactions', 0)
            significant = significant_interactions.get('significant_interactions', 0)
            rate = significant_interactions.get('significance_rate', 0)
            
            findings.append(f"å…±æµ‹è¯•äº† {total} ä¸ªäº¤äº’æ•ˆåº”ï¼Œå…¶ä¸­ {significant} ä¸ªå…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§ ({rate:.1%})")
            
            if significant > 0:
                strongest = significant_interactions.get('strongest_effect')
                if strongest:
                    findings.append(f"æœ€å¼ºçš„äº¤äº’æ•ˆåº”æ¥è‡ª {strongest.get('interaction')}ï¼Œç³»æ•°ä¸º {strongest.get('coefficient'):.3f}")
            
            # åˆ†æç±»å‹å¯¹æ¯”
            if len(results_table) > 0:
                global_sig = len(results_table[(results_table['analysis_type'] == 'Global') & 
                                             (results_table['significant'] == True)])
                local_sig = len(results_table[(results_table['analysis_type'] == 'Local') & 
                                            (results_table['significant'] == True)])
                
                if global_sig > local_sig:
                    findings.append("å…¨å±€ç½‘ç»œç‰¹å¾å¯¹DLIæ•ˆåº”çš„è°ƒèŠ‚ä½œç”¨æ›´ä¸ºæ˜¾è‘—")
                elif local_sig > global_sig:
                    findings.append("å±€éƒ¨èŠ‚ç‚¹ç‰¹å¾å¯¹DLIæ•ˆåº”çš„è°ƒèŠ‚ä½œç”¨æ›´ä¸ºæ˜¾è‘—")
                else:
                    findings.append("å…¨å±€å’Œå±€éƒ¨ç½‘ç»œç‰¹å¾å¯¹DLIæ•ˆåº”çš„è°ƒèŠ‚ä½œç”¨ç›¸å½“")
        
        if not findings:
            findings.append("æœªå‘ç°æ˜¾è‘—çš„ç½‘ç»œç»“æ„å¼‚è´¨æ€§æ•ˆåº”")
        
        return findings
    
    def generate_final_report(self) -> str:
        """ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š"""
        
        report_path = self.output_dir / "heterogeneity_analysis_report.md"
        
        # è¯»å–åˆ†æç»“æœ
        results_table = None
        significant_interactions = None
        
        try:
            results_path = self.output_dir / "tables" / "heterogeneity_results.csv"
            if results_path.exists():
                import pandas as pd
                results_table = pd.read_csv(results_path)
        except:
            pass
            
        try:
            sig_path = self.output_dir / "tables" / "significant_interactions.json"
            if sig_path.exists():
                with open(sig_path, 'r', encoding='utf-8') as f:
                    significant_interactions = json.load(f)
        except:
            pass
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = f"""# ç½‘ç»œç»“æ„å¼‚è´¨æ€§åˆ†ææŠ¥å‘Š
## Network Structure Heterogeneity Analysis Report

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**åˆ†ææ¨¡å—**: 08_heterogeneity_analysis v1.0

---

## ğŸ¯ ç ”ç©¶ç›®æ ‡

æœ¬åˆ†ææ—¨åœ¨æ¢ç©¶åŒå‘åŠ¨æ€é”å®šæ•ˆåº”(DLI)æ˜¯å¦ä¼šå› èƒ½æºè´¸æ˜“ç½‘ç»œçš„æ‹“æ‰‘ç»“æ„ä¸åŒè€Œè¡¨ç°å‡ºå¼‚è´¨æ€§ï¼š

1. **å…¨å±€å¼‚è´¨æ€§**: DLIå¯¹ç½‘ç»œéŸ§æ€§çš„å› æœæ•ˆåº”æ˜¯å¦åœ¨æ›´ç¨ å¯†ã€æ›´é›†èšæˆ–æ›´ä¸­å¿ƒåŒ–çš„ç½‘ç»œä¸­è¡¨ç°ä¸åŒï¼Ÿ
2. **å±€éƒ¨å¼‚è´¨æ€§**: è´¸æ˜“å…³ç³»çš„é”å®šæ•ˆåº”æ˜¯å¦ä¼šå› è´¸æ˜“åŒæ–¹åœ¨ç½‘ç»œä¸­çš„é‡è¦æ€§è€Œå¾—åˆ°æ”¾å¤§æˆ–ç¼©å°ï¼Ÿ

---

## ğŸ“Š åˆ†æç»“æœæ‘˜è¦

"""
        
        if significant_interactions:
            total = significant_interactions.get('total_interactions', 0)
            significant = significant_interactions.get('significant_interactions', 0)
            rate = significant_interactions.get('significance_rate', 0)
            
            report_content += f"""### æ€»ä½“å‘ç°

- **äº¤äº’æ•ˆåº”æµ‹è¯•æ€»æ•°**: {total}
- **æ˜¾è‘—äº¤äº’æ•ˆåº”æ•°é‡**: {significant}
- **æ˜¾è‘—æ€§æ¯”ä¾‹**: {rate:.1%}

"""
            
            if significant > 0:
                strongest = significant_interactions.get('strongest_effect', {})
                report_content += f"""### æœ€å¼ºäº¤äº’æ•ˆåº”

- **å˜é‡ç»„åˆ**: {strongest.get('interaction', 'N/A')}
- **æ•ˆåº”ç³»æ•°**: {strongest.get('coefficient', 'N/A')}
- **æ˜¾è‘—æ€§æ°´å¹³**: {strongest.get('p_value', 'N/A')}

"""
        
        if results_table is not None and len(results_table) > 0:
            global_count = len(results_table[results_table['analysis_type'] == 'Global'])
            local_count = len(results_table[results_table['analysis_type'] == 'Local'])
            
            report_content += f"""### åˆ†æç±»å‹åˆ†å¸ƒ

- **å…¨å±€åˆ†ææ¨¡å‹**: {global_count}
- **å±€éƒ¨åˆ†ææ¨¡å‹**: {local_count}

"""
        
        report_content += f"""---

## ğŸ“ˆ å¯è§†åŒ–ç»“æœ

æœ¬åˆ†æç”Ÿæˆäº†ä»¥ä¸‹å¯è§†åŒ–å›¾è¡¨ï¼š

1. **äº¤äº’æ•ˆåº”çƒ­åŠ›å›¾** (`interaction_heatmap.png`)
   - å±•ç¤ºä¸åŒDLIå˜é‡ä¸ç½‘ç»œç‰¹å¾çš„äº¤äº’æ•ˆåº”å¼ºåº¦
   
2. **æ˜¾è‘—æ€§æ¦‚è§ˆå›¾** (`significance_overview.png`)
   - æ˜¾ç¤ºæ˜¾è‘—æ€§åˆ†å¸ƒã€ç³»æ•°åˆ†å¸ƒç­‰ç»Ÿè®¡æ¦‚è§ˆ
   
3. **è¾¹é™…æ•ˆåº”å›¾** (`marginal_effect_*.png`)
   - å±•ç¤ºåœ¨ä¸åŒç½‘ç»œç‰¹å¾æ°´å¹³ä¸‹DLIæ•ˆåº”çš„å˜åŒ–
   
4. **å›å½’è¯Šæ–­å›¾** (`diagnostics_*.png`)
   - å›å½’æ¨¡å‹çš„æ®‹å·®åˆ†æå’Œè¯Šæ–­æ£€éªŒ

---

## ğŸ” æ–¹æ³•è®ºè¯´æ˜

### åˆ†ææ–¹æ³•

æœ¬ç ”ç©¶åŸºäº05_causal_validationçš„åŸºå‡†å›å½’æ¨¡å‹ï¼Œå¼•å…¥DLIæŒ‡æ ‡ä¸ç½‘ç»œç‰¹å¾çš„äº¤äº’é¡¹ï¼š

**å…¨å±€åˆ†ææ¨¡å‹**:
```
Y ~ DLI + Global_Metric + DLI Ã— Global_Metric + Controls
```

**å±€éƒ¨åˆ†ææ¨¡å‹**:
```
Y ~ DLI + Local_Metric + DLI Ã— Local_Metric + Controls
```

### æ•°æ®æ¥æº

- **DLIæ•ˆåº”æŒ‡æ ‡**: æ¥è‡ª `04_dli_analysis` æ¨¡å—
- **å…¨å±€ç½‘ç»œæŒ‡æ ‡**: æ¥è‡ª `03_metrics` æ¨¡å—çš„ç½‘ç»œæ•´ä½“æ‹“æ‰‘æŒ‡æ ‡
- **å±€éƒ¨èŠ‚ç‚¹æŒ‡æ ‡**: æ¥è‡ª `03_metrics` æ¨¡å—çš„èŠ‚ç‚¹ä¸­å¿ƒæ€§æŒ‡æ ‡
- **å› æœåˆ†ææ•°æ®**: æ¥è‡ª `05_causal_validation` æ¨¡å—çš„åŸºå‡†å›å½’å˜é‡

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶

### æ•°æ®è¡¨æ ¼
- `heterogeneity_results.csv`: å®Œæ•´çš„å›å½’ç»“æœæ±‡æ€»è¡¨
- `significant_interactions.json`: æ˜¾è‘—äº¤äº’æ•ˆåº”çš„è¯¦ç»†ä¿¡æ¯
- `full_regression_results.json`: æ‰€æœ‰å›å½’æ¨¡å‹çš„å®Œæ•´ç»“æœ

### å¯è§†åŒ–å›¾è¡¨
- æ‰€æœ‰å›¾è¡¨ä¿å­˜åœ¨ `outputs/figures/` ç›®å½•ä¸‹
- æ”¯æŒé«˜åˆ†è¾¨ç‡PNGæ ¼å¼ï¼Œé€‚åˆå­¦æœ¯å‘è¡¨

---

## ğŸ’¡ ç ”ç©¶æ„ä¹‰

æœ¬åˆ†ææ­ç¤ºäº†ç½‘ç»œç»“æ„å¯¹DLIæ•ˆåº”çš„è°ƒèŠ‚ä½œç”¨ï¼Œä¸ºç†è§£èƒ½æºè´¸æ˜“é”å®šæ•ˆåº”çš„å¤æ‚æ€§æä¾›äº†æ–°çš„è§†è§’ã€‚ç ”ç©¶å‘ç°æœ‰åŠ©äºï¼š

1. **ç†è®ºè´¡çŒ®**: ä¸°å¯Œäº†åŠ¨æ€é”å®šç†è®ºçš„ç½‘ç»œç»´åº¦
2. **æ”¿ç­–å¯ç¤º**: ä¸ºèƒ½æºæ”¿ç­–åˆ¶å®šæä¾›ç½‘ç»œç»“æ„çš„è€ƒè™‘å› ç´ 
3. **æ–¹æ³•åˆ›æ–°**: å»ºç«‹äº†ç½‘ç»œå¼‚è´¨æ€§åˆ†æçš„æ ‡å‡†åŒ–æ¡†æ¶

---

*æœ¬æŠ¥å‘Šç”± Network Heterogeneity Analysis Pipeline v1.0 è‡ªåŠ¨ç”Ÿæˆ*  
*Energy Network Analysis Team*
"""
        
        # ä¿å­˜æŠ¥å‘Š
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"ğŸ“‹ æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return str(report_path)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç½‘ç»œç»“æ„å¼‚è´¨æ€§åˆ†æ')
    parser.add_argument('--mode', choices=['full', 'demo'], default='demo',
                       help='åˆ†ææ¨¡å¼: full=å®Œæ•´åˆ†æ, demo=å¿«é€Ÿæ¼”ç¤º')
    parser.add_argument('--output-dir', default='outputs',
                       help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--config', type=str,
                       help='é…ç½®æ–‡ä»¶è·¯å¾„(JSONæ ¼å¼)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ†æç®¡é“
    pipeline = NetworkHeterogeneityPipeline(args.output_dir)
    
    try:
        # åŠ è½½é…ç½®
        config = None
        if args.config and Path(args.config).exists():
            with open(args.config, 'r', encoding='utf-8') as f:
                config = json.load(f)
        
        # è¿è¡Œåˆ†æ
        if args.mode == 'demo':
            summary = pipeline.run_quick_demo()
        else:
            summary = pipeline.run_complete_analysis(config)
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        report_path = pipeline.generate_final_report()
        
        # è¾“å‡ºæ‘˜è¦
        print("\n" + "="*60)
        print("ğŸ“Š ç½‘ç»œç»“æ„å¼‚è´¨æ€§åˆ†æå®Œæˆ!")
        print("="*60)
        print(f"æ‰§è¡Œæ—¶é—´: {summary.get('execution_time', 'N/A')}")
        print(f"æ€»æ¨¡å‹æ•°: {summary.get('total_models', 0)}")
        print(f"æ˜¾è‘—äº¤äº’: {summary.get('significant_interactions', {}).get('significant_interactions', 0)}")
        print(f"æœ€ç»ˆæŠ¥å‘Š: {report_path}")
        print("="*60)
        
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()