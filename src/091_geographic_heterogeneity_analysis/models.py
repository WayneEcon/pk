#!/usr/bin/env python3
"""
è®¡é‡æ¨¡å‹æ¨¡å— (Econometric Models Module)
=====================================

09_econometric_analysis æ¨¡å—çš„æ ¸å¿ƒè®¡é‡æ¨¡å‹å®ç°

ç†è®ºæ¡†æ¶ï¼šé”šå®šå¤šæ ·åŒ–å‡è¯´ (Anchored Diversification Hypothesis)
============================================================

æ ¸å¿ƒç ”ç©¶é—®é¢˜ï¼š
ä¸€ä¸ªå›½å®¶ä¸ç¾å›½å»ºç«‹æ›´ç´§å¯†çš„èƒ½æºç½‘ç»œå…³ç³»ï¼Œæ˜¯å¦æœ‰åŠ©äºå…¶æ•´ä½“èƒ½æºè¿›å£æ¥æºçš„å¤šå…ƒåŒ–ï¼Ÿ

æ ¸å¿ƒæ¨¡å‹è®¾å®šï¼š
HHI_imports_{i,t} = Î²Â·NodeDLI^{US}_{i,t} + Î“Â·Controls_{i,t} + Î±_i + Î»_t + Îµ_{i,t}

ç†è®ºé¢„æœŸï¼šÎ² < 0
- é”šå®šå¤šæ ·åŒ–å‡è¯´è®¤ä¸ºï¼Œä¸ä¸»è¦èƒ½æºå‡ºå£å›½ï¼ˆç¾å›½ï¼‰å»ºç«‹ç¨³å®šçš„èƒ½æºç½‘ç»œå…³ç³»ï¼Œ
  ä¸ºè¿›å£å›½æä¾›äº†ä¸€ä¸ªå¯é çš„"é”šç‚¹"ï¼Œä»è€Œé™ä½äº†å¯¹ä»»ä½•å•ä¸€ä¾›åº”å•†çš„ä¾èµ–ï¼Œ
  é¼“åŠ±è¿›å£å¤šæ ·åŒ–ç­–ç•¥ï¼Œæœ€ç»ˆå¯¼è‡´hhi_importsæŒ‡æ•°ä¸‹é™ã€‚

å­¦æœ¯ä¸¥è°¨æ€§è€ƒè™‘ï¼š
1. èšç±»ç¨³å¥æ ‡å‡†è¯¯ï¼šæ‰€æœ‰é¢æ¿å›å½’ä½¿ç”¨æŒ‰å›½å®¶èšç±»çš„ç¨³å¥æ ‡å‡†è¯¯ï¼Œæ ¡æ­£å›½å®¶å†…è§‚æµ‹å€¼çš„åºåˆ—ç›¸å…³æ€§
2. é¿å…æ„é€ å†…ç”Ÿæ€§ï¼šæ ¸å¿ƒæ¨¡å‹ç›´æ¥ä½¿ç”¨hhi_importsï¼Œé¿å…ä¹‹å‰vul_us=f(us_import_share, hhi_imports)çš„å¾ªç¯è®ºè¯
3. åŒå‘å›ºå®šæ•ˆåº”ï¼šæ§åˆ¶å›½å®¶å¼‚è´¨æ€§å’Œæ—¶é—´è¶‹åŠ¿çš„å½±å“

æ¨¡å‹å±€é™æ€§ä¸æœªæ¥æ–¹å‘ï¼š
è­¦å‘Šï¼šæœ¬æ¨¡å‹ç»“æœåº”è¢«ä¸¥è°¨åœ°è§£è¯»ä¸ºç›¸å…³æ€§è¯æ®è€Œéä¸¥æ ¼å› æœæ•ˆåº”ï¼Œä¸»è¦æŒ‘æˆ˜åŒ…æ‹¬ï¼š
1. é—æ¼å˜é‡åè¯¯ï¼šåˆ¶åº¦è´¨é‡ã€æ”¿æ²»ç«‹åœºç­‰ä¸å¯è§‚æµ‹å› ç´ å¯èƒ½åŒæ—¶å½±å“NodeDLI_USå’ŒHHI
2. åå‘å› æœï¼šå¤šæ ·åŒ–ç¨‹åº¦é«˜çš„å›½å®¶å¯èƒ½æ›´å®¹æ˜“å¸å¼•ç¾å›½å»ºç«‹èƒ½æºåˆä½œå…³ç³»
3. æœªæ¥ç ”ç©¶æ–¹å‘ï¼šè€ƒè™‘ä½¿ç”¨å·¥å…·å˜é‡æ³•ï¼ˆBartikå¼æˆ–é‡åŠ›æ¨¡å‹å¼ï¼‰è¿›è¡Œå› æœè¯†åˆ«

ä½œè€…ï¼šEnergy Network Analysis Team
ç‰ˆæœ¬ï¼šv2.0 - é”šå®šå¤šæ ·åŒ–å‡è¯´ç‰ˆæœ¬ï¼ˆå«å±€é™æ€§è®¨è®ºï¼‰
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
import logging
from pathlib import Path
import warnings

# è®¡é‡åˆ†æåº“å¯¼å…¥ (æ¡ä»¶å¯¼å…¥ä»¥å¤„ç†ç¼ºå¤±ä¾èµ–)
try:
    import statsmodels.api as sm
    from statsmodels.formula.api import ols
    from statsmodels.stats.diagnostic import het_breuschpagan, het_white
    from statsmodels.stats.stattools import durbin_watson
    HAS_STATSMODELS = True
except ImportError:
    HAS_STATSMODELS = False

try:
    from linearmodels import PanelOLS, PooledOLS
    HAS_LINEARMODELS = True
except ImportError:
    HAS_LINEARMODELS = False

# ç®€åŒ–çš„é…ç½®è®¾ç½®
class SimpleConfig:
    def __init__(self):
        self.validation = type('obj', (object,), {'DATA_QUALITY_THRESHOLDS': {'min_observations': 20}})
        self.analysis = type('obj', (object,), {'RESEARCH_MODELS': {}})
    
    def get_control_variables(self, control_type):
        if control_type == 'macro_controls':
            return ['log_gdp', 'log_population']
        return []

# ä½¿ç”¨ç®€åŒ–é…ç½®
config = SimpleConfig()

logger = logging.getLogger(__name__)

class EconometricModels:
    """
    è®¡é‡åˆ†ææ¨¡å‹ç±» - å®ç°ç©ºæ•°æ®å…¼å®¹çš„è®¡é‡åˆ†ææ¡†æ¶
    """
    
    def __init__(self):
        """åˆå§‹åŒ–è®¡é‡æ¨¡å‹åˆ†æå™¨"""
        self.config = config
        self.results = {}
        
        logger.info("ğŸ”¬ è®¡é‡æ¨¡å‹åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        
        # æ£€æŸ¥ä¾èµ–åº“å¯ç”¨æ€§
        if not HAS_STATSMODELS:
            logger.warning("âš ï¸ statsmodelsåº“ä¸å¯ç”¨ï¼Œéƒ¨åˆ†åŠŸèƒ½å—é™")
        if not HAS_LINEARMODELS:
            logger.warning("âš ï¸ linearmodelsåº“ä¸å¯ç”¨ï¼Œé¢æ¿æ•°æ®åˆ†æå—é™")
    
    def _check_data_availability(self, df: pd.DataFrame, required_vars: List[str]) -> Tuple[Dict[str, Any], pd.DataFrame]:
        """
        æ£€æŸ¥æ•°æ®å¯ç”¨æ€§ - åªæ£€æŸ¥å­˜åœ¨æ€§å’Œéç©ºæ€§ï¼Œä¸æ‰§è¡Œdropna()
        
        Args:
            df: è¾“å…¥æ•°æ®
            required_vars: å¿…éœ€å˜é‡åˆ—è¡¨
            
        Returns:
            (æ£€æŸ¥ç»“æœå­—å…¸, åŸå§‹æœªä¿®æ”¹çš„DataFrame)
        """
        check_result = {
            'data_available': False,
            'missing_vars': [],
            'empty_vars': [],
            'total_obs': 0,
            'status_message': ''
        }
        
        # åŸºç¡€æ£€æŸ¥ï¼šæ•°æ®æ˜¯å¦ä¸ºç©º
        if df is None or len(df) == 0:
            check_result['status_message'] = 'æ•°æ®é›†ä¸ºç©ºæˆ–ä¸å­˜åœ¨'
            return check_result, df
        
        check_result['total_obs'] = len(df)
        
        # æ£€æŸ¥å˜é‡æ˜¯å¦å­˜åœ¨
        missing_vars = [var for var in required_vars if var not in df.columns]
        if missing_vars:
            check_result['missing_vars'] = missing_vars
            check_result['status_message'] = f'ç¼ºå°‘å¿…éœ€å˜é‡: {missing_vars}'
            return check_result, df
        
        # æ£€æŸ¥å˜é‡æ˜¯å¦å…¨ä¸ºç©º
        empty_vars = [var for var in required_vars if df[var].isna().all()]
        if empty_vars:
            check_result['empty_vars'] = empty_vars
            check_result['status_message'] = f'å˜é‡æ•°æ®å…¨ä¸ºç©º: {empty_vars}'
            return check_result, df
        
        # æ•°æ®æ£€æŸ¥é€šè¿‡
        check_result['data_available'] = True
        check_result['status_message'] = 'æ•°æ®æ£€æŸ¥é€šè¿‡'
        
        return check_result, df
    
    def _create_empty_result(self, model_name: str, status_message: str) -> Dict[str, Any]:
        """
        åˆ›å»ºç©ºç»“æœå­—å…¸
        
        Args:
            model_name: æ¨¡å‹åç§°
            status_message: çŠ¶æ€ä¿¡æ¯
            
        Returns:
            ç©ºç»“æœå­—å…¸
        """
        return {
            'model_name': model_name,
            'model_type': self.config.analysis.RESEARCH_MODELS.get(model_name, {}).get('method', 'unknown'),
            'status': 'failed',
            'status_message': status_message,
            'coefficients': {},
            'std_errors': {},
            'p_values': {},
            'r_squared': np.nan,
            'n_obs': 0,
            'n_entities': 0,
            'diagnostics': {},
            'estimation_time': 0.0,
            'formula': self.config.analysis.RESEARCH_MODELS.get(model_name, {}).get('formula', ''),
            'data_available': False
        }
    
    def run_dli_hhi_association(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        æ ¸å¿ƒæ¨¡å‹: DLI-HHIå…³è”æ£€éªŒï¼ˆé”šå®šå¤šæ ·åŒ–å‡è¯´ï¼‰
        åŒå‘å›ºå®šæ•ˆåº”é¢æ¿æ¨¡å‹: HHI_{i,t} = Î²Â·NodeDLI^{US}_{i,t} + Î“Â·Controls_{i,t} + Î±_i + Î»_t + Îµ_{i,t}
        
        ç ”ç©¶é—®é¢˜: ä¸€ä¸ªå›½å®¶ä¸ç¾å›½å»ºç«‹æ›´ç´§å¯†çš„èƒ½æºç½‘ç»œå…³ç³»ï¼Œæ˜¯å¦æœ‰åŠ©äºå…¶æ•´ä½“èƒ½æºè¿›å£æ¥æºçš„å¤šå…ƒåŒ–ï¼Ÿ
        
        ç†è®ºé¢„æœŸ: Î² < 0 (ä¸ç¾å›½å…³ç³»è¶Šç´§å¯†ï¼Œè¿›å£æ¥æºè¶Šå¤šæ ·åŒ–ï¼ŒHHIè¶Šä½)
        
        Args:
            df: åˆ†ææ•°æ®
            
        Returns:
            æ¨¡å‹ç»“æœå­—å…¸
        """
        model_name = 'model_1_dli_hhi_association'
        logger.info(f"ğŸ” è¿è¡Œæ ¸å¿ƒæ¨¡å‹1: DLI-HHIå…³è”æ£€éªŒï¼ˆé”šå®šå¤šæ ·åŒ–å‡è¯´ï¼‰...")
        
        # åŠ¨æ€æ„å»ºå¿…éœ€å˜é‡åˆ—è¡¨  
        dependent_var = 'hhi_imports'
        explanatory_vars = ['node_dli_us'] + self.config.get_control_variables('macro_controls')
        required_vars = [dependent_var] + explanatory_vars + ['year', 'country']
        
        # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§ (åªæ£€æŸ¥å­˜åœ¨æ€§ï¼Œä¸æ‰§è¡Œdropna)
        data_check, df_checked = self._check_data_availability(df, required_vars)
        if not data_check['data_available']:
            logger.warning(f"   âš ï¸ {data_check['status_message']}")
            return self._create_empty_result(model_name, data_check['status_message'])
        
        # åˆ›å»ºè¯¥æ¨¡å‹çš„ä¸“ç”¨æ•°æ®å­é›†
        analysis_data = df_checked[required_vars].dropna().copy()
        
        # è®°å½•æ•°æ®å¤„ç†çš„å½±å“
        logger.info(f"   Data for Model 1: Started with {len(df_checked)} obs, using {len(analysis_data)} after handling missing values.")
        
        # æ£€æŸ¥å¤„ç†åçš„è§‚æµ‹æ•°æ˜¯å¦è¶³å¤Ÿ
        if len(analysis_data) < self.config.validation.DATA_QUALITY_THRESHOLDS['min_observations']:
            error_msg = f'å¤„ç†ç¼ºå¤±å€¼åè§‚æµ‹æ•°ä¸è¶³: {len(analysis_data)} < {self.config.validation.DATA_QUALITY_THRESHOLDS["min_observations"]}'
            logger.warning(f"   âš ï¸ {error_msg}")
            return self._create_empty_result(model_name, error_msg)
        
        # å¦‚æœæ²¡æœ‰statsmodelsæˆ–linearmodelsï¼Œè¿”å›ç©ºç»“æœ
        if not HAS_STATSMODELS or not HAS_LINEARMODELS:
            return self._create_empty_result(model_name, 'ç¼ºå°‘å¿…éœ€çš„è®¡é‡åˆ†æåº“')
        
        try:
            # è®¾ç½®é¢æ¿æ•°æ®ç´¢å¼•
            analysis_data = analysis_data.set_index(['country', 'year'])
            
            # åŠ¨æ€æ„å»ºå…¬å¼ (ç”¨äºè®°å½•ç›®çš„)
            formula = f"{dependent_var} ~ {' + '.join(explanatory_vars)} + EntityEffects + TimeEffects"
            
            # è¿è¡ŒåŒå‘å›ºå®šæ•ˆåº”æ¨¡å‹ï¼ˆèšç±»ç¨³å¥æ ‡å‡†è¯¯ï¼‰
            logger.info(f"   ä¼°è®¡é”šå®šå¤šæ ·åŒ–å‡è¯´æ¨¡å‹...")
            
            model = PanelOLS(
                dependent=analysis_data[dependent_var],
                exog=analysis_data[explanatory_vars],
                entity_effects=True,    # ä¸ªä½“å›ºå®šæ•ˆåº”
                time_effects=True,      # æ—¶é—´å›ºå®šæ•ˆåº”
                check_rank=False        # è·³è¿‡rankæ£€æŸ¥ä»¥å¤„ç†å°æ ·æœ¬
            )
            
            # ä½¿ç”¨æŒ‰å›½å®¶èšç±»çš„ç¨³å¥æ ‡å‡†è¯¯æ¥æ ¡æ­£å›½å®¶å†…è§‚æµ‹å€¼çš„åºåˆ—ç›¸å…³æ€§
            results = model.fit(cov_type='clustered', cluster_entity=True)
            
            # æå–ç»“æœ
            result_dict = {
                'model_name': model_name,
                'model_type': 'two_way_fixed_effects',
                'status': 'success',
                'status_message': 'æ¨¡å‹ä¼°è®¡æˆåŠŸ',
                'coefficients': dict(results.params),
                'std_errors': dict(results.std_errors),
                'p_values': dict(results.pvalues),
                'r_squared': float(results.rsquared),
                'r_squared_within': float(results.rsquared_within) if hasattr(results, 'rsquared_within') else np.nan,
                'n_obs': int(results.nobs),
                'n_entities': len(analysis_data.index.get_level_values('country').unique()),
                'f_statistic': float(results.f_statistic.stat) if hasattr(results, 'f_statistic') else np.nan,
                'formula': formula,
                'data_available': True,
                'estimation_time': 0.0,  # å¯ä»¥æ·»åŠ è®¡æ—¶åŠŸèƒ½
                'diagnostics': self._run_model_diagnostics(analysis_data, results)
            }
            
            logger.info(f"   âœ… æ ¸å¿ƒæ¨¡å‹ä¼°è®¡å®Œæˆ: RÂ²={result_dict['r_squared']:.4f}, N={result_dict['n_obs']}")
            
            # æ£€éªŒé”šå®šå¤šæ ·åŒ–å‡è¯´
            node_dli_coef = result_dict['coefficients'].get('node_dli_us', np.nan)
            if not np.isnan(node_dli_coef):
                hypothesis_supported = node_dli_coef < 0
                logger.info(f"   é”šå®šå¤šæ ·åŒ–å‡è¯´æ£€éªŒ: Î²={node_dli_coef:.4f}, å‡è¯´{'æ”¯æŒ' if hypothesis_supported else 'ä¸æ”¯æŒ'}")
            
            return result_dict
            
        except Exception as e:
            error_msg = f"æ¨¡å‹ä¼°è®¡å¤±è´¥: {str(e)}"
            logger.error(f"   âŒ {error_msg}")
            return self._create_empty_result(model_name, error_msg)
    
    
    def run_local_projection_shock_validation(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        æ¨¡å‹3: å±€éƒ¨æŠ•å½±å› æœéªŒè¯
        å±€éƒ¨æŠ•å½±æ¨¡å‹: Î”Y(t+h) ~ US_ProdShock(t) * OVI_gas(t-1) + Controls
        
        Args:
            df: åˆ†ææ•°æ®
            
        Returns:
            æ¨¡å‹ç»“æœå­—å…¸
        """
        model_name = 'model_3_local_projection_validation'
        logger.info(f"ğŸ” è¿è¡Œæ¨¡å‹3: å±€éƒ¨æŠ•å½±å› æœéªŒè¯...")
        
        # åŠ¨æ€æ„å»ºå¿…éœ€å˜é‡åˆ—è¡¨ - é‡æ„åä½¿ç”¨hhi_importsæ›¿ä»£vul_us
        base_required_vars = ['hhi_imports', 'us_prod_shock', 'ovi_gas', 'year', 'country'] + self.config.get_control_variables('macro_controls')
        
        # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§ (åªæ£€æŸ¥å­˜åœ¨æ€§ï¼Œä¸æ‰§è¡Œdropna)
        data_check, df_checked = self._check_data_availability(df, base_required_vars)
        if not data_check['data_available']:
            logger.warning(f"   âš ï¸ {data_check['status_message']}")
            return self._create_empty_result(model_name, data_check['status_message'])
        
        if not HAS_STATSMODELS or not HAS_LINEARMODELS:
            return self._create_empty_result(model_name, 'ç¼ºå°‘å¿…éœ€çš„è®¡é‡åˆ†æåº“')
        
        try:
            # å‡†å¤‡æ•°æ®å¹¶åˆ›å»ºè½¬æ¢å˜é‡ (åœ¨dropnaä¹‹å‰)
            analysis_data = df_checked[base_required_vars].copy()
            analysis_data = analysis_data.sort_values(['country', 'year'])
            
            # åˆ›å»ºæ»åå˜é‡å’Œæœªæ¥å˜åŒ–
            analysis_data['ovi_gas_lag1'] = analysis_data.groupby('country')['ovi_gas'].shift(1)
            
            # è·å–é¢„æµ‹æœŸæ•°è®¾å®š
            horizons = [0, 1, 2, 3]  # é»˜è®¤é¢„æµ‹æœŸæ•°
            
            # ä¸ºä¸åŒé¢„æµ‹æœŸåˆ›å»ºå› å˜é‡ - ä½¿ç”¨hhi_importsæ›¿ä»£vul_us
            for h in horizons:
                if h == 0:
                    analysis_data[f'delta_hhi_h{h}'] = analysis_data.groupby('country')['hhi_imports'].diff()
                else:
                    analysis_data[f'delta_hhi_h{h}'] = (
                        analysis_data.groupby('country')['hhi_imports'].shift(-h) - 
                        analysis_data['hhi_imports']
                    )
            
            # åˆ›å»ºäº¤äº’é¡¹
            analysis_data['us_prod_shock_x_ovi_gas_lag1'] = (
                analysis_data['us_prod_shock'] * analysis_data['ovi_gas_lag1']
            )
            
            # æ„å»ºåŸºç¡€è§£é‡Šå˜é‡åˆ—è¡¨ (ç”¨äºæ‰€æœ‰é¢„æµ‹æœŸ)
            base_explanatory_vars = ['us_prod_shock', 'ovi_gas_lag1', 'us_prod_shock_x_ovi_gas_lag1'] + self.config.get_control_variables('macro_controls')
            
            # åˆ é™¤åŸºç¡€å˜é‡çš„ç¼ºå¤±æ•°æ®
            analysis_data = analysis_data.dropna(subset=base_explanatory_vars)
            
            # è®°å½•æ•°æ®å¤„ç†çš„å½±å“
            logger.info(f"   Data for Model 3: Started with {len(df_checked)} obs, using {len(analysis_data)} after handling missing values.")
            
            if len(analysis_data) < self.config.validation.DATA_QUALITY_THRESHOLDS['min_observations']:
                error_msg = f'åˆ›å»ºå±€éƒ¨æŠ•å½±å˜é‡åè§‚æµ‹æ•°ä¸è¶³: {len(analysis_data)} < {self.config.validation.DATA_QUALITY_THRESHOLDS["min_observations"]}'
                logger.warning(f"   âš ï¸ {error_msg}")
                return self._create_empty_result(model_name, error_msg)
            
            logger.info(f"   ä¼°è®¡å±€éƒ¨æŠ•å½±æ¨¡å‹ï¼Œé¢„æµ‹æœŸæ•°: {horizons}")
            
            # è¿è¡Œä¸åŒæ—¶é—´çª—å£çš„å±€éƒ¨æŠ•å½±
            horizon_results = {}
            overall_diagnostics = {}
            
            for h in horizons:
                dependent_var = f'delta_hhi_h{h}'
                
                # æ£€æŸ¥è¯¥æœŸæ•°çš„å› å˜é‡æ˜¯å¦å¯ç”¨
                if dependent_var not in analysis_data.columns or analysis_data[dependent_var].isna().all():
                    logger.warning(f"   è·³è¿‡é¢„æµ‹æœŸ h={h}: å› å˜é‡ä¸å¯ç”¨")
                    continue
                
                # å‡†å¤‡è¯¥æœŸæ•°çš„æ•°æ®
                horizon_data = analysis_data.dropna(subset=[dependent_var])
                
                if len(horizon_data) < 20:  # æœ€å°‘è§‚æµ‹æ•°
                    logger.warning(f"   è·³è¿‡é¢„æµ‹æœŸ h={h}: è§‚æµ‹æ•°ä¸è¶³({len(horizon_data)})")
                    continue
                
                # è®¾ç½®ç´¢å¼•
                horizon_data = horizon_data.set_index(['country', 'year'])
                
                # ä¼°è®¡æ¨¡å‹
                explanatory_vars = base_explanatory_vars
                
                try:
                    model = PanelOLS(
                        dependent=horizon_data[dependent_var],
                        exog=horizon_data[explanatory_vars],
                        entity_effects=True,
                        time_effects=False,  # å±€éƒ¨æŠ•å½±é€šå¸¸ä¸åŒ…å«æ—¶é—´æ•ˆåº”
                        check_rank=False
                    )
                    
                    results = model.fit(cov_type='clustered', cluster_entity=True)
                    
                    horizon_results[f'h{h}'] = {
                        'horizon': h,
                        'coefficients': dict(results.params),
                        'std_errors': dict(results.std_errors),
                        'p_values': dict(results.pvalues),
                        'r_squared': float(results.rsquared),
                        'n_obs': int(results.nobs)
                    }
                    
                    logger.info(f"     âœ“ h={h}: RÂ²={results.rsquared:.4f}, N={results.nobs}")
                    
                except Exception as e:
                    logger.warning(f"     âœ— h={h}: ä¼°è®¡å¤±è´¥ - {str(e)}")
                    continue
            
            if not horizon_results:
                return self._create_empty_result(model_name, 'æ‰€æœ‰é¢„æµ‹æœŸæ•°çš„æ¨¡å‹ä¼°è®¡éƒ½å¤±è´¥')
            
            # æ„å»ºåŠ¨æ€å…¬å¼å­—ç¬¦ä¸²
            formula = f"Î”hhi_imports(t+h) ~ {' + '.join(base_explanatory_vars)} + EntityEffects"
            
            # èšåˆç»“æœ
            result_dict = {
                'model_name': model_name,
                'model_type': 'local_projections',
                'status': 'success',
                'status_message': f'å±€éƒ¨æŠ•å½±æ¨¡å‹ä¼°è®¡æˆåŠŸï¼Œ{len(horizon_results)}ä¸ªé¢„æµ‹æœŸ',
                'horizon_results': horizon_results,
                'horizons_estimated': list(horizon_results.keys()),
                'n_horizons': len(horizon_results),
                'formula': formula,
                'data_available': True,
                'estimation_time': 0.0,
                'diagnostics': overall_diagnostics
            }
            
            logger.info(f"   âœ… æ¨¡å‹3ä¼°è®¡å®Œæˆ: {len(horizon_results)} ä¸ªé¢„æµ‹æœŸ")
            
            return result_dict
            
        except Exception as e:
            error_msg = f"å±€éƒ¨æŠ•å½±æ¨¡å‹ä¼°è®¡å¤±è´¥: {str(e)}"
            logger.error(f"   âŒ {error_msg}")
            return self._create_empty_result(model_name, error_msg)

    def run_lp_irf_price_channel(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        æ¨¡å‹4A: LP-IRFä»·æ ¼é€šé“æ¨¡å‹ (ç¬¬4ç« ç‰©ç†æœ¬è´¨æ£€éªŒ)
        P_{i,t+h} = Î¸_h * (US_ProdShock_t Ã— OVI_{i,t-1}) + Controls + Î±_i + Î»_t + Î·_{i,t+h}
        
        é¢„æœŸç»“æœ: Î¸_h æ˜¾è‘—ä¸ºè´Ÿ (OVIé«˜çš„å›½å®¶åœ¨ç¾å›½ä¾›åº”å¢åŠ å†²å‡»ä¸‹ä»·æ ¼ä¸‹é™æ›´å¤š)
        
        Args:
            df: åˆ†ææ•°æ®
            
        Returns:
            æ¨¡å‹ç»“æœå­—å…¸
        """
        model_name = 'model_4a_lp_irf_price_channel'
        logger.info(f"ğŸ” è¿è¡Œæ¨¡å‹4A: LP-IRFä»·æ ¼é€šé“æ£€éªŒ...")
        
        # åŠ¨æ€æ„å»ºå¿…éœ€å˜é‡åˆ—è¡¨
        base_required_vars = ['P_it', 'us_prod_shock', 'ovi_gas', 'year', 'country'] + self.config.get_control_variables('macro_controls')
        
        # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
        data_check, df_checked = self._check_data_availability(df, base_required_vars)
        if not data_check['data_available']:
            logger.warning(f"   âš ï¸ {data_check['status_message']}")
            return self._create_empty_result(model_name, data_check['status_message'])
        
        if not HAS_STATSMODELS or not HAS_LINEARMODELS:
            return self._create_empty_result(model_name, 'ç¼ºå°‘å¿…éœ€çš„è®¡é‡åˆ†æåº“')
        
        try:
            # å‡†å¤‡æ•°æ®
            analysis_data = df_checked[base_required_vars].copy()
            analysis_data = analysis_data.sort_values(['country', 'year'])
            
            # åˆ›å»ºæ»åOVIå˜é‡
            analysis_data['ovi_gas_lag1'] = analysis_data.groupby('country')['ovi_gas'].shift(1)
            
            # åˆ›å»ºäº¤äº’é¡¹: US_ProdShock Ã— OVI(t-1)
            analysis_data['shock_x_ovi'] = (
                analysis_data['us_prod_shock'] * analysis_data['ovi_gas_lag1']
            )
            
            # è·å–é¢„æµ‹æœŸæ•°è®¾å®š (0åˆ°4å¹´)
            horizons = [0, 1, 2, 3, 4]
            
            # ä¸ºä¸åŒé¢„æµ‹æœŸåˆ›å»ºå› å˜é‡ P_{i,t+h}
            for h in horizons:
                if h == 0:
                    analysis_data[f'P_it_h{h}'] = analysis_data['P_it']
                else:
                    analysis_data[f'P_it_h{h}'] = analysis_data.groupby('country')['P_it'].shift(-h)
            
            # è·å–æ§åˆ¶å˜é‡
            control_vars = self.config.get_control_variables('macro_controls')
            available_controls = [var for var in control_vars if var in analysis_data.columns]
            
            # æ„å»ºè§£é‡Šå˜é‡åˆ—è¡¨
            explanatory_vars = ['shock_x_ovi'] + available_controls
            required_for_regression = explanatory_vars + ['ovi_gas_lag1', 'year', 'country']
            
            # æœ€ç»ˆæ¸…ç†æ•°æ®
            for h in horizons:
                required_for_regression.append(f'P_it_h{h}')
            
            final_data = analysis_data[required_for_regression].dropna()
            
            if len(final_data) < 50:  # æœ€å°æ ·æœ¬é‡è¦æ±‚
                error_msg = f'æ ·æœ¬é‡ä¸è¶³: {len(final_data)} < 50'
                return self._create_empty_result(model_name, error_msg)
            
            # è®¾ç½®é¢æ¿æ•°æ®ç´¢å¼•
            final_data = final_data.set_index(['country', 'year'])
            
            horizon_results = {}
            
            # å¯¹æ¯ä¸ªé¢„æµ‹æœŸè¿è¡Œå›å½’
            for h in horizons:
                try:
                    logger.info(f"   ä¼°è®¡é¢„æµ‹æœŸ h={h}...")
                    
                    # è¿è¡ŒåŒå‘å›ºå®šæ•ˆåº”æ¨¡å‹
                    model = PanelOLS(
                        dependent=final_data[f'P_it_h{h}'],
                        exog=final_data[explanatory_vars],
                        entity_effects=True,    # å›½å®¶å›ºå®šæ•ˆåº”
                        time_effects=True,      # å¹´ä»½å›ºå®šæ•ˆåº”
                        check_rank=False
                    )
                    
                    results = model.fit(cov_type='clustered', cluster_entity=True)
                    
                    # æå–æ ¸å¿ƒç³»æ•° Î¸_h (äº¤äº’é¡¹ç³»æ•°)
                    theta_h = results.params['shock_x_ovi']
                    theta_h_se = results.std_errors['shock_x_ovi']
                    theta_h_pvalue = results.pvalues['shock_x_ovi']
                    
                    horizon_results[f'h{h}'] = {
                        'horizon': h,
                        'theta_coefficient': float(theta_h),
                        'theta_std_error': float(theta_h_se),
                        'theta_p_value': float(theta_h_pvalue),
                        'theta_significant': theta_h_pvalue < 0.05,
                        'theta_sign_correct': theta_h < 0,  # é¢„æœŸä¸ºè´Ÿ
                        'r_squared': float(results.rsquared),
                        'n_obs': int(results.nobs),
                        'all_coefficients': dict(results.params),
                        'all_p_values': dict(results.pvalues)
                    }
                    
                    logger.info(f"     h={h}: Î¸_h={theta_h:.4f} (p={theta_h_pvalue:.3f})")
                    
                except Exception as e:
                    logger.warning(f"     é¢„æµ‹æœŸ h={h} ä¼°è®¡å¤±è´¥: {str(e)}")
                    continue
            
            if not horizon_results:
                return self._create_empty_result(model_name, 'æ‰€æœ‰é¢„æµ‹æœŸä¼°è®¡å¤±è´¥')
            
            # æ±‡æ€»ç»“æœ
            formula = f"P_it(t+h) ~ shock_x_ovi + {' + '.join(available_controls)} + EntityEffects + TimeEffects"
            
            result_dict = {
                'model_name': model_name,
                'model_type': 'lp_irf_price_channel',
                'status': 'success',
                'status_message': f'LP-IRFä»·æ ¼é€šé“æ¨¡å‹ä¼°è®¡æˆåŠŸï¼Œ{len(horizon_results)}ä¸ªé¢„æµ‹æœŸ',
                'horizon_results': horizon_results,
                'horizons_estimated': [int(k[1:]) for k in horizon_results.keys()],
                'n_horizons': len(horizon_results),
                'formula': formula,
                'economic_interpretation': 'è´Ÿçš„Î¸_hè¡¨ç¤ºOVIé«˜çš„å›½å®¶åœ¨ç¾å›½ä¾›åº”å†²å‡»ä¸‹ä»·æ ¼ä¸‹é™æ›´å¤š',
                'expected_sign': 'negative',
                'data_available': True,
                'sample_period': f"{final_data.index.get_level_values('year').min()}-{final_data.index.get_level_values('year').max()}",
                'total_observations': len(final_data)
            }
            
            logger.info(f"   âœ… LP-IRFä»·æ ¼é€šé“æ¨¡å‹å®Œæˆ: {len(horizon_results)} ä¸ªé¢„æµ‹æœŸ")
            
            return result_dict
            
        except Exception as e:
            error_msg = f"LP-IRFä»·æ ¼é€šé“æ¨¡å‹ä¼°è®¡å¤±è´¥: {str(e)}"
            logger.error(f"   âŒ {error_msg}")
            return self._create_empty_result(model_name, error_msg)

    def run_lp_irf_quantity_channel(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        æ¨¡å‹4B: LP-IRFæ•°é‡é€šé“æ¨¡å‹ (ç¬¬4ç« ç‰©ç†æœ¬è´¨æ£€éªŒ)
        g_{i,t+h} = Î¸_h * (US_ProdShock_t Ã— OVI_{i,t-1}) + Controls + Î±_i + Î»_t + Î·_{i,t+h}
        
        é¢„æœŸç»“æœ: Î¸_h æ˜¾è‘—ä¸ºæ­£ (OVIé«˜çš„å›½å®¶åœ¨ç¾å›½ä¾›åº”å¢åŠ å†²å‡»ä¸‹è¿›å£é‡å¢é•¿æ›´å¤š)
        
        Args:
            df: åˆ†ææ•°æ®
            
        Returns:
            æ¨¡å‹ç»“æœå­—å…¸
        """
        model_name = 'model_4b_lp_irf_quantity_channel'
        logger.info(f"ğŸ” è¿è¡Œæ¨¡å‹4B: LP-IRFæ•°é‡é€šé“æ£€éªŒ...")
        
        # åŠ¨æ€æ„å»ºå¿…éœ€å˜é‡åˆ—è¡¨
        base_required_vars = ['g_it', 'us_prod_shock', 'ovi_gas', 'year', 'country'] + self.config.get_control_variables('macro_controls')
        
        # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
        data_check, df_checked = self._check_data_availability(df, base_required_vars)
        if not data_check['data_available']:
            logger.warning(f"   âš ï¸ {data_check['status_message']}")
            return self._create_empty_result(model_name, data_check['status_message'])
        
        if not HAS_STATSMODELS or not HAS_LINEARMODELS:
            return self._create_empty_result(model_name, 'ç¼ºå°‘å¿…éœ€çš„è®¡é‡åˆ†æåº“')
        
        try:
            # å‡†å¤‡æ•°æ®
            analysis_data = df_checked[base_required_vars].copy()
            analysis_data = analysis_data.sort_values(['country', 'year'])
            
            # åˆ›å»ºæ»åOVIå˜é‡
            analysis_data['ovi_gas_lag1'] = analysis_data.groupby('country')['ovi_gas'].shift(1)
            
            # åˆ›å»ºäº¤äº’é¡¹: US_ProdShock Ã— OVI(t-1)
            analysis_data['shock_x_ovi'] = (
                analysis_data['us_prod_shock'] * analysis_data['ovi_gas_lag1']
            )
            
            # è·å–é¢„æµ‹æœŸæ•°è®¾å®š (0åˆ°4å¹´)
            horizons = [0, 1, 2, 3, 4]
            
            # ä¸ºä¸åŒé¢„æµ‹æœŸåˆ›å»ºå› å˜é‡ g_{i,t+h}
            for h in horizons:
                if h == 0:
                    analysis_data[f'g_it_h{h}'] = analysis_data['g_it']
                else:
                    analysis_data[f'g_it_h{h}'] = analysis_data.groupby('country')['g_it'].shift(-h)
            
            # è·å–æ§åˆ¶å˜é‡
            control_vars = self.config.get_control_variables('macro_controls')
            available_controls = [var for var in control_vars if var in analysis_data.columns]
            
            # æ„å»ºè§£é‡Šå˜é‡åˆ—è¡¨
            explanatory_vars = ['shock_x_ovi'] + available_controls
            required_for_regression = explanatory_vars + ['ovi_gas_lag1', 'year', 'country']
            
            # æœ€ç»ˆæ¸…ç†æ•°æ®
            for h in horizons:
                required_for_regression.append(f'g_it_h{h}')
            
            final_data = analysis_data[required_for_regression].dropna()
            
            if len(final_data) < 50:  # æœ€å°æ ·æœ¬é‡è¦æ±‚
                error_msg = f'æ ·æœ¬é‡ä¸è¶³: {len(final_data)} < 50'
                return self._create_empty_result(model_name, error_msg)
            
            # è®¾ç½®é¢æ¿æ•°æ®ç´¢å¼•
            final_data = final_data.set_index(['country', 'year'])
            
            horizon_results = {}
            
            # å¯¹æ¯ä¸ªé¢„æµ‹æœŸè¿è¡Œå›å½’
            for h in horizons:
                try:
                    logger.info(f"   ä¼°è®¡é¢„æµ‹æœŸ h={h}...")
                    
                    # è¿è¡ŒåŒå‘å›ºå®šæ•ˆåº”æ¨¡å‹
                    model = PanelOLS(
                        dependent=final_data[f'g_it_h{h}'],
                        exog=final_data[explanatory_vars],
                        entity_effects=True,    # å›½å®¶å›ºå®šæ•ˆåº”
                        time_effects=True,      # å¹´ä»½å›ºå®šæ•ˆåº”
                        check_rank=False
                    )
                    
                    results = model.fit(cov_type='clustered', cluster_entity=True)
                    
                    # æå–æ ¸å¿ƒç³»æ•° Î¸_h (äº¤äº’é¡¹ç³»æ•°)
                    theta_h = results.params['shock_x_ovi']
                    theta_h_se = results.std_errors['shock_x_ovi']
                    theta_h_pvalue = results.pvalues['shock_x_ovi']
                    
                    horizon_results[f'h{h}'] = {
                        'horizon': h,
                        'theta_coefficient': float(theta_h),
                        'theta_std_error': float(theta_h_se),
                        'theta_p_value': float(theta_h_pvalue),
                        'theta_significant': theta_h_pvalue < 0.05,
                        'theta_sign_correct': theta_h > 0,  # é¢„æœŸä¸ºæ­£
                        'r_squared': float(results.rsquared),
                        'n_obs': int(results.nobs),
                        'all_coefficients': dict(results.params),
                        'all_p_values': dict(results.pvalues)
                    }
                    
                    logger.info(f"     h={h}: Î¸_h={theta_h:.4f} (p={theta_h_pvalue:.3f})")
                    
                except Exception as e:
                    logger.warning(f"     é¢„æµ‹æœŸ h={h} ä¼°è®¡å¤±è´¥: {str(e)}")
                    continue
            
            if not horizon_results:
                return self._create_empty_result(model_name, 'æ‰€æœ‰é¢„æµ‹æœŸä¼°è®¡å¤±è´¥')
            
            # æ±‡æ€»ç»“æœ
            formula = f"g_it(t+h) ~ shock_x_ovi + {' + '.join(available_controls)} + EntityEffects + TimeEffects"
            
            result_dict = {
                'model_name': model_name,
                'model_type': 'lp_irf_quantity_channel',
                'status': 'success',
                'status_message': f'LP-IRFæ•°é‡é€šé“æ¨¡å‹ä¼°è®¡æˆåŠŸï¼Œ{len(horizon_results)}ä¸ªé¢„æµ‹æœŸ',
                'horizon_results': horizon_results,
                'horizons_estimated': [int(k[1:]) for k in horizon_results.keys()],
                'n_horizons': len(horizon_results),
                'formula': formula,
                'economic_interpretation': 'æ­£çš„Î¸_hè¡¨ç¤ºOVIé«˜çš„å›½å®¶åœ¨ç¾å›½ä¾›åº”å†²å‡»ä¸‹è¿›å£é‡å¢é•¿æ›´å¤š',
                'expected_sign': 'positive',
                'data_available': True,
                'sample_period': f"{final_data.index.get_level_values('year').min()}-{final_data.index.get_level_values('year').max()}",
                'total_observations': len(final_data)
            }
            
            logger.info(f"   âœ… LP-IRFæ•°é‡é€šé“æ¨¡å‹å®Œæˆ: {len(horizon_results)} ä¸ªé¢„æµ‹æœŸ")
            
            return result_dict
            
        except Exception as e:
            error_msg = f"LP-IRFæ•°é‡é€šé“æ¨¡å‹ä¼°è®¡å¤±è´¥: {str(e)}"
            logger.error(f"   âŒ {error_msg}")
            return self._create_empty_result(model_name, error_msg)
    
    def _run_model_diagnostics(self, data: pd.DataFrame, results) -> Dict[str, Any]:
        """
        è¿è¡Œæ¨¡å‹è¯Šæ–­æ£€éªŒ
        
        Args:
            data: åˆ†ææ•°æ®
            results: æ¨¡å‹ç»“æœ
            
        Returns:
            è¯Šæ–­ç»“æœå­—å…¸
        """
        diagnostics = {}
        
        try:
            # åŸºç¡€ç»Ÿè®¡
            diagnostics['n_obs'] = len(data)
            diagnostics['n_vars'] = len(data.columns)
            
            # å¦‚æœæœ‰æ®‹å·®ï¼Œè¿›è¡Œè¿›ä¸€æ­¥è¯Šæ–­
            if hasattr(results, 'resids'):
                residuals = results.resids
                
                # æ®‹å·®åŸºç¡€ç»Ÿè®¡
                diagnostics['residual_mean'] = float(residuals.mean())
                diagnostics['residual_std'] = float(residuals.std())
                
                # Durbin-Watsonæ£€éªŒ (å¦‚æœæœ‰statsmodels)
                if HAS_STATSMODELS:
                    try:
                        diagnostics['durbin_watson'] = float(durbin_watson(residuals))
                    except:
                        diagnostics['durbin_watson'] = np.nan
            
        except Exception as e:
            logger.warning(f"è¯Šæ–­æ£€éªŒå¤±è´¥: {str(e)}")
            diagnostics['error'] = str(e)
        
        return diagnostics
    
    def run_all_models(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        è¿è¡Œæ ¸å¿ƒæ¨¡å‹1: DLI-HHIå…³è”åˆ†æ
        
        Args:
            df: åˆ†ææ•°æ®
            
        Returns:
            æ¨¡å‹1ç»“æœçš„æ±‡æ€»å­—å…¸
        """
        logger.info("ğŸš€ è¿è¡Œæ ¸å¿ƒæ¨¡å‹1: DLI-HHIå…³è”åˆ†æ...")
        
        all_results = {
            'overview': {
                'total_models': 1,  # åªæœ‰1ä¸ªæ ¸å¿ƒæ¨¡å‹
                'completed_models': 0,
                'failed_models': 0,
                'data_available': len(df) > 0 if df is not None else False
            },
            'models': {}
        }
        
        # æ¨¡å‹1: DLI-HHIå…³è”ï¼ˆå”¯ä¸€æ ¸å¿ƒæ¨¡å‹ï¼‰
        try:
            result1 = self.run_dli_hhi_association(df)
            all_results['models']['model_1_dli_hhi_association'] = result1
            if result1['status'] == 'success':
                all_results['overview']['completed_models'] += 1
            else:
                all_results['overview']['failed_models'] += 1
        except Exception as e:
            logger.error(f"æ ¸å¿ƒæ¨¡å‹è¿è¡Œå¼‚å¸¸: {str(e)}")
            all_results['models']['model_1_dli_hhi_association'] = self._create_empty_result('model_1_dli_hhi_association', f'è¿è¡Œå¼‚å¸¸: {str(e)}')
            all_results['overview']['failed_models'] += 1
        
        logger.info(f"âœ… æ ¸å¿ƒæ¨¡å‹è¿è¡Œå®Œæˆ: æˆåŠŸ {all_results['overview']['completed_models']}/{all_results['overview']['total_models']}")
        
        return all_results

    def run_surface_association_test(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        ç¬¬3ç« ï¼šè¡¨é¢å…³è”æ£€éªŒ - Node-DLI_USä¸HHIçš„å…³è”æ€§æµ‹è¯•
        
        æ¨¡å‹è®¾å®šï¼š
        HHI_{i,t} = Î² Ã— NodeDLI^US_{i,t} + Î“ Ã— Controls_{i,t} + Î±_i + Î»_t + Îµ_{i,t}
        
        é”šå®šå¤šæ ·åŒ–å‡è¯´ï¼šÎ² < 0 (ä¸ç¾å›½å…³ç³»è¶Šç´§å¯†ï¼Œè¿›å£æ¥æºè¶Šå¤šæ ·åŒ–)
        
        Args:
            df: åˆ†ææ•°æ®é›†
            
        Returns:
            DictåŒ…å«ä¼°è®¡ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯
        """
        model_name = 'model_3_surface_association'
        logger.info(f"ğŸ¯ å¼€å§‹è¿è¡Œè¡¨é¢å…³è”æ£€éªŒ: {model_name}")
        
        # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§  
        required_variables = ['hhi_imports', 'node_dli_us', 'log_gdp', 'log_population', 'year', 'country']
        check_result, analysis_data = self._check_data_availability(df, required_variables)
        
        if not check_result['data_available']:
            return self._create_empty_result(model_name, check_result['message'])
        
        logger.info(f"   æ•°æ®æ£€æŸ¥é€šè¿‡: {len(analysis_data)} è§‚æµ‹å€¼")
        
        try:
            # å»é™¤ç¼ºå¤±å€¼
            clean_data = analysis_data.dropna(subset=['hhi_imports', 'node_dli_us', 'log_gdp', 'log_population'])
            
            if len(clean_data) < 20:
                return self._create_empty_result(model_name, f'æœ‰æ•ˆè§‚æµ‹æ•°ä¸è¶³: {len(clean_data)}')
            
            logger.info(f"   æ¸…ç†åæ ·æœ¬é‡: {len(clean_data)} è§‚æµ‹å€¼")
            
            # è®¾ç½®é¢æ¿ç´¢å¼•
            clean_data = clean_data.set_index(['country', 'year'])
            
            # å®šä¹‰è§£é‡Šå˜é‡
            explanatory_vars = ['node_dli_us', 'log_gdp', 'log_population']
            
            # ä¼°è®¡åŒå‘å›ºå®šæ•ˆåº”æ¨¡å‹
            model = PanelOLS(
                dependent=clean_data['hhi_imports'],
                exog=clean_data[explanatory_vars],
                entity_effects=True,   # å›½å®¶å›ºå®šæ•ˆåº”
                time_effects=True,     # å¹´ä»½å›ºå®šæ•ˆåº”
                check_rank=False
            )
            
            results = model.fit(cov_type='clustered', cluster_entity=True)
            
            # æå–å…³é”®ç³»æ•°
            node_dli_coef = float(results.params.get('node_dli_us', np.nan))
            node_dli_pval = float(results.pvalues.get('node_dli_us', 1.0))
            node_dli_stderr = float(results.std_errors.get('node_dli_us', np.nan))
            
            # æ„å»ºç»“æœ
            result_dict = {
                'model_name': model_name,
                'status': 'success',
                'status_message': f'è¡¨é¢å…³è”æ£€éªŒå®Œæˆï¼Œæ ·æœ¬é‡{results.nobs}',
                'model_formula': 'hhi_imports ~ node_dli_us + log_gdp + log_population + EntityEffects + TimeEffects',
                'sample_size': int(results.nobs),
                'r_squared': float(results.rsquared),
                'node_dli_coefficient': node_dli_coef,
                'node_dli_p_value': node_dli_pval,
                'node_dli_std_error': node_dli_stderr,
                'expected_sign_correct': node_dli_coef < 0,  # é”šå®šå¤šæ ·åŒ–å‡è¯´é¢„æœŸä¸ºè´Ÿ
                'all_coefficients': dict(results.params),
                'all_p_values': dict(results.pvalues),
                'all_std_errors': dict(results.std_errors),
                'economic_interpretation': self._get_surface_association_interpretation(node_dli_coef, node_dli_pval)
            }
            
            logger.info(f"   âœ… è¡¨é¢å…³è”æ£€éªŒå®Œæˆ: Î²={node_dli_coef:.4f} (p={node_dli_pval:.3f})")
            return result_dict
            
        except Exception as e:
            logger.error(f"   âŒ è¡¨é¢å…³è”æ£€éªŒå¤±è´¥: {str(e)}")
            return self._create_empty_result(model_name, f'ä¼°è®¡è¿‡ç¨‹å¤±è´¥: {str(e)}')

    def _get_surface_association_interpretation(self, beta: float, p_value: float) -> str:
        """ç”Ÿæˆè¡¨é¢å…³è”æ£€éªŒçš„ç»æµå­¦è§£è¯»ï¼ˆé”šå®šå¤šæ ·åŒ–å‡è¯´ï¼‰"""
        significance = "æ˜¾è‘—" if p_value < 0.05 else "ä¸æ˜¾è‘—" if p_value < 0.1 else "ä¸æ˜¾è‘—"
        sign = "è´Ÿ" if beta < 0 else "æ­£"
        
        if beta < 0:
            base_interpretation = f"Node-DLI_USå¯¹hhi_importsçš„å½±å“ä¸º{sign}({significance})ï¼Œæ”¯æŒé”šå®šå¤šæ ·åŒ–å‡è¯´ï¼šä¸ç¾å›½å»ºç«‹æ›´ç´§å¯†ç½‘ç»œå…³ç³»çš„å›½å®¶ï¼Œè¿›å£æ¥æºæ›´åŠ å¤šæ ·åŒ–ï¼ˆhhi_importsæ›´ä½ï¼‰ã€‚"
        else:
            base_interpretation = f"Node-DLI_USå¯¹hhi_importsçš„å½±å“ä¸º{sign}({significance})ï¼Œä¸æ”¯æŒé”šå®šå¤šæ ·åŒ–å‡è¯´ï¼Œå¯èƒ½å­˜åœ¨å…¶ä»–ç»æµæœºåˆ¶æˆ–éœ€è¦è€ƒè™‘å†…ç”Ÿæ€§é—®é¢˜ã€‚"
        
        return base_interpretation


# ä¾¿æ·å‡½æ•°
def run_single_model(model_name: str, df: pd.DataFrame) -> Dict[str, Any]:
    """
    è¿è¡Œå•ä¸ªæ¨¡å‹çš„ä¾¿æ·å‡½æ•°
    
    Args:
        model_name: æ¨¡å‹åç§°
        df: åˆ†ææ•°æ®
        
    Returns:
        æ¨¡å‹ç»“æœ
    """
    models = EconometricModels()
    
    if model_name == 'model_1_dli_hhi_association':
        return models.run_dli_hhi_association(df)
    elif model_name == 'model_2_ovi_dli_causality':
        return models.run_ovi_dli_causality(df)
    elif model_name == 'model_3_local_projection_validation':
        return models.run_local_projection_shock_validation(df)
    elif model_name == 'model_4a_lp_irf_price_channel':
        return models.run_lp_irf_price_channel(df)
    elif model_name == 'model_4b_lp_irf_quantity_channel':
        return models.run_lp_irf_quantity_channel(df)
    elif model_name == 'model_3_surface_association':
        return models.run_surface_association_test(df)
    else:
        raise ValueError(f"æœªçŸ¥æ¨¡å‹åç§°: {model_name}")


if __name__ == "__main__":
    # æµ‹è¯•æ¨¡å‹æ¨¡å—
    import logging
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    print("ğŸ”¬ 09_econometric_analysis æ¨¡å‹æ¨¡å—æµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºç©ºDataFrameæµ‹è¯•
    test_df = pd.DataFrame()
    
    models = EconometricModels()
    results = models.run_all_models(test_df)
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"æ€»æ¨¡å‹æ•°: {results['overview']['total_models']}")
    print(f"å®Œæˆæ¨¡å‹æ•°: {results['overview']['completed_models']}")
    print(f"å¤±è´¥æ¨¡å‹æ•°: {results['overview']['failed_models']}")
    
    for model_name, result in results['models'].items():
        print(f"\nâ€¢ {model_name}:")
        print(f"  çŠ¶æ€: {result['status']}")
        print(f"  ä¿¡æ¯: {result['status_message']}")
    
    print("\nğŸ‰ æ¨¡å‹æ¨¡å—æµ‹è¯•å®Œæˆ!")