#!/usr/bin/env python3
"""
è¾“å‡ºç®¡ç†æ¨¡å—
è´Ÿè´£ä¿å­˜ç½‘ç»œæ•°æ®å’Œç”ŸæˆæŠ¥å‘Š
"""

import pandas as pd
import networkx as nx
import pickle
import logging
from pathlib import Path
from typing import Dict, List
from .utils import (setup_path, log_dataframe_info, safe_divide, 
                   NETWORKS_DIR, NETWORK_STATS_DIR, FILE_TEMPLATES, 
                   DATA_CONSISTENCY_STRATEGY, ENERGY_PRODUCT_CODES, 
                   REGIONAL_GROUPS, FOCUS_COUNTRIES, DATA_VALIDATION)

# ç¡®ä¿è·¯å¾„è®¾ç½®  
setup_path()

logger = logging.getLogger(__name__)

def save_networks_comprehensive(annual_networks: Dict[int, nx.DiGraph], network_stats: List[Dict]) -> None:
    """
    å…¨é¢ä¿å­˜ç½‘ç»œæ•°æ®ï¼ˆå¤šç§æ ¼å¼ï¼‰
    
    Args:
        annual_networks: å¹´åº¦ç½‘ç»œå­—å…¸ï¼Œé”®ä¸ºå¹´ä»½ï¼Œå€¼ä¸ºNetworkXå›¾å¯¹è±¡
        network_stats: ç½‘ç»œç»Ÿè®¡åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºåŒ…å«ç»Ÿè®¡æŒ‡æ ‡çš„å­—å…¸
        
    Raises:
        Exception: å½“ä¿å­˜è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯æ—¶
        
    Example:
        >>> networks = {2020: G2020, 2021: G2021}
        >>> stats = [{"year": 2020, "nodes": 100}, {"year": 2021, "nodes": 105}]
        >>> save_networks_comprehensive(networks, stats)
    """
    logger.info(f"\nğŸ’¾ å¼€å§‹ä¿å­˜ç½‘ç»œæ•°æ®...")
    
    if not annual_networks:
        logger.warning("æ²¡æœ‰ç½‘ç»œæ•°æ®éœ€è¦ä¿å­˜")
        return
    
    years = sorted(annual_networks.keys())
    start_year, end_year = min(years), max(years)
    
    try:
        # 1. ä¿å­˜ç½‘ç»œå¯¹è±¡ï¼ˆPickleæ ¼å¼ - å¿«é€ŸåŠ è½½ï¼‰
        networks_file = NETWORKS_DIR / FILE_TEMPLATES['network_pickle'].format(
            start_year=start_year, end_year=end_year)
        with open(networks_file, 'wb') as f:
            pickle.dump(annual_networks, f)
        logger.info(f"     âœ… Pickleç½‘ç»œæ–‡ä»¶: {networks_file}")
        
        # 2. ä¿å­˜ç½‘ç»œé›†åˆï¼ˆGraphMLæ ¼å¼ - é€šç”¨å…¼å®¹ï¼Œä¼˜åŒ–ç‰ˆï¼‰
        graphml_count = 0
        
        def clean_graph_for_graphml(G: nx.DiGraph) -> nx.DiGraph:
            """æ¸…ç†å›¾ä»¥é€‚é…GraphMLæ ¼å¼"""
            G_clean = G.copy()
            
            # æ¸…ç†å›¾çº§åˆ«å±æ€§ï¼ˆä¿ç•™åŸºæœ¬ç±»å‹ï¼‰
            allowed_types = (str, int, float, bool)
            G_clean.graph = {
                k: v for k, v in G_clean.graph.items() 
                if isinstance(v, allowed_types)
            }
            
            # æ‰¹é‡æ¸…ç†èŠ‚ç‚¹å±æ€§
            for node in G_clean.nodes():
                G_clean.nodes[node] = {
                    k: v for k, v in G_clean.nodes[node].items()
                    if isinstance(v, allowed_types)
                }
            
            # æ‰¹é‡æ¸…ç†è¾¹å±æ€§
            for source, target in G_clean.edges():
                G_clean.edges[source, target] = {
                    k: v for k, v in G_clean.edges[source, target].items()
                    if isinstance(v, allowed_types)
                }
            
            return G_clean
        
        for year, G in annual_networks.items():
            try:
                # ä½¿ç”¨ä¼˜åŒ–çš„æ¸…ç†å‡½æ•°
                G_clean = clean_graph_for_graphml(G)
                
                graphml_file = NETWORKS_DIR / f"network_{year}.graphml"
                nx.write_graphml(G_clean, graphml_file)
                graphml_count += 1
                
            except Exception as e:
                logger.warning(f"ä¿å­˜ {year} å¹´GraphMLæ–‡ä»¶å¤±è´¥: {e}")
        
        logger.info(f"     âœ… GraphMLç½‘ç»œæ–‡ä»¶: {graphml_count} ä¸ªå¹´åº¦æ–‡ä»¶")
        
        # 3. ä¿å­˜ç½‘ç»œç»Ÿè®¡ä¿¡æ¯
        stats_df = pd.DataFrame(network_stats)
        stats_file = NETWORK_STATS_DIR / FILE_TEMPLATES['basic_stats']
        stats_df.to_csv(stats_file, index=False)
        logger.info(f"     âœ… ç»Ÿè®¡ä¿¡æ¯: {stats_file}")
        
        # 4. ç”Ÿæˆå¹´åº¦èŠ‚ç‚¹å’Œè¾¹æ–‡ä»¶
        logger.info(f"     ğŸ”„ ç”Ÿæˆå¹´åº¦èŠ‚ç‚¹å’Œè¾¹æ–‡ä»¶...")
        nodes_edges_generated = generate_annual_nodes_edges(annual_networks)
        logger.info(f"     âœ… èŠ‚ç‚¹è¾¹æ–‡ä»¶: {nodes_edges_generated} å¯¹")
        
        # 5. ç”Ÿæˆè¯¦ç»†æ‘˜è¦æŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰
        generate_summary_report(annual_networks, network_stats)
        logger.info(f"     âœ… æ‘˜è¦æŠ¥å‘Š: {NETWORK_STATS_DIR / FILE_TEMPLATES['summary_report']}")
        
        logger.info(f"\nğŸ¯ ä¿å­˜å®Œæˆ! æ‰€æœ‰æ–‡ä»¶å·²è¾“å‡ºåˆ°ç›¸åº”ç›®å½•")
        
    except Exception as e:
        logger.error(f"ä¿å­˜ç½‘ç»œæ•°æ®æ—¶å‡ºé”™: {e}")
        raise

def generate_annual_nodes_edges(annual_networks: Dict[int, nx.DiGraph]) -> int:
    """
    ä¸ºæ¯å¹´çš„ç½‘ç»œç”ŸæˆèŠ‚ç‚¹å’Œè¾¹CSVæ–‡ä»¶ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    
    Args:
        annual_networks: å¹´åº¦ç½‘ç»œå­—å…¸
        
    Returns:
        æˆåŠŸç”Ÿæˆçš„å¹´åº¦æ–‡ä»¶å¯¹æ•°é‡
        
    Example:
        >>> count = generate_annual_nodes_edges(annual_networks)
        >>> print(f"ç”Ÿæˆäº† {count} å¯¹å¹´åº¦æ–‡ä»¶")
    """
    generated_count = 0
    
    for year, G in annual_networks.items():
        try:
            # ä¼˜åŒ–ï¼šé¢„è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹çš„åº¦å’Œå¼ºåº¦ï¼ˆæ‰¹é‡è®¡ç®—ï¼‰
            if G.number_of_nodes() > 0:
                out_degrees = dict(G.out_degree())
                in_degrees = dict(G.in_degree())
                out_strengths = dict(G.out_degree(weight='weight'))
                in_strengths = dict(G.in_degree(weight='weight'))
                
                # ç”ŸæˆèŠ‚ç‚¹æ–‡ä»¶ï¼ˆvectorizedæ“ä½œï¼‰
                nodes_data = {
                    'country_code': list(G.nodes()),
                    'country_name': [G.nodes[node].get('name', node) for node in G.nodes()],
                    'region': [G.nodes[node].get('region', 'Other') for node in G.nodes()],
                    'out_degree': [out_degrees[node] for node in G.nodes()],
                    'in_degree': [in_degrees[node] for node in G.nodes()],
                    'out_strength': [out_strengths[node] for node in G.nodes()],
                    'in_strength': [in_strengths[node] for node in G.nodes()],
                    'total_strength': [out_strengths[node] + in_strengths[node] for node in G.nodes()]
                }
                
                nodes_df = pd.DataFrame(nodes_data)
                nodes_file = NETWORKS_DIR / FILE_TEMPLATES['nodes_file'].format(year=year)
                
                # ä¼˜åŒ–ï¼šä½¿ç”¨é«˜æ•ˆçš„CSVå†™å…¥
                nodes_df.to_csv(nodes_file, index=False, float_format='%.2f')
            else:
                # ç©ºç½‘ç»œçš„å¤„ç†
                empty_nodes_df = pd.DataFrame(columns=[
                    'country_code', 'country_name', 'region', 'out_degree', 
                    'in_degree', 'out_strength', 'in_strength', 'total_strength'
                ])
                nodes_file = NETWORKS_DIR / FILE_TEMPLATES['nodes_file'].format(year=year)
                empty_nodes_df.to_csv(nodes_file, index=False)
            
            # ç”Ÿæˆè¾¹æ–‡ä»¶ï¼ˆä¼˜åŒ–ï¼šä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ï¼‰
            if G.number_of_edges() > 0:
                edges_data = {
                    'source': [edge[0] for edge in G.edges()],
                    'target': [edge[1] for edge in G.edges()],
                    'weight': [G.edges[edge]['weight'] for edge in G.edges()],
                    'data_source': [G.edges[edge].get('data_source', 'unknown') for edge in G.edges()]
                }
                
                edges_df = pd.DataFrame(edges_data)
                edges_file = NETWORKS_DIR / FILE_TEMPLATES['edges_file'].format(year=year)
                
                # ä¼˜åŒ–ï¼šä½¿ç”¨é«˜æ•ˆçš„CSVå†™å…¥
                edges_df.to_csv(edges_file, index=False, float_format='%.2f')
            else:
                # ç©ºç½‘ç»œçš„è¾¹æ–‡ä»¶
                empty_edges_df = pd.DataFrame(columns=['source', 'target', 'weight', 'data_source'])
                edges_file = NETWORKS_DIR / FILE_TEMPLATES['edges_file'].format(year=year)
                empty_edges_df.to_csv(edges_file, index=False)
            
            generated_count += 1
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆ {year} å¹´èŠ‚ç‚¹è¾¹æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    return generated_count

def generate_summary_report(annual_networks: Dict[int, nx.DiGraph], network_stats: List[Dict]) -> None:
    """
    ç”ŸæˆMarkdownæ ¼å¼çš„è¯¦ç»†æ‘˜è¦æŠ¥å‘Š
    
    Args:
        annual_networks: å¹´åº¦ç½‘ç»œå­—å…¸
        network_stats: ç½‘ç»œç»Ÿè®¡æ•°æ®åˆ—è¡¨
        
    Side Effects:
        åœ¨NETWORK_STATS_DIRç›®å½•ä¸‹ç”ŸæˆMarkdownæŠ¥å‘Šæ–‡ä»¶
        
    Example:
        >>> generate_summary_report(annual_networks, network_stats)
        # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶åˆ°æŒ‡å®šç›®å½•
    """
    years = sorted(annual_networks.keys())
    start_year, end_year = min(years), max(years)
    
    report_content = f"""# ç¾å›½èƒ½æºç‹¬ç«‹æ”¿ç­–ç ”ç©¶ - ç½‘ç»œæ„å»ºæ‘˜è¦æŠ¥å‘Š

## ğŸ“Š æ„å»ºæ¦‚è§ˆ

- **æ„å»ºæ—¶é—´**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ç½‘ç»œæ•°é‡**: {len(annual_networks)} ä¸ªå¹´åº¦ç½‘ç»œ
- **æ—¶é—´è·¨åº¦**: {start_year} - {end_year}
- **æ•°æ®ä¸€è‡´æ€§ç­–ç•¥**: {DATA_CONSISTENCY_STRATEGY}
- **èƒ½æºäº§å“**: {', '.join([f"{code}({name})" for code, name in ENERGY_PRODUCT_CODES.items()])}

## ğŸ” æ•´ä½“ç»Ÿè®¡

"""
    
    # è®¡ç®—æ•´ä½“ç»Ÿè®¡
    if network_stats:
        stats_df = pd.DataFrame(network_stats)
        
        report_content += f"""
### ç½‘ç»œè§„æ¨¡æ¼”åŒ–
- **å¹³å‡èŠ‚ç‚¹æ•°**: {stats_df['nodes'].mean():.0f}
- **å¹³å‡è¾¹æ•°**: {stats_df['edges'].mean():.0f}
- **å¹³å‡å¯†åº¦**: {stats_df['density'].mean():.4f}
- **æ€»è´¸æ˜“é¢**: ${stats_df['total_trade_value'].sum()/1e12:.1f}ä¸‡äº¿ç¾å…ƒ

### ç¾å›½è´¸æ˜“åœ°ä½æ¼”åŒ–
- **{start_year}å¹´ç¾å›½è´¸æ˜“ä»½é¢**: {stats_df.iloc[0]['usa_trade_share']:.1%}
- **{end_year}å¹´ç¾å›½è´¸æ˜“ä»½é¢**: {stats_df.iloc[-1]['usa_trade_share']:.1%}
- **å˜åŒ–**: {(stats_df.iloc[-1]['usa_trade_share'] - stats_df.iloc[0]['usa_trade_share']):.1%}

## ğŸ“ˆ å¹´åº¦ç½‘ç»œè¯¦æƒ…

| å¹´ä»½ | èŠ‚ç‚¹æ•° | è¾¹æ•° | å¯†åº¦ | æ€»è´¸æ˜“é¢(ä¸‡äº¿$) | ç¾å›½ä»½é¢ |
|------|--------|------|------|----------------|----------|
"""
        
        for _, row in stats_df.iterrows():
            report_content += f"| {row['year']} | {row['nodes']} | {row['edges']} | {row['density']:.4f} | {row['total_trade_value']/1e12:.2f} | {row['usa_trade_share']:.1%} |\n"
    
    report_content += f"""

## ğŸ”§ æŠ€æœ¯è¯´æ˜

### æ•°æ®å¤„ç†ç­–ç•¥
1. **ä¼˜å…ˆè¿›å£æ•°æ®**: å¯¹äºåŒè¾¹è´¸æ˜“ï¼Œä¼˜å…ˆä½¿ç”¨è¿›å£æ–¹æŠ¥å‘Šçš„æ•°æ®
2. **é•œåƒæ•°æ®è¡¥å……**: å½“è¿›å£æ•°æ®ç¼ºå¤±æ—¶ï¼Œä½¿ç”¨å‡ºå£æ–¹æ•°æ®ä½œä¸ºé•œåƒè¡¥å……
3. **è´¸æ˜“æµèšåˆ**: å°†åŒä¸€å›½å®¶å¯¹çš„å¤šç§èƒ½æºäº§å“è´¸æ˜“é¢åˆå¹¶

### æ•°æ®è´¨é‡æ§åˆ¶
- **æœ€å°è´¸æ˜“é¢é˜ˆå€¼**: ${DATA_VALIDATION['min_trade_value']:,} ç¾å…ƒ
- **å›½å®¶åŒºåŸŸåˆ†ç»„**: å·²å®ç° {len(REGIONAL_GROUPS)} ä¸ªåŒºåŸŸåˆ†ç»„
- **æ ¸å¿ƒå…³æ³¨å›½å®¶**: {len(FOCUS_COUNTRIES)} ä¸ªé‡ç‚¹åˆ†æå›½å®¶

### è¾“å‡ºæ–‡ä»¶è¯´æ˜
- **Pickleæ ¼å¼**: å¿«é€ŸåŠ è½½çš„Pythonç½‘ç»œå¯¹è±¡
- **GraphMLæ ¼å¼**: é€šç”¨çš„ç½‘ç»œäº¤æ¢æ ¼å¼ï¼Œæ”¯æŒGephiã€Cytoscapeç­‰å·¥å…·
- **CSVæ ¼å¼**: å¹´åº¦èŠ‚ç‚¹å’Œè¾¹æ–‡ä»¶ï¼Œä¾¿äºè¿›ä¸€æ­¥åˆ†æ
- **ç»Ÿè®¡æ–‡ä»¶**: åŒ…å«æ‰€æœ‰å¹´åº¦çš„ç½‘ç»œæ‹“æ‰‘ç»Ÿè®¡æŒ‡æ ‡

## ğŸš€ åç»­åˆ†æå»ºè®®

1. **ä¸­å¿ƒæ€§åˆ†æ**: è®¡ç®—åº¦ä¸­å¿ƒæ€§ã€ä¸­ä»‹ä¸­å¿ƒæ€§ã€ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§
2. **ç¤¾ç¾¤æ£€æµ‹**: ä½¿ç”¨Leidenç®—æ³•è¯†åˆ«è´¸æ˜“é›†å›¢
3. **éª¨å¹²ç½‘ç»œæå–**: å®æ–½DFã€PFã€MSTä¸‰ç§éª¨å¹²æå–æ–¹æ³•
4. **åŠ¨æ€åˆ†æ**: è¿½è¸ªå…³é”®æŒ‡æ ‡çš„æ—¶é—´åºåˆ—å˜åŒ–
5. **æ”¿ç­–æ•ˆåº”è¯„ä¼°**: å°†ç½‘ç»œå˜åŒ–ä¸æ”¿ç­–æ—¶é—´ç‚¹å¯¹åº”åˆ†æ

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = NETWORK_STATS_DIR / FILE_TEMPLATES['summary_report']
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)