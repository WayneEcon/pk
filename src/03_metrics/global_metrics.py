#!/usr/bin/env python3
"""
å…¨å±€ç½‘ç»œæŒ‡æ ‡è®¡ç®—æ¨¡å—

è´Ÿè´£è®¡ç®—æ•´ä¸ªç½‘ç»œçš„å…¨å±€æ‹“æ‰‘ç‰¹å¾ï¼š
- ç½‘ç»œå¯†åº¦
- è¿é€šæ€§æŒ‡æ ‡  
- è·¯å¾„é•¿åº¦æŒ‡æ ‡ï¼ˆä¿®æ­£åŠ æƒè·¯å¾„è®¡ç®—ï¼‰
- èšç±»ç³»æ•°
- ç½‘ç»œæ•ˆç‡
"""

import networkx as nx
import pandas as pd
import numpy as np
from typing import Dict, Any
from utils import (
    setup_logger, validate_graph, safe_divide, timer_decorator, 
    handle_computation_error, add_distance_weights, get_node_sample
)

logger = setup_logger(__name__)

@timer_decorator
def calculate_density_metrics(G: nx.DiGraph, year: int) -> Dict[str, Any]:
    """
    è®¡ç®—ç½‘ç»œå¯†åº¦ç›¸å…³æŒ‡æ ‡
    
    Args:
        G: NetworkXæœ‰å‘å›¾
        year: å¹´ä»½
    
    Returns:
        å¯†åº¦æŒ‡æ ‡å­—å…¸
    """
    validate_graph(G, "calculate_density_metrics")
    logger.info(f"     {year}: è®¡ç®—ç½‘ç»œå¯†åº¦...")
    
    try:
        n_nodes = G.number_of_nodes()
        n_edges = G.number_of_edges()
        
        # åŸºæœ¬å¯†åº¦
        density = nx.density(G)
        
        # æœ€å¤§å¯èƒ½è¾¹æ•° (æœ‰å‘å›¾)
        max_edges = n_nodes * (n_nodes - 1) if n_nodes > 1 else 0
        
        # æƒé‡å¯†åº¦ (åŸºäºè¾¹æƒé‡)
        edge_weights = [data.get('weight', 0) for _, _, data in G.edges(data=True)]
        total_weight = sum(edge_weights)
        avg_edge_weight = safe_divide(total_weight, n_edges)
        
        return {
            'year': year,
            'density': density,
            'nodes': n_nodes,
            'edges': n_edges,
            'max_possible_edges': max_edges,
            'edge_coverage_ratio': safe_divide(n_edges, max_edges),
            'total_weight': total_weight,
            'avg_edge_weight': avg_edge_weight,
            'weight_density': total_weight / (max_edges * avg_edge_weight) if max_edges > 0 and avg_edge_weight > 0 else 0
        }
        
    except Exception as e:
        return handle_computation_error("calculate_density_metrics", year, e, 
                                      {'year': year, 'density': 0, 'nodes': 0, 'edges': 0})

@timer_decorator
def calculate_connectivity_metrics(G: nx.DiGraph, year: int) -> Dict[str, Any]:
    """
    è®¡ç®—è¿é€šæ€§æŒ‡æ ‡
    
    Args:
        G: NetworkXæœ‰å‘å›¾
        year: å¹´ä»½
    
    Returns:
        è¿é€šæ€§æŒ‡æ ‡å­—å…¸
    """
    validate_graph(G, "calculate_connectivity_metrics")
    logger.info(f"     {year}: è®¡ç®—è¿é€šæ€§æŒ‡æ ‡...")
    
    try:
        # å¼ºè¿é€šæ€§
        is_strongly_connected = nx.is_strongly_connected(G)
        num_strongly_connected_components = nx.number_strongly_connected_components(G)
        
        # å¼±è¿é€šæ€§
        is_weakly_connected = nx.is_weakly_connected(G)
        num_weakly_connected_components = nx.number_weakly_connected_components(G)
        
        # æœ€å¤§å¼ºè¿é€šåˆ†é‡å¤§å°
        if num_strongly_connected_components > 0:
            largest_scc = max(nx.strongly_connected_components(G), key=len)
            largest_scc_size = len(largest_scc)
            largest_scc_ratio = safe_divide(largest_scc_size, G.number_of_nodes())
        else:
            largest_scc_size = 0
            largest_scc_ratio = 0
        
        # æœ€å¤§å¼±è¿é€šåˆ†é‡å¤§å°
        if num_weakly_connected_components > 0:
            largest_wcc = max(nx.weakly_connected_components(G), key=len)
            largest_wcc_size = len(largest_wcc)
            largest_wcc_ratio = safe_divide(largest_wcc_size, G.number_of_nodes())
        else:
            largest_wcc_size = 0
            largest_wcc_ratio = 0
        
        return {
            'year': year,
            'is_strongly_connected': is_strongly_connected,
            'num_strongly_connected_components': num_strongly_connected_components,
            'largest_scc_size': largest_scc_size,
            'largest_scc_ratio': largest_scc_ratio,
            'is_weakly_connected': is_weakly_connected,
            'num_weakly_connected_components': num_weakly_connected_components,
            'largest_wcc_size': largest_wcc_size,
            'largest_wcc_ratio': largest_wcc_ratio
        }
        
    except Exception as e:
        return handle_computation_error("calculate_connectivity_metrics", year, e,
                                      {'year': year, 'is_strongly_connected': False, 'is_weakly_connected': False})

@timer_decorator
def calculate_path_metrics(G: nx.DiGraph, year: int, sample_size: int = 1000) -> Dict[str, Any]:
    """
    è®¡ç®—è·¯å¾„é•¿åº¦ç›¸å…³æŒ‡æ ‡ï¼ˆä¿®æ­£ç‰ˆï¼šä½¿ç”¨distanceæƒé‡ï¼‰
    
    Args:
        G: NetworkXæœ‰å‘å›¾
        year: å¹´ä»½
        sample_size: é‡‡æ ·å¤§å°ï¼ˆå¯¹äºå¤§ç½‘ç»œè¿›è¡Œé‡‡æ ·ä»¥åŠ é€Ÿè®¡ç®—ï¼‰
    
    Returns:
        è·¯å¾„æŒ‡æ ‡å­—å…¸
    """
    validate_graph(G, "calculate_path_metrics")
    logger.info(f"     {year}: è®¡ç®—è·¯å¾„é•¿åº¦æŒ‡æ ‡ï¼ˆä¿®æ­£ç‰ˆï¼‰...")
    
    try:
        # ä¿®æ­£ï¼šæ·»åŠ è·ç¦»æƒé‡ï¼ˆdistance = 1/weightï¼‰
        G_with_distance = add_distance_weights(G)
        
        # è·å–é‡‡æ ·èŠ‚ç‚¹
        nodes = list(G.nodes())
        n_nodes = len(nodes)
        
        if n_nodes <= sample_size:
            sample_nodes = nodes
        else:
            # ä½¿ç”¨ç¼“å­˜çš„é‡‡æ ·å‡½æ•°
            sample_nodes = list(get_node_sample(tuple(nodes), sample_size))
        
        path_lengths = []
        weighted_path_lengths = []  # åŸºäºè´¸æ˜“å¼ºåº¦çš„è·¯å¾„é•¿åº¦
        reachable_pairs = 0
        total_pairs = 0
        
        for source in sample_nodes:
            try:
                # è®¡ç®—æœªåŠ æƒæœ€çŸ­è·¯å¾„
                unweighted_lengths = nx.single_source_shortest_path_length(G, source)
                
                # è®¡ç®—åŠ æƒæœ€çŸ­è·¯å¾„ï¼ˆä½¿ç”¨distanceæƒé‡ï¼Œä¿®æ­£åï¼‰
                weighted_lengths = nx.single_source_shortest_path_length(G_with_distance, source, weight='distance')
                
                for target in sample_nodes:
                    if source != target:
                        total_pairs += 1
                        if target in unweighted_lengths:
                            path_lengths.append(unweighted_lengths[target])
                            reachable_pairs += 1
                            
                        if target in weighted_lengths:
                            # æ£€æŸ¥è·¯å¾„é•¿åº¦æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯æ— ç©·å¤§ï¼‰
                            if weighted_lengths[target] != float('inf'):
                                weighted_path_lengths.append(weighted_lengths[target])
                                
            except Exception as e:
                logger.debug(f"     {year}: èŠ‚ç‚¹{source}è·¯å¾„è®¡ç®—éƒ¨åˆ†å¤±è´¥: {e}")
                continue
        
        # è®¡ç®—ç»Ÿè®¡é‡
        if path_lengths:
            avg_path_length = np.mean(path_lengths)
            median_path_length = np.median(path_lengths)
            max_path_length = np.max(path_lengths)
            min_path_length = np.min(path_lengths)
        else:
            avg_path_length = median_path_length = max_path_length = min_path_length = 0
        
        # è®¡ç®—åŠ æƒè·¯å¾„ç»Ÿè®¡é‡
        if weighted_path_lengths:
            avg_weighted_path_length = np.mean(weighted_path_lengths)
            median_weighted_path_length = np.median(weighted_path_lengths)
        else:
            avg_weighted_path_length = median_weighted_path_length = 0
        
        reachability_ratio = safe_divide(reachable_pairs, total_pairs)
        
        return {
            'year': year,
            'avg_path_length': avg_path_length,
            'median_path_length': median_path_length,
            'max_path_length': max_path_length,
            'min_path_length': min_path_length,
            'avg_weighted_path_length': avg_weighted_path_length,
            'median_weighted_path_length': median_weighted_path_length,
            'reachability_ratio': reachability_ratio,
            'sampled_pairs': total_pairs,
            'reachable_pairs': reachable_pairs,
            'weighted_reachable_pairs': len(weighted_path_lengths)
        }
        
    except Exception as e:
        return handle_computation_error("calculate_path_metrics", year, e,
                                      {'year': year, 'avg_path_length': 0, 'reachability_ratio': 0})

@timer_decorator
def calculate_efficiency_metrics(G: nx.DiGraph, year: int, sample_size: int = 500) -> Dict[str, Any]:
    """
    è®¡ç®—ç½‘ç»œæ•ˆç‡æŒ‡æ ‡ï¼ˆä¿®æ­£ç‰ˆï¼šä½¿ç”¨distanceæƒé‡ï¼‰
    
    Args:
        G: NetworkXæœ‰å‘å›¾
        year: å¹´ä»½
        sample_size: é‡‡æ ·å¤§å°
    
    Returns:
        æ•ˆç‡æŒ‡æ ‡å­—å…¸
    """
    validate_graph(G, "calculate_efficiency_metrics")
    logger.info(f"     {year}: è®¡ç®—ç½‘ç»œæ•ˆç‡ï¼ˆä¿®æ­£ç‰ˆï¼‰...")
    
    try:
        # ä¿®æ­£ï¼šæ·»åŠ è·ç¦»æƒé‡
        G_with_distance = add_distance_weights(G)
        
        nodes = list(G.nodes())
        n_nodes = len(nodes)
        
        if n_nodes <= sample_size:
            sample_nodes = nodes
        else:
            sample_nodes = list(get_node_sample(tuple(nodes), sample_size))
        
        efficiency_sum = 0
        weighted_efficiency_sum = 0
        total_pairs = 0
        
        for source in sample_nodes:
            try:
                # æœªåŠ æƒè·¯å¾„é•¿åº¦
                unweighted_lengths = nx.single_source_shortest_path_length(G, source)
                
                # åŠ æƒè·¯å¾„é•¿åº¦ï¼ˆä½¿ç”¨distanceæƒé‡ï¼‰
                weighted_lengths = nx.single_source_shortest_path_length(G_with_distance, source, weight='distance')
                
                for target in sample_nodes:
                    if source != target:
                        total_pairs += 1
                        
                        # æœªåŠ æƒæ•ˆç‡
                        if target in unweighted_lengths and unweighted_lengths[target] > 0:
                            efficiency_sum += 1.0 / unweighted_lengths[target]
                        
                        # åŠ æƒæ•ˆç‡
                        if target in weighted_lengths and weighted_lengths[target] > 0 and weighted_lengths[target] != float('inf'):
                            weighted_efficiency_sum += 1.0 / weighted_lengths[target]
                            
            except Exception as e:
                logger.debug(f"     {year}: èŠ‚ç‚¹{source}æ•ˆç‡è®¡ç®—éƒ¨åˆ†å¤±è´¥: {e}")
                continue
        
        global_efficiency = safe_divide(efficiency_sum, total_pairs)
        weighted_global_efficiency = safe_divide(weighted_efficiency_sum, total_pairs)
        
        return {
            'year': year,
            'global_efficiency': global_efficiency,
            'weighted_global_efficiency': weighted_global_efficiency,
            'efficiency_sample_size': len(sample_nodes),
            'efficiency_sample_pairs': total_pairs
        }
        
    except Exception as e:
        return handle_computation_error("calculate_efficiency_metrics", year, e,
                                      {'year': year, 'global_efficiency': 0, 'weighted_global_efficiency': 0})

@timer_decorator
def calculate_clustering_metrics(G: nx.DiGraph, year: int) -> Dict[str, Any]:
    """
    è®¡ç®—èšç±»ç³»æ•°ç›¸å…³æŒ‡æ ‡
    
    Args:
        G: NetworkXæœ‰å‘å›¾
        year: å¹´ä»½
    
    Returns:
        èšç±»æŒ‡æ ‡å­—å…¸
    """
    validate_graph(G, "calculate_clustering_metrics")
    logger.info(f"     {year}: è®¡ç®—èšç±»ç³»æ•°...")
    
    try:
        # è½¬æ¢ä¸ºæ— å‘å›¾è®¡ç®—èšç±»ç³»æ•°
        G_undirected = G.to_undirected()
        
        # å…¨å±€èšç±»ç³»æ•°ï¼ˆä¼ é€’æ€§ï¼‰
        global_clustering = nx.transitivity(G_undirected)
        
        # å¹³å‡èšç±»ç³»æ•°
        avg_clustering = nx.average_clustering(G_undirected)
        
        # åŠ æƒå¹³å‡èšç±»ç³»æ•°
        try:
            weighted_avg_clustering = nx.average_clustering(G_undirected, weight='weight')
        except:
            weighted_avg_clustering = avg_clustering
        
        return {
            'year': year,
            'global_clustering': global_clustering,
            'avg_clustering': avg_clustering,
            'weighted_avg_clustering': weighted_avg_clustering
        }
        
    except Exception as e:
        return handle_computation_error("calculate_clustering_metrics", year, e,
                                      {'year': year, 'global_clustering': 0, 'avg_clustering': 0})

def calculate_all_global_metrics(G: nx.DiGraph, year: int) -> Dict[str, Any]:
    """
    è®¡ç®—æ‰€æœ‰å…¨å±€ç½‘ç»œæŒ‡æ ‡
    
    Args:
        G: NetworkXæœ‰å‘å›¾
        year: å¹´ä»½
    
    Returns:
        åŒ…å«æ‰€æœ‰å…¨å±€ç½‘ç»œæŒ‡æ ‡çš„å­—å…¸
    """
    logger.info(f"ğŸŒ {year}: å¼€å§‹è®¡ç®—å…¨å±€ç½‘ç»œæŒ‡æ ‡...")
    
    # è®¡ç®—å„ç±»æŒ‡æ ‡
    density_metrics = calculate_density_metrics(G, year)
    connectivity_metrics = calculate_connectivity_metrics(G, year)
    path_metrics = calculate_path_metrics(G, year)
    efficiency_metrics = calculate_efficiency_metrics(G, year)
    clustering_metrics = calculate_clustering_metrics(G, year)
    
    # åˆå¹¶æ‰€æœ‰æŒ‡æ ‡
    all_metrics = {}
    all_metrics.update(density_metrics)
    all_metrics.update(connectivity_metrics)
    all_metrics.update(path_metrics)
    all_metrics.update(efficiency_metrics)
    all_metrics.update(clustering_metrics)
    
    logger.info(f"âœ… {year}: å…¨å±€ç½‘ç»œæŒ‡æ ‡è®¡ç®—å®Œæˆ")
    
    return all_metrics

def get_global_metrics_summary(metrics_dict: Dict[str, Any]) -> Dict[str, Any]:
    """
    ç”Ÿæˆå…¨å±€æŒ‡æ ‡çš„æ‘˜è¦ä¿¡æ¯
    
    Args:
        metrics_dict: å…¨å±€æŒ‡æ ‡å­—å…¸
        
    Returns:
        æ‘˜è¦ä¿¡æ¯å­—å…¸
    """
    year = metrics_dict.get('year', 'Unknown')
    
    summary = {
        'year': year,
        'network_scale': f"{metrics_dict.get('nodes', 0)} nodes, {metrics_dict.get('edges', 0)} edges",
        'connectivity_status': 'Strongly Connected' if metrics_dict.get('is_strongly_connected', False) else 
                              'Weakly Connected' if metrics_dict.get('is_weakly_connected', False) else 'Disconnected',
        'density_level': 'High' if metrics_dict.get('density', 0) > 0.1 else 
                        'Medium' if metrics_dict.get('density', 0) > 0.01 else 'Low',
        'avg_path_length': round(metrics_dict.get('avg_path_length', 0), 2),
        'global_efficiency': round(metrics_dict.get('global_efficiency', 0), 4),
        'clustering_coefficient': round(metrics_dict.get('global_clustering', 0), 4)
    }
    
    return summary