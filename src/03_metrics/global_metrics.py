#!/usr/bin/env python3
"""
å…¨å±€ç½‘ç»œæŒ‡æ ‡è®¡ç®—æ¨¡å—

è´Ÿè´£è®¡ç®—æ•´ä¸ªç½‘ç»œçš„å…¨å±€æ‹“æ‰‘ç‰¹å¾ï¼š
- ç½‘ç»œå¯†åº¦
- è¿é€šæ€§æŒ‡æ ‡  
- è·¯å¾„é•¿åº¦æŒ‡æ ‡ï¼ˆä¿®æ­£åŠ æƒè·¯å¾„è®¡ç®—ï¼‰
- èšç±»ç³»æ•°
- ç½‘ç»œæ•ˆç‡
"""

import networkx as nx
import pandas as pd
import numpy as np
from typing import Dict, Any
from utils import (
    setup_logger, validate_graph, safe_divide, timer_decorator, 
    handle_computation_error, add_distance_weights, get_node_sample
)

logger = setup_logger(__name__)

@timer_decorator
def calculate_density_metrics(G: nx.DiGraph, year: int) -> Dict[str, Any]:
    """
    è®¡ç®—ç½‘ç»œå¯†åº¦ç›¸å…³æŒ‡æ ‡
    
    Args:
        G: NetworkXæœ‰å‘å›¾
        year: å¹´ä»½
    
    Returns:
        å¯†åº¦æŒ‡æ ‡å­—å…¸
    """
    validate_graph(G, "calculate_density_metrics")
    logger.info(f"     {year}: è®¡ç®—ç½‘ç»œå¯†åº¦...")
    
    try:
        n_nodes = G.number_of_nodes()
        n_edges = G.number_of_edges()
        
        # åŸºæœ¬å¯†åº¦
        density = nx.density(G)
        
        # æœ€å¤§å¯èƒ½è¾¹æ•° (æœ‰å‘å›¾)
        max_edges = n_nodes * (n_nodes - 1) if n_nodes > 1 else 0
        
        # æƒé‡å¯†åº¦ (åŸºäºè¾¹æƒé‡)
        edge_weights = [data.get('weight', 0) for _, _, data in G.edges(data=True)]
        total_weight = sum(edge_weights)
        avg_edge_weight = safe_divide(total_weight, n_edges)
        
        return {
            'year': year,
            'density': density,
            'nodes': n_nodes,
            'edges': n_edges,
            'max_possible_edges': max_edges,
            'edge_coverage_ratio': safe_divide(n_edges, max_edges),
            'total_weight': total_weight,
            'avg_edge_weight': avg_edge_weight,
            'weight_density': total_weight / (max_edges * avg_edge_weight) if max_edges > 0 and avg_edge_weight > 0 else 0
        }
        
    except Exception as e:
        return handle_computation_error("calculate_density_metrics", year, e, 
                                      {'year': year, 'density': 0, 'nodes': 0, 'edges': 0})

@timer_decorator
def calculate_connectivity_metrics(G: nx.DiGraph, year: int) -> Dict[str, Any]:
    """
    è®¡ç®—è¿é€šæ€§æŒ‡æ ‡
    
    Args:
        G: NetworkXæœ‰å‘å›¾
        year: å¹´ä»½
    
    Returns:
        è¿é€šæ€§æŒ‡æ ‡å­—å…¸
    """
    validate_graph(G, "calculate_connectivity_metrics")
    logger.info(f"     {year}: è®¡ç®—è¿é€šæ€§æŒ‡æ ‡...")
    
    try:
        # å¼ºè¿é€šæ€§
        is_strongly_connected = nx.is_strongly_connected(G)
        num_strongly_connected_components = nx.number_strongly_connected_components(G)
        
        # å¼±è¿é€šæ€§
        is_weakly_connected = nx.is_weakly_connected(G)
        num_weakly_connected_components = nx.number_weakly_connected_components(G)
        
        # æœ€å¤§å¼ºè¿é€šåˆ†é‡å¤§å°
        if num_strongly_connected_components > 0:
            largest_scc = max(nx.strongly_connected_components(G), key=len)
            largest_scc_size = len(largest_scc)
            largest_scc_ratio = safe_divide(largest_scc_size, G.number_of_nodes())
        else:
            largest_scc_size = 0
            largest_scc_ratio = 0
        
        # æœ€å¤§å¼±è¿é€šåˆ†é‡å¤§å°
        if num_weakly_connected_components > 0:
            largest_wcc = max(nx.weakly_connected_components(G), key=len)
            largest_wcc_size = len(largest_wcc)
            largest_wcc_ratio = safe_divide(largest_wcc_size, G.number_of_nodes())
        else:
            largest_wcc_size = 0
            largest_wcc_ratio = 0
        
        return {
            'year': year,
            'is_strongly_connected': is_strongly_connected,
            'num_strongly_connected_components': num_strongly_connected_components,
            'largest_scc_size': largest_scc_size,
            'largest_scc_ratio': largest_scc_ratio,
            'is_weakly_connected': is_weakly_connected,
            'num_weakly_connected_components': num_weakly_connected_components,
            'largest_wcc_size': largest_wcc_size,
            'largest_wcc_ratio': largest_wcc_ratio
        }
        
    except Exception as e:
        return handle_computation_error("calculate_connectivity_metrics", year, e,
                                      {'year': year, 'is_strongly_connected': False, 'is_weakly_connected': False})

@timer_decorator
def calculate_path_metrics(G: nx.DiGraph, year: int, sample_size: int = 1000) -> Dict[str, Any]:
    """
    è®¡ç®—è·¯å¾„é•¿åº¦ç›¸å…³æŒ‡æ ‡ï¼ˆé‡å†™ç‰ˆæœ¬ï¼šåŸºäºLWCCï¼‰
    
    æ­¥éª¤:
    1. æå–æœ€å¤§å¼±è¿é€šåˆ†é‡(LWCC)
    2. åœ¨LWCCä¸Šè¿›è¡Œè·¯å¾„è®¡ç®—
    3. æŠ¥å‘ŠLWCCè¦†ç›–ç‡æŒ‡æ ‡
    
    Args:
        G: NetworkXæœ‰å‘å›¾
        year: å¹´ä»½
        sample_size: é‡‡æ ·å¤§å°ï¼ˆå¯¹äºå¤§ç½‘ç»œè¿›è¡Œé‡‡æ ·ä»¥åŠ é€Ÿè®¡ç®—ï¼‰
    
    Returns:
        è·¯å¾„æŒ‡æ ‡å­—å…¸ï¼ˆåŒ…å«LWCCè¦†ç›–ç‡ï¼‰
    """
    validate_graph(G, "calculate_path_metrics")
    logger.info(f"     {year}: è®¡ç®—è·¯å¾„é•¿åº¦æŒ‡æ ‡ï¼ˆåŸºäºLWCCï¼‰...")
    
    try:
        # ç¬¬1æ­¥ï¼šæå–æœ€å¤§å¼±è¿é€šåˆ†é‡(LWCC)
        if not nx.is_weakly_connected(G):
            # æ‰¾åˆ°æœ€å¤§å¼±è¿é€šåˆ†é‡
            wcc_components = list(nx.weakly_connected_components(G))
            if not wcc_components:
                logger.warning(f"     {year}: æ²¡æœ‰å¼±è¿é€šåˆ†é‡ï¼Œè¿”å›é›¶å€¼")
                return {
                    'year': year, 'avg_path_length': 0, 'median_path_length': 0,
                    'max_path_length': 0, 'min_path_length': 0,
                    'avg_weighted_path_length': 0, 'median_weighted_path_length': 0,
                    'reachability_ratio': 0, 'sampled_pairs': 0, 'reachable_pairs': 0,
                    'weighted_reachable_pairs': 0, 'lwcc_node_ratio': 0, 'lwcc_edge_ratio': 0
                }
            
            # è·å–æœ€å¤§è¿é€šåˆ†é‡çš„èŠ‚ç‚¹é›†
            largest_wcc_nodes = max(wcc_components, key=len)
            G_lwcc = G.subgraph(largest_wcc_nodes).copy()
        else:
            # æ•´ä¸ªå›¾å°±æ˜¯ä¸€ä¸ªå¼±è¿é€šåˆ†é‡
            G_lwcc = G.copy()
            largest_wcc_nodes = set(G.nodes())
        
        # è®¡ç®—LWCCè¦†ç›–ç‡
        lwcc_node_ratio = len(largest_wcc_nodes) / G.number_of_nodes()
        lwcc_edge_ratio = G_lwcc.number_of_edges() / G.number_of_edges() if G.number_of_edges() > 0 else 0
        
        logger.info(f"     {year}: LWCCè¦†ç›– {len(largest_wcc_nodes)}/{G.number_of_nodes()} èŠ‚ç‚¹ ({lwcc_node_ratio:.3f})")
        
        # ç¬¬2æ­¥ï¼šä¸ºLWCCæ·»åŠ è·ç¦»æƒé‡
        G_lwcc_with_distance = add_distance_weights(G_lwcc)
        
        # ç¬¬3æ­¥ï¼šåœ¨LWCCä¸Šè¿›è¡Œé‡‡æ ·
        lwcc_nodes = list(G_lwcc.nodes())
        n_lwcc_nodes = len(lwcc_nodes)
        
        if n_lwcc_nodes <= sample_size:
            sample_nodes = lwcc_nodes
        else:
            sample_nodes = list(get_node_sample(tuple(lwcc_nodes), sample_size))
        
        path_lengths = []
        weighted_path_lengths = []
        reachable_pairs = 0
        total_pairs = 0
        
        # ç¬¬4æ­¥ï¼šåœ¨LWCCä¸Šè®¡ç®—è·¯å¾„é•¿åº¦
        for source in sample_nodes:
            if source not in G_lwcc:
                continue
                
            try:
                # è®¡ç®—æœªåŠ æƒæœ€çŸ­è·¯å¾„ï¼ˆåœ¨LWCCä¸Šï¼‰
                unweighted_lengths = nx.single_source_shortest_path_length(G_lwcc, source)
                
                # è®¡ç®—åŠ æƒæœ€çŸ­è·¯å¾„ï¼ˆåœ¨LWCCä¸Šä½¿ç”¨distanceæƒé‡ï¼‰
                weighted_lengths = nx.single_source_dijkstra_path_length(G_lwcc_with_distance, source, weight='distance')
                
                for target in sample_nodes:
                    if source != target and target in G_lwcc:
                        total_pairs += 1
                        
                        # æœªåŠ æƒè·¯å¾„
                        if target in unweighted_lengths:
                            path_lengths.append(unweighted_lengths[target])
                            reachable_pairs += 1
                            
                        # åŠ æƒè·¯å¾„
                        if target in weighted_lengths and weighted_lengths[target] != float('inf'):
                            weighted_path_lengths.append(weighted_lengths[target])
                                
            except Exception as e:
                logger.debug(f"     {year}: èŠ‚ç‚¹{source}è·¯å¾„è®¡ç®—å¤±è´¥: {e}")
                continue
        
        # ç¬¬5æ­¥ï¼šè®¡ç®—ç»Ÿè®¡é‡
        if path_lengths:
            avg_path_length = np.mean(path_lengths)
            median_path_length = np.median(path_lengths)  
            max_path_length = np.max(path_lengths)
            min_path_length = np.min(path_lengths)
        else:
            avg_path_length = median_path_length = max_path_length = min_path_length = 0
        
        if weighted_path_lengths:
            avg_weighted_path_length = np.mean(weighted_path_lengths)
            median_weighted_path_length = np.median(weighted_path_lengths)
        else:
            avg_weighted_path_length = median_weighted_path_length = 0
        
        reachability_ratio = safe_divide(reachable_pairs, total_pairs)
        
        logger.info(f"     {year}: è·¯å¾„ç»Ÿè®¡ - å¹³å‡é•¿åº¦: {avg_path_length:.2f}, å¯è¾¾ç‡: {reachability_ratio:.3f}")
        
        return {
            'year': year,
            'avg_path_length': avg_path_length,
            'median_path_length': median_path_length,
            'max_path_length': max_path_length,
            'min_path_length': min_path_length,
            'avg_weighted_path_length': avg_weighted_path_length,
            'median_weighted_path_length': median_weighted_path_length,
            'reachability_ratio': reachability_ratio,
            'sampled_pairs': total_pairs,
            'reachable_pairs': reachable_pairs,
            'weighted_reachable_pairs': len(weighted_path_lengths),
            'lwcc_node_ratio': lwcc_node_ratio,
            'lwcc_edge_ratio': lwcc_edge_ratio
        }
        
    except Exception as e:
        return handle_computation_error("calculate_path_metrics", year, e,
                                      {'year': year, 'avg_path_length': 0, 'reachability_ratio': 0,
                                       'lwcc_node_ratio': 0, 'lwcc_edge_ratio': 0})

@timer_decorator
def calculate_efficiency_metrics(G: nx.DiGraph, year: int, sample_size: int = 500) -> Dict[str, Any]:
    """
    è®¡ç®—ç½‘ç»œæ•ˆç‡æŒ‡æ ‡ï¼ˆé‡å†™ç‰ˆæœ¬ï¼šåŸºäºLWCCï¼‰
    
    æ­¥éª¤:
    1. æå–æœ€å¤§å¼±è¿é€šåˆ†é‡(LWCC)  
    2. åœ¨LWCCä¸Šè¿›è¡Œæ•ˆç‡è®¡ç®—
    
    Args:
        G: NetworkXæœ‰å‘å›¾
        year: å¹´ä»½
        sample_size: é‡‡æ ·å¤§å°
    
    Returns:
        æ•ˆç‡æŒ‡æ ‡å­—å…¸
    """
    validate_graph(G, "calculate_efficiency_metrics")
    logger.info(f"     {year}: è®¡ç®—ç½‘ç»œæ•ˆç‡ï¼ˆåŸºäºLWCCï¼‰...")
    
    try:
        # ç¬¬1æ­¥ï¼šæå–æœ€å¤§å¼±è¿é€šåˆ†é‡(LWCC)
        if not nx.is_weakly_connected(G):
            # æ‰¾åˆ°æœ€å¤§å¼±è¿é€šåˆ†é‡
            wcc_components = list(nx.weakly_connected_components(G))
            if not wcc_components:
                logger.warning(f"     {year}: æ²¡æœ‰å¼±è¿é€šåˆ†é‡ï¼Œæ•ˆç‡ä¸º0")
                return {
                    'year': year,
                    'global_efficiency': 0,
                    'weighted_global_efficiency': 0,
                    'efficiency_sample_size': 0,
                    'efficiency_sample_pairs': 0
                }
            
            # è·å–æœ€å¤§è¿é€šåˆ†é‡çš„èŠ‚ç‚¹é›†
            largest_wcc_nodes = max(wcc_components, key=len)
            G_lwcc = G.subgraph(largest_wcc_nodes).copy()
        else:
            # æ•´ä¸ªå›¾å°±æ˜¯ä¸€ä¸ªå¼±è¿é€šåˆ†é‡
            G_lwcc = G.copy()
            largest_wcc_nodes = set(G.nodes())
        
        # ç¬¬2æ­¥ï¼šä¸ºLWCCæ·»åŠ è·ç¦»æƒé‡
        G_lwcc_with_distance = add_distance_weights(G_lwcc)
        
        # ç¬¬3æ­¥ï¼šåœ¨LWCCä¸Šè¿›è¡Œé‡‡æ ·
        lwcc_nodes = list(G_lwcc.nodes())
        n_lwcc_nodes = len(lwcc_nodes)
        
        if n_lwcc_nodes <= sample_size:
            sample_nodes = lwcc_nodes
        else:
            sample_nodes = list(get_node_sample(tuple(lwcc_nodes), sample_size))
        
        efficiency_sum = 0
        weighted_efficiency_sum = 0
        total_pairs = 0
        
        # ç¬¬4æ­¥ï¼šåœ¨LWCCä¸Šè®¡ç®—æ•ˆç‡
        for source in sample_nodes:
            if source not in G_lwcc:
                continue
                
            try:
                # æœªåŠ æƒè·¯å¾„é•¿åº¦ï¼ˆåœ¨LWCCä¸Šï¼‰
                unweighted_lengths = nx.single_source_shortest_path_length(G_lwcc, source)
                
                # åŠ æƒè·¯å¾„é•¿åº¦ï¼ˆåœ¨LWCCä¸Šä½¿ç”¨distanceæƒé‡ï¼‰
                weighted_lengths = nx.single_source_dijkstra_path_length(G_lwcc_with_distance, source, weight='distance')
                
                for target in sample_nodes:
                    if source != target and target in G_lwcc:
                        total_pairs += 1
                        
                        # æœªåŠ æƒæ•ˆç‡
                        if target in unweighted_lengths and unweighted_lengths[target] > 0:
                            efficiency_sum += 1.0 / unweighted_lengths[target]
                        
                        # åŠ æƒæ•ˆç‡
                        if target in weighted_lengths and weighted_lengths[target] > 0 and weighted_lengths[target] != float('inf'):
                            weighted_efficiency_sum += 1.0 / weighted_lengths[target]
                            
            except Exception as e:
                logger.debug(f"     {year}: èŠ‚ç‚¹{source}æ•ˆç‡è®¡ç®—å¤±è´¥: {e}")
                continue
        
        global_efficiency = safe_divide(efficiency_sum, total_pairs)
        weighted_global_efficiency = safe_divide(weighted_efficiency_sum, total_pairs)
        
        logger.info(f"     {year}: æ•ˆç‡ç»Ÿè®¡ - å…¨å±€æ•ˆç‡: {global_efficiency:.4f}, åŠ æƒæ•ˆç‡: {weighted_global_efficiency:.4f}")
        
        return {
            'year': year,
            'global_efficiency': global_efficiency,
            'weighted_global_efficiency': weighted_global_efficiency,
            'efficiency_sample_size': len(sample_nodes),
            'efficiency_sample_pairs': total_pairs
        }
        
    except Exception as e:
        return handle_computation_error("calculate_efficiency_metrics", year, e,
                                      {'year': year, 'global_efficiency': 0, 'weighted_global_efficiency': 0})

@timer_decorator
def calculate_clustering_metrics(G: nx.DiGraph, year: int) -> Dict[str, Any]:
    """
    è®¡ç®—èšç±»ç³»æ•°ç›¸å…³æŒ‡æ ‡
    
    Args:
        G: NetworkXæœ‰å‘å›¾
        year: å¹´ä»½
    
    Returns:
        èšç±»æŒ‡æ ‡å­—å…¸
    """
    validate_graph(G, "calculate_clustering_metrics")
    logger.info(f"     {year}: è®¡ç®—èšç±»ç³»æ•°...")
    
    try:
        # è½¬æ¢ä¸ºæ— å‘å›¾è®¡ç®—èšç±»ç³»æ•°
        G_undirected = G.to_undirected()
        
        # å…¨å±€èšç±»ç³»æ•°ï¼ˆä¼ é€’æ€§ï¼‰
        global_clustering = nx.transitivity(G_undirected)
        
        # å¹³å‡èšç±»ç³»æ•°
        avg_clustering = nx.average_clustering(G_undirected)
        
        # åŠ æƒå¹³å‡èšç±»ç³»æ•°
        try:
            weighted_avg_clustering = nx.average_clustering(G_undirected, weight='weight')
        except:
            weighted_avg_clustering = avg_clustering
        
        return {
            'year': year,
            'global_clustering': global_clustering,
            'avg_clustering': avg_clustering,
            'weighted_avg_clustering': weighted_avg_clustering
        }
        
    except Exception as e:
        return handle_computation_error("calculate_clustering_metrics", year, e,
                                      {'year': year, 'global_clustering': 0, 'avg_clustering': 0})

def calculate_all_global_metrics(G: nx.DiGraph, year: int) -> pd.DataFrame:
    """
    è®¡ç®—æ‰€æœ‰å…¨å±€ç½‘ç»œæŒ‡æ ‡ï¼Œè¿”å›å•è¡ŒDataFrame
    
    Args:
        G: NetworkXæœ‰å‘å›¾
        year: å¹´ä»½
    
    Returns:
        åŒ…å«æ‰€æœ‰å…¨å±€ç½‘ç»œæŒ‡æ ‡çš„å•è¡ŒDataFrame
    """
    logger.info(f"ğŸŒ {year}: å¼€å§‹è®¡ç®—å…¨å±€ç½‘ç»œæŒ‡æ ‡...")
    
    # è®¡ç®—å„ç±»æŒ‡æ ‡
    density_metrics = calculate_density_metrics(G, year)
    connectivity_metrics = calculate_connectivity_metrics(G, year)
    path_metrics = calculate_path_metrics(G, year)
    efficiency_metrics = calculate_efficiency_metrics(G, year)
    clustering_metrics = calculate_clustering_metrics(G, year)
    
    # åˆå¹¶æ‰€æœ‰æŒ‡æ ‡
    all_metrics = {}
    all_metrics.update(density_metrics)
    all_metrics.update(connectivity_metrics)
    all_metrics.update(path_metrics)
    all_metrics.update(efficiency_metrics)
    all_metrics.update(clustering_metrics)
    
    # è½¬æ¢ä¸ºDataFrameï¼ˆå•è¡Œï¼‰
    global_df = pd.DataFrame([all_metrics])
    
    logger.info(f"âœ… {year}: å…¨å±€ç½‘ç»œæŒ‡æ ‡è®¡ç®—å®Œæˆï¼Œå…± {len(all_metrics)} ä¸ªæŒ‡æ ‡")
    
    return global_df

def get_global_metrics_summary(metrics_dict: Dict[str, Any]) -> Dict[str, Any]:
    """
    ç”Ÿæˆå…¨å±€æŒ‡æ ‡çš„æ‘˜è¦ä¿¡æ¯
    
    Args:
        metrics_dict: å…¨å±€æŒ‡æ ‡å­—å…¸
        
    Returns:
        æ‘˜è¦ä¿¡æ¯å­—å…¸
    """
    year = metrics_dict.get('year', 'Unknown')
    
    summary = {
        'year': year,
        'network_scale': f"{metrics_dict.get('nodes', 0)} nodes, {metrics_dict.get('edges', 0)} edges",
        'connectivity_status': 'Strongly Connected' if metrics_dict.get('is_strongly_connected', False) else 
                              'Weakly Connected' if metrics_dict.get('is_weakly_connected', False) else 'Disconnected',
        'density_level': 'High' if metrics_dict.get('density', 0) > 0.1 else 
                        'Medium' if metrics_dict.get('density', 0) > 0.01 else 'Low',
        'avg_path_length': round(metrics_dict.get('avg_path_length', 0), 2),
        'global_efficiency': round(metrics_dict.get('global_efficiency', 0), 4),
        'clustering_coefficient': round(metrics_dict.get('global_clustering', 0), 4)
    }
    
    return summary