#!/usr/bin/env python3
"""
æ•°æ®å‡†å¤‡æ¨¡å— (Data Preparation Module)
=====================================

æœ¬æ¨¡å—è´Ÿè´£ä¸ºDLIåˆ†æå‡†å¤‡æ‰€éœ€çš„æ•°æ®ï¼š
1. åŠ è½½ç¾å›½ç›¸å…³çš„èƒ½æºè´¸æ˜“æ•°æ®ï¼ˆä½œä¸ºè¿›å£å›½æˆ–å‡ºå£å›½ï¼‰
2. è¡¥å……åœ°ç†è·ç¦»æ•°æ®
3. æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–å¤„ç†

ä½œè€…ï¼šEnergy Network Analysis Team
"""

import pandas as pd
import numpy as np
from pathlib import Path
import logging
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# èƒ½æºäº§å“ä»£ç æ˜ å°„
ENERGY_PRODUCTS = {
    '2701': 'Coal',
    '2709': 'Crude_Oil', 
    '2710': 'Refined_Oil',
    '2711': 'Natural_Gas'
}

def load_country_distances() -> Dict[str, float]:
    """
    åŠ è½½å®Œæ•´çš„å›½å®¶è·ç¦»æ•°æ®
    
    ä½¿ç”¨CEPIIæ•°æ®æºçš„ç²¾ç¡®è·ç¦»æ•°æ®ï¼ŒåŸºäºäººå£åŠ æƒä¸­å¿ƒè·ç¦»è®¡ç®—
    
    Returns:
        å›½å®¶ä»£ç åˆ°ç¾å›½è·ç¦»çš„å­—å…¸ï¼ˆå•ä½ï¼šå…¬é‡Œï¼‰
    """
    import json
    
    # å°è¯•åŠ è½½å®Œæ•´çš„è·ç¦»æ•°æ®
    distance_file = Path(__file__).parent / "complete_us_distances_cepii.json"
    
    if distance_file.exists():
        try:
            with open(distance_file, 'r', encoding='utf-8') as f:
                distances = json.load(f)
            logger.info(f"æˆåŠŸåŠ è½½å®Œæ•´è·ç¦»æ•°æ®: {len(distances)} ä¸ªå›½å®¶")
            return distances
        except Exception as e:
            logger.warning(f"åŠ è½½å®Œæ•´è·ç¦»æ•°æ®å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ä»½æ•°æ®")
    
    # å¤‡ä»½è·ç¦»æ•°æ®ï¼ˆåŸºäºé¦–éƒ½åˆ°åç››é¡¿DCçš„è·ç¦»ï¼Œå•ä½ï¼šå…¬é‡Œï¼‰
    backup_distances = {
        'CAN': 735,     # æ¸¥å¤ªå-åç››é¡¿
        'MEX': 1887,    # å¢¨è¥¿å“¥åŸ-åç››é¡¿  
        'SAU': 11140,   # åˆ©é›…å¾—-åç››é¡¿
        'QAT': 11235,   # å¤šå“ˆ-åç››é¡¿
        'VEN': 3367,    # åŠ æ‹‰åŠ æ–¯-åç››é¡¿
        'NOR': 6120,    # å¥¥æ–¯é™†-åç››é¡¿
        'GBR': 5900,    # ä¼¦æ•¦-åç››é¡¿
        'CHN': 11172,   # åŒ—äº¬-åç››é¡¿
        'RUS': 7816,    # è«æ–¯ç§‘-åç››é¡¿
        'ARE': 11575,   # é˜¿å¸ƒæ‰æ¯”-åç››é¡¿
        'IND': 12342,   # æ–°å¾·é‡Œ-åç››é¡¿
        'JPN': 10906,   # ä¸œäº¬-åç››é¡¿
        'KOR': 11014,   # é¦–å°”-åç››é¡¿
        'BRA': 6834,    # å·´è¥¿åˆ©äºš-åç››é¡¿
        'ARG': 8531,    # å¸ƒå®œè¯ºæ–¯è‰¾åˆ©æ–¯-åç››é¡¿
        'COL': 3593,    # æ³¢å“¥å¤§-åç››é¡¿
        'ECU': 4406,    # åŸºå¤š-åç››é¡¿
        'TTO': 3458,    # è¥¿ç­ç‰™æ¸¯-åç››é¡¿
        'NLD': 5862,    # é˜¿å§†æ–¯ç‰¹ä¸¹-åç››é¡¿
        'AGO': 10152,   # ç½—å®‰è¾¾-åç››é¡¿
        'NGA': 9568,    # é˜¿å¸ƒè´¾-åç››é¡¿
        'IRQ': 10327,   # å·´æ ¼è¾¾-åç››é¡¿
        'IRN': 10856,   # å¾·é»‘å…°-åç››é¡¿
        'KWT': 10823,   # ç§‘å¨ç‰¹åŸ-åç››é¡¿
        'DZA': 7520,    # é˜¿å°”åŠå°”-åç››é¡¿
        'LBY': 8850,    # çš„é»æ³¢é‡Œ-åç››é¡¿
        'EGY': 9100,    # å¼€ç½—-åç››é¡¿
    }
    
    logger.warning(f"ä½¿ç”¨å¤‡ä»½è·ç¦»æ•°æ®: {len(backup_distances)} ä¸ªå›½å®¶")
    return backup_distances

# å…¨å±€è·ç¦»æ•°æ®ï¼ˆåœ¨æ¨¡å—åŠ è½½æ—¶åˆå§‹åŒ–ï¼‰
COUNTRY_DISTANCES = load_country_distances()

def robust_outlier_treatment(df: pd.DataFrame, column: str, 
                           method: str = 'iqr', factor: float = 1.5) -> pd.DataFrame:
    """
    ç¨³å¥çš„å¼‚å¸¸å€¼æ£€æµ‹å’Œå¤„ç†
    
    Args:
        df: è¾“å…¥DataFrame
        column: éœ€è¦å¤„ç†çš„åˆ—å
        method: å¼‚å¸¸å€¼æ£€æµ‹æ–¹æ³• ('iqr' æˆ– 'zscore')
        factor: å¼‚å¸¸å€¼é˜ˆå€¼å› å­
        
    Returns:
        æ·»åŠ äº†å¼‚å¸¸å€¼æ ‡è®°å’Œæ¸©èåŒ–å¤„ç†åˆ—çš„DataFrame
        
    æ–°å¢åˆ—ï¼š
        - {column}_is_outlier: å¼‚å¸¸å€¼æ ‡è®°
        - {column}_winsorized: æ¸©èåŒ–å¤„ç†åçš„å€¼
    """
    
    if column not in df.columns:
        logger.warning(f"åˆ— {column} ä¸å­˜åœ¨ï¼Œè·³è¿‡å¼‚å¸¸å€¼å¤„ç†")
        return df
    
    df_result = df.copy()
    
    if method == 'iqr':
        Q1 = df_result[column].quantile(0.25)
        Q3 = df_result[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - factor * IQR
        upper_bound = Q3 + factor * IQR
        
        # æ ‡è®°å¼‚å¸¸å€¼
        df_result[f'{column}_is_outlier'] = (
            (df_result[column] < lower_bound) | 
            (df_result[column] > upper_bound)
        )
        
        # æ¸©èåŒ–å¤„ç†
        df_result[f'{column}_winsorized'] = df_result[column].clip(lower_bound, upper_bound)
        
        logger.info(f"IQRå¼‚å¸¸å€¼æ£€æµ‹ - {column}: é˜ˆå€¼=[{lower_bound:.2e}, {upper_bound:.2e}]")
        
    elif method == 'zscore':
        mean_val = df_result[column].mean()
        std_val = df_result[column].std()
        z_scores = np.abs((df_result[column] - mean_val) / std_val)
        
        # æ ‡è®°å¼‚å¸¸å€¼
        df_result[f'{column}_is_outlier'] = z_scores > factor
        
        # æ¸©èåŒ–å¤„ç†
        lower_bound = mean_val - factor * std_val
        upper_bound = mean_val + factor * std_val
        df_result[f'{column}_winsorized'] = df_result[column].clip(lower_bound, upper_bound)
        
        logger.info(f"Z-scoreå¼‚å¸¸å€¼æ£€æµ‹ - {column}: é˜ˆå€¼=Â±{factor}, èŒƒå›´=[{lower_bound:.2e}, {upper_bound:.2e}]")
    
    else:
        logger.warning(f"æœªçŸ¥çš„å¼‚å¸¸å€¼æ£€æµ‹æ–¹æ³•: {method}")
        return df
    
    outlier_count = df_result[f'{column}_is_outlier'].sum()
    outlier_pct = outlier_count / len(df_result) * 100
    
    logger.info(f"{column}å¼‚å¸¸å€¼: {outlier_count} æ¡ ({outlier_pct:.2f}%)")
    
    return df_result

def load_us_trade_data(data_dir: str = None) -> pd.DataFrame:
    """
    åŠ è½½ç¾å›½ç›¸å…³çš„èƒ½æºè´¸æ˜“æ•°æ®
    
    Args:
        data_dir: æ•°æ®ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨é¡¹ç›®æ ‡å‡†è·¯å¾„
        
    Returns:
        åŒ…å«ç¾å›½ä½œä¸ºè¿›å£å›½æˆ–å‡ºå£å›½çš„æ‰€æœ‰èƒ½æºè´¸æ˜“æ•°æ®çš„DataFrame
        
    æ•°æ®ç»“æ„ï¼š
        - year: å¹´ä»½
        - reporter: æŠ¥å‘Šå›½ä»£ç 
        - partner: ä¼™ä¼´å›½ä»£ç   
        - flow: è´¸æ˜“æµå‘ (M=Import, X=Export)
        - product_code: èƒ½æºäº§å“ä»£ç 
        - product_name: äº§å“åç§°
        - trade_value_usd: è´¸æ˜“å€¼ï¼ˆç¾å…ƒï¼‰
        - us_role: ç¾å›½è§’è‰² ('importer' æˆ– 'exporter')
        - us_partner: ç¾å›½çš„è´¸æ˜“ä¼™ä¼´å›½
        - energy_product: æ ‡å‡†åŒ–çš„èƒ½æºäº§å“åç§°
    """
    
    logger.info("ğŸš€ å¼€å§‹åŠ è½½ç¾å›½èƒ½æºè´¸æ˜“æ•°æ®...")
    
    # è®¾ç½®æ•°æ®è·¯å¾„
    if data_dir is None:
        base_dir = Path(__file__).parent.parent.parent  # åˆ°è¾¾energy_networkç›®å½•
        data_dir = base_dir / "data" / "processed_data"
    else:
        data_dir = Path(data_dir)
    
    if not data_dir.exists():
        raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
    
    # åŠ è½½æ‰€æœ‰å¹´ä»½çš„æ•°æ®
    all_us_trade = []
    years_processed = 0
    
    for year in range(2001, 2025):
        file_path = data_dir / f"cleaned_energy_trade_{year}.csv"
        
        if not file_path.exists():
            logger.warning(f"âŒ {year}å¹´æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue
            
        try:
            # è¯»å–å¹´åº¦æ•°æ®
            df = pd.read_csv(file_path)
            logger.info(f"ğŸ“‚ {year}: åŠ è½½äº† {len(df):,} æ¡è´¸æ˜“è®°å½•")
            
            # ç­›é€‰ç¾å›½ç›¸å…³çš„è´¸æ˜“æ•°æ®
            # æƒ…å†µ1ï¼šç¾å›½ä½œä¸ºæŠ¥å‘Šå›½ï¼ˆè¿›å£å•†æˆ–å‡ºå£å•†ï¼‰
            usa_as_reporter = df[df['reporter'] == 'USA'].copy()
            if len(usa_as_reporter) > 0:
                usa_as_reporter['us_role'] = usa_as_reporter['flow'].map({'M': 'importer', 'X': 'exporter'})
                usa_as_reporter['us_partner'] = usa_as_reporter['partner']
                
            # æƒ…å†µ2ï¼šç¾å›½ä½œä¸ºä¼™ä¼´å›½
            usa_as_partner = df[df['partner'] == 'USA'].copy()
            if len(usa_as_partner) > 0:
                # å½“USAä½œä¸ºä¼™ä¼´å›½æ—¶ï¼Œæµå‘éœ€è¦åå‘ç†è§£
                usa_as_partner['us_role'] = usa_as_partner['flow'].map({'M': 'exporter', 'X': 'importer'})
                usa_as_partner['us_partner'] = usa_as_partner['reporter']
                # è°ƒæ•´reporterå’Œpartneråˆ—ï¼Œä½¿USAå§‹ç»ˆåœ¨reporterä½ç½®
                usa_as_partner = usa_as_partner.rename(columns={
                    'reporter': 'temp_partner',
                    'partner': 'reporter'
                })
                usa_as_partner = usa_as_partner.rename(columns={
                    'temp_partner': 'partner'
                })
                # ç›¸åº”åœ°è°ƒæ•´æµå‘
                usa_as_partner['flow'] = usa_as_partner['us_role'].map({'importer': 'M', 'exporter': 'X'})
            
            # åˆå¹¶ä¸¤ç§æƒ…å†µçš„æ•°æ®
            year_usa_trade = []
            if len(usa_as_reporter) > 0:
                year_usa_trade.append(usa_as_reporter)
            if len(usa_as_partner) > 0:
                year_usa_trade.append(usa_as_partner)
                
            if year_usa_trade:
                year_df = pd.concat(year_usa_trade, ignore_index=True)
                
                # é‡å‘½åè´¸æ˜“å€¼åˆ—
                year_df = year_df.rename(columns={'trade_value_raw_usd': 'trade_value_usd'})
                
                # æ ‡å‡†åŒ–èƒ½æºäº§å“åç§°ï¼ˆç¡®ä¿product_codeæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼‰
                year_df['product_code'] = year_df['product_code'].astype(str)
                year_df['energy_product'] = year_df['product_code'].map(ENERGY_PRODUCTS)
                
                # é€‰æ‹©éœ€è¦çš„åˆ—
                columns_to_keep = [
                    'year', 'reporter', 'partner', 'flow', 'product_code', 
                    'product_name', 'trade_value_usd', 'us_role', 'us_partner', 'energy_product'
                ]
                year_df = year_df[columns_to_keep]
                
                all_us_trade.append(year_df)
                years_processed += 1
                logger.info(f"âœ… {year}: æå–äº† {len(year_df):,} æ¡ç¾å›½ç›¸å…³è´¸æ˜“è®°å½•")
            else:
                logger.warning(f"âš ï¸  {year}: æœªæ‰¾åˆ°ç¾å›½ç›¸å…³è´¸æ˜“æ•°æ®")
                
        except Exception as e:
            logger.error(f"âŒ å¤„ç†{year}å¹´æ•°æ®æ—¶å‡ºé”™: {e}")
            continue
    
    if not all_us_trade:
        raise ValueError("æœªæ‰¾åˆ°ä»»ä½•ç¾å›½ç›¸å…³çš„è´¸æ˜“æ•°æ®")
    
    # åˆå¹¶æ‰€æœ‰å¹´ä»½æ•°æ®
    us_trade_df = pd.concat(all_us_trade, ignore_index=True)
    
    # æ•°æ®è´¨é‡æ£€æŸ¥
    logger.info("ğŸ” æ‰§è¡Œæ•°æ®è´¨é‡æ£€æŸ¥...")
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    missing_values = us_trade_df.isnull().sum()
    if missing_values.any():
        logger.warning(f"å‘ç°ç¼ºå¤±å€¼: {missing_values[missing_values > 0].to_dict()}")
    
    # æ£€æŸ¥è´¸æ˜“å€¼
    invalid_trade_values = us_trade_df[us_trade_df['trade_value_usd'] <= 0]
    if len(invalid_trade_values) > 0:
        logger.warning(f"å‘ç° {len(invalid_trade_values)} æ¡æ— æ•ˆè´¸æ˜“å€¼è®°å½•ï¼ˆ<=0ï¼‰ï¼Œå°†è¢«ç§»é™¤")
        us_trade_df = us_trade_df[us_trade_df['trade_value_usd'] > 0]
    
    # æ•°æ®æ‘˜è¦ç»Ÿè®¡
    logger.info(f"ğŸ“Š ç¾å›½è´¸æ˜“æ•°æ®æ‘˜è¦:")
    logger.info(f"  æ€»è®°å½•æ•°: {len(us_trade_df):,}")
    logger.info(f"  å¹´ä»½èŒƒå›´: {us_trade_df['year'].min()}-{us_trade_df['year'].max()}")
    logger.info(f"  è´¸æ˜“ä¼™ä¼´æ•°: {us_trade_df['us_partner'].nunique()}")
    logger.info(f"  èƒ½æºäº§å“æ•°: {us_trade_df['energy_product'].nunique()}")
    logger.info(f"  æ€»è´¸æ˜“é¢: ${us_trade_df['trade_value_usd'].sum():,.0f}")
    
    # æŒ‰è§’è‰²ç»Ÿè®¡
    role_stats = us_trade_df.groupby('us_role')['trade_value_usd'].agg(['count', 'sum'])
    logger.info(f"  æŒ‰ç¾å›½è§’è‰²ç»Ÿè®¡:")
    for role, stats in role_stats.iterrows():
        logger.info(f"    {role}: {stats['count']:,} æ¡è®°å½•, ${stats['sum']:,.0f}")
    
    # æŒ‰äº§å“ç»Ÿè®¡  
    product_stats = us_trade_df.groupby('energy_product')['trade_value_usd'].agg(['count', 'sum'])
    logger.info(f"  æŒ‰èƒ½æºäº§å“ç»Ÿè®¡:")
    for product, stats in product_stats.iterrows():
        logger.info(f"    {product}: {stats['count']:,} æ¡è®°å½•, ${stats['sum']:,.0f}")
    
    logger.info("âœ… ç¾å›½èƒ½æºè´¸æ˜“æ•°æ®åŠ è½½å®Œæˆ!")
    return us_trade_df

def add_distance_data(trade_df: pd.DataFrame) -> pd.DataFrame:
    """
    ä¸ºç¾å›½è´¸æ˜“æ•°æ®æ·»åŠ åœ°ç†è·ç¦»ä¿¡æ¯
    
    Args:
        trade_df: åŒ…å«ç¾å›½è´¸æ˜“æ•°æ®çš„DataFrame
        
    Returns:
        æ·»åŠ äº†distance_kmåˆ—çš„DataFrame
        
    æ³¨æ„ï¼š
        - è·ç¦»æ•°æ®åŸºäºå„å›½é¦–éƒ½åˆ°åç››é¡¿DCçš„å¤§åœ†è·ç¦»
        - å¯¹äºæœªåŒ…å«åœ¨è·ç¦»å­—å…¸ä¸­çš„å›½å®¶ï¼Œä½¿ç”¨å…¨çƒå¹³å‡è·ç¦»ä½œä¸ºä¼°è®¡å€¼
    """
    
    logger.info("ğŸŒ å¼€å§‹æ·»åŠ åœ°ç†è·ç¦»æ•°æ®...")
    
    df = trade_df.copy()
    
    # æ·»åŠ è·ç¦»åˆ—
    df['distance_km'] = df['us_partner'].map(COUNTRY_DISTANCES)
    
    # å¤„ç†æœªçŸ¥å›½å®¶
    unknown_countries = df[df['distance_km'].isnull()]['us_partner'].unique()
    total_countries_in_data = df['us_partner'].nunique()
    known_countries = total_countries_in_data - len(unknown_countries)
    
    logger.info(f"ğŸ“ è·ç¦»æ•°æ®åŒ¹é…æƒ…å†µ:")
    logger.info(f"  æ•°æ®ä¸­æ€»å›½å®¶æ•°: {total_countries_in_data}")
    logger.info(f"  æˆåŠŸåŒ¹é…: {known_countries} ä¸ªå›½å®¶ ({known_countries/total_countries_in_data*100:.1f}%)")
    logger.info(f"  éœ€è¦ä¼°ç®—: {len(unknown_countries)} ä¸ªå›½å®¶ ({len(unknown_countries)/total_countries_in_data*100:.1f}%)")
    
    if len(unknown_countries) > 0:
        # ä½¿ç”¨å…¨çƒå¹³å‡è·ç¦»
        global_avg_distance = np.mean(list(COUNTRY_DISTANCES.values()))
        logger.info(f"å¯¹æœªçŸ¥å›½å®¶ä½¿ç”¨å…¨çƒå¹³å‡è·ç¦»: {global_avg_distance:.0f}km")
        
        if len(unknown_countries) <= 10:
            logger.info(f"æœªçŸ¥å›½å®¶åˆ—è¡¨: {list(unknown_countries)}")
        else:
            logger.info(f"æœªçŸ¥å›½å®¶æ•°é‡è¾ƒå¤šï¼Œæ˜¾ç¤ºå‰10ä¸ª: {list(unknown_countries[:10])}")
        
        df['distance_km'] = df['distance_km'].fillna(global_avg_distance)
    
    # æ•°æ®éªŒè¯
    assert df['distance_km'].isnull().sum() == 0, "è·ç¦»æ•°æ®ä¸­ä»æœ‰ç¼ºå¤±å€¼"
    
    # è·ç¦»ç»Ÿè®¡
    logger.info(f"ğŸ“ è·ç¦»æ•°æ®ç»Ÿè®¡:")
    logger.info(f"  æœ€è¿‘è·ç¦»: {df['distance_km'].min():.0f} km")
    logger.info(f"  æœ€è¿œè·ç¦»: {df['distance_km'].max():.0f} km") 
    logger.info(f"  å¹³å‡è·ç¦»: {df['distance_km'].mean():.0f} km")
    
    # æŒ‰è·ç¦»åŒºé—´ç»Ÿè®¡è´¸æ˜“ä¼™ä¼´
    distance_bins = [0, 2000, 5000, 8000, 15000]
    distance_labels = ['é‚»è¿‘(<2000km)', 'è¿‘è·ç¦»(2-5000km)', 'ä¸­è·ç¦»(5-8000km)', 'è¿œè·ç¦»(>8000km)']
    df['distance_category'] = pd.cut(df['distance_km'], bins=distance_bins, labels=distance_labels, include_lowest=True)
    
    distance_partner_stats = df.groupby('distance_category')['us_partner'].nunique()
    logger.info(f"  æŒ‰è·ç¦»åŒºé—´çš„è´¸æ˜“ä¼™ä¼´æ•°:")
    for category, count in distance_partner_stats.items():
        logger.info(f"    {category}: {count} ä¸ªå›½å®¶")
    
    logger.info("âœ… åœ°ç†è·ç¦»æ•°æ®æ·»åŠ å®Œæˆ!")
    return df

def prepare_dli_dataset(data_dir: str = None) -> pd.DataFrame:
    """
    å‡†å¤‡DLIåˆ†æçš„å®Œæ•´æ•°æ®é›†
    
    è¿™æ˜¯æ•°æ®å‡†å¤‡æ¨¡å—çš„ä¸»è¦æ¥å£å‡½æ•°ï¼Œæ•´åˆäº†æ‰€æœ‰æ•°æ®å‡†å¤‡æ­¥éª¤
    
    Args:
        data_dir: æ•°æ®ç›®å½•è·¯å¾„
        
    Returns:
        å®Œæ•´çš„ã€å‡†å¤‡å¥½è¿›è¡ŒDLIåˆ†æçš„DataFrame
        
    åŒ…å«ä»¥ä¸‹åˆ—ï¼š
        - year, reporter, partner, flow, product_code, product_name
        - trade_value_usd, us_role, us_partner, energy_product
        - distance_km, distance_category
    """
    
    logger.info("ğŸ¯ å¼€å§‹å‡†å¤‡DLIåˆ†ææ•°æ®é›†...")
    
    # ç¬¬1æ­¥ï¼šåŠ è½½ç¾å›½è´¸æ˜“æ•°æ®
    us_trade_df = load_us_trade_data(data_dir)
    
    # ç¬¬2æ­¥ï¼šæ·»åŠ è·ç¦»æ•°æ®
    complete_df = add_distance_data(us_trade_df)
    
    # ç¬¬3æ­¥ï¼šæœ€ç»ˆæ•°æ®éªŒè¯å’Œæ¸…æ´—
    logger.info("ğŸ”§ æ‰§è¡Œæœ€ç»ˆæ•°æ®éªŒè¯å’Œå¼‚å¸¸å€¼å¤„ç†...")
    
    # ç§»é™¤é‡å¤è®°å½•
    initial_rows = len(complete_df)
    complete_df = complete_df.drop_duplicates()
    removed_duplicates = initial_rows - len(complete_df)
    if removed_duplicates > 0:
        logger.info(f"ç§»é™¤äº† {removed_duplicates} æ¡é‡å¤è®°å½•")
    
    # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
    complete_df['year'] = complete_df['year'].astype(int)
    complete_df['trade_value_usd'] = complete_df['trade_value_usd'].astype(float)
    complete_df['distance_km'] = complete_df['distance_km'].astype(float)
    
    # å¼‚å¸¸å€¼æ£€æµ‹å’Œå¤„ç†
    complete_df = robust_outlier_treatment(complete_df, 'trade_value_usd', method='iqr', factor=3.0)
    complete_df = robust_outlier_treatment(complete_df, 'distance_km', method='iqr', factor=2.0)
    
    # æŠ¥å‘Šå¼‚å¸¸å€¼æƒ…å†µ
    trade_outliers = complete_df['trade_value_usd_is_outlier'].sum()
    distance_outliers = complete_df['distance_km_is_outlier'].sum()
    
    if trade_outliers > 0 or distance_outliers > 0:
        logger.info(f"ğŸ“Š å¼‚å¸¸å€¼æ£€æµ‹ç»“æœ:")
        logger.info(f"  è´¸æ˜“é¢å¼‚å¸¸å€¼: {trade_outliers} æ¡è®°å½• ({trade_outliers/len(complete_df)*100:.2f}%)")
        logger.info(f"  è·ç¦»å¼‚å¸¸å€¼: {distance_outliers} æ¡è®°å½• ({distance_outliers/len(complete_df)*100:.2f}%)")
        logger.info("  æ³¨æ„ï¼šå¼‚å¸¸å€¼å·²æ ‡è®°ä½†ä¿ç•™åœ¨æ•°æ®ä¸­ï¼Œå¯ä½¿ç”¨æ¸©èåŒ–å¤„ç†åçš„å€¼")
    
    # æŒ‰å¹´ä»½ã€ä¼™ä¼´å›½ã€äº§å“æ’åº
    complete_df = complete_df.sort_values(['year', 'us_partner', 'energy_product', 'us_role'])
    complete_df = complete_df.reset_index(drop=True)
    
    # æœ€ç»ˆæ•°æ®æ‘˜è¦
    logger.info(f"âœ… DLIæ•°æ®é›†å‡†å¤‡å®Œæˆ!")
    logger.info(f"ğŸ“Š æœ€ç»ˆæ•°æ®é›†è§„æ¨¡:")
    logger.info(f"  æ€»è®°å½•æ•°: {len(complete_df):,}")
    logger.info(f"  æ—¶é—´è·¨åº¦: {complete_df['year'].min()}-{complete_df['year'].max()}")
    logger.info(f"  è´¸æ˜“ä¼™ä¼´: {complete_df['us_partner'].nunique()} ä¸ªå›½å®¶")
    logger.info(f"  èƒ½æºäº§å“: {complete_df['energy_product'].nunique()} ç§")
    logger.info(f"  æ•°æ®åˆ—æ•°: {len(complete_df.columns)}")
    
    return complete_df

def load_global_trade_data_by_year(year: int, data_dir: str = None) -> pd.DataFrame:
    """
    åŠ è½½æŒ‡å®šå¹´ä»½çš„å…¨å±€èƒ½æºè´¸æ˜“æ•°æ®
    
    è¿™ä¸ªå‡½æ•°ä¸“ä¸ºåŒå‘DLIåˆ†æè®¾è®¡ï¼Œæ”¯æŒè®¡ç®—å‡ºå£é”å®šåŠ›æ—¶éœ€è¦çš„å…¨çƒè´¸æ˜“æ ¼å±€æ•°æ®
    
    Args:
        year: éœ€è¦åŠ è½½çš„å¹´ä»½
        data_dir: æ•°æ®ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨é¡¹ç›®æ ‡å‡†è·¯å¾„
        
    Returns:
        åŒ…å«è¯¥å¹´ä»½æ‰€æœ‰èƒ½æºè´¸æ˜“è®°å½•çš„DataFrame
        
    æ•°æ®ç»“æ„ï¼š
        - year: å¹´ä»½
        - reporter: æŠ¥å‘Šå›½ä»£ç   
        - partner: ä¼™ä¼´å›½ä»£ç 
        - flow: è´¸æ˜“æµå‘ (M=Import, X=Export)
        - product_code: èƒ½æºäº§å“ä»£ç 
        - product_name: äº§å“åç§°
        - trade_value_usd: è´¸æ˜“å€¼ï¼ˆç¾å…ƒï¼‰
        - energy_product: æ ‡å‡†åŒ–çš„èƒ½æºäº§å“åç§°
    """
    
    logger.info(f"ğŸŒ åŠ è½½{year}å¹´å…¨çƒèƒ½æºè´¸æ˜“æ•°æ®...")
    
    # è®¾ç½®æ•°æ®è·¯å¾„
    if data_dir is None:
        base_dir = Path(__file__).parent.parent.parent  # åˆ°è¾¾energy_networkç›®å½•
        data_dir = base_dir / "data" / "processed_data"
    else:
        data_dir = Path(data_dir)
    
    file_path = data_dir / f"cleaned_energy_trade_{year}.csv"
    
    if not file_path.exists():
        raise FileNotFoundError(f"âŒ {year}å¹´å…¨çƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    try:
        # è¯»å–å¹´åº¦æ•°æ®
        df = pd.read_csv(file_path)
        logger.info(f"ğŸ“‚ {year}: æˆåŠŸåŠ è½½ {len(df):,} æ¡å…¨çƒè´¸æ˜“è®°å½•")
        
        # é‡å‘½åè´¸æ˜“å€¼åˆ—ä»¥ä¿æŒä¸€è‡´æ€§
        if 'trade_value_raw_usd' in df.columns:
            df = df.rename(columns={'trade_value_raw_usd': 'trade_value_usd'})
        
        # æ ‡å‡†åŒ–èƒ½æºäº§å“åç§°
        df['product_code'] = df['product_code'].astype(str)
        df['energy_product'] = df['product_code'].map(ENERGY_PRODUCTS)
        
        # ç­›é€‰æœ‰æ•ˆçš„èƒ½æºäº§å“
        df = df[df['energy_product'].notna()]
        
        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        df['trade_value_usd'] = df['trade_value_usd'].astype(float)
        
        # ç§»é™¤æ— æ•ˆè´¸æ˜“å€¼
        df = df[df['trade_value_usd'] > 0]
        
        logger.info(f"âœ… {year}: æ¸…æ´—åä¿ç•™ {len(df):,} æ¡æœ‰æ•ˆèƒ½æºè´¸æ˜“è®°å½•")
        
        return df
        
    except Exception as e:
        logger.error(f"âŒ å¤„ç†{year}å¹´å…¨çƒæ•°æ®æ—¶å‡ºé”™: {e}")
        raise


def get_global_trade_cache() -> Dict[int, pd.DataFrame]:
    """
    è·å–å…¨å±€è´¸æ˜“æ•°æ®ç¼“å­˜
    
    ä¸ºäº†é¿å…é‡å¤åŠ è½½å¤§é‡æ•°æ®ï¼Œæä¾›ä¸€ä¸ªç®€å•çš„ç¼“å­˜æœºåˆ¶
    
    Returns:
        å¹´ä»½åˆ°DataFrameçš„å­—å…¸ç¼“å­˜
    """
    if not hasattr(get_global_trade_cache, '_cache'):
        get_global_trade_cache._cache = {}
    return get_global_trade_cache._cache


def load_global_trade_data_range(start_year: int = 2001, end_year: int = 2024, 
                               data_dir: str = None) -> Dict[int, pd.DataFrame]:
    """
    æ‰¹é‡åŠ è½½æŒ‡å®šå¹´ä»½èŒƒå›´çš„å…¨å±€è´¸æ˜“æ•°æ®
    
    Args:
        start_year: èµ·å§‹å¹´ä»½
        end_year: ç»“æŸå¹´ä»½  
        data_dir: æ•°æ®ç›®å½•è·¯å¾„
        
    Returns:
        å¹´ä»½åˆ°DataFrameçš„å­—å…¸
    """
    
    logger.info(f"ğŸŒ æ‰¹é‡åŠ è½½{start_year}-{end_year}å¹´å…¨çƒèƒ½æºè´¸æ˜“æ•°æ®...")
    
    cache = get_global_trade_cache()
    global_data = {}
    
    for year in range(start_year, end_year + 1):
        if year in cache:
            logger.info(f"ğŸ“‹ {year}: ä½¿ç”¨ç¼“å­˜æ•°æ®")
            global_data[year] = cache[year]
        else:
            try:
                df = load_global_trade_data_by_year(year, data_dir)
                global_data[year] = df
                cache[year] = df
            except FileNotFoundError:
                logger.warning(f"âš ï¸  {year}: æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                continue
            except Exception as e:
                logger.error(f"âŒ {year}: åŠ è½½å¤±è´¥ - {e}")
                continue
    
    total_records = sum(len(df) for df in global_data.values())
    logger.info(f"âœ… æˆåŠŸåŠ è½½{len(global_data)}å¹´æ•°æ®ï¼Œæ€»è®¡ {total_records:,} æ¡è®°å½•")
    
    return global_data


def export_prepared_data(df: pd.DataFrame, output_path: str = None) -> str:
    """
    å¯¼å‡ºå‡†å¤‡å¥½çš„æ•°æ®é›†åˆ°CSVæ–‡ä»¶
    
    Args:
        df: å‡†å¤‡å¥½çš„æ•°æ®é›†
        output_path: è¾“å‡ºè·¯å¾„ï¼Œé»˜è®¤ä¿å­˜åˆ°outputsç›®å½•
        
    Returns:
        å®é™…çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    
    if output_path is None:
        base_dir = Path(__file__).parent.parent.parent  # åˆ°è¾¾energy_networkç›®å½•
        output_dir = Path(__file__).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = output_dir / "us_trade_prepared_for_dli.csv"
    
    df.to_csv(output_path, index=False)
    logger.info(f"ğŸ’¾ æ•°æ®å·²å¯¼å‡ºè‡³: {output_path}")
    
    return str(output_path)

if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®å‡†å¤‡åŠŸèƒ½
    try:
        prepared_data = prepare_dli_dataset()
        output_file = export_prepared_data(prepared_data)
        print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼Œæ–‡ä»¶ä¿å­˜åœ¨: {output_file}")
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
        raise