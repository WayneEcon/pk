"""
å‡ºå£DLIè®¡ç®—å™¨ (Export DLI Calculator)
====================================

æœ¬æ¨¡å—ä¸“é—¨è´Ÿè´£è®¡ç®—ç¾å›½å¯¹å…¶ä»–å›½å®¶çš„å‡ºå£é”å®šDLIæŒ‡æ•°ã€‚
ä»åŒå‘DLIåˆ†æä¸­å‰¥ç¦»å‡ºæ¥ï¼Œæä¾›ç‹¬ç«‹çš„å‡ºå£é”å®šåˆ†æåŠŸèƒ½ã€‚

ç†è®ºæ¡†æ¶ï¼š
- å‡ºå£é”å®šDLIè¡¡é‡ç¾å›½é€šè¿‡èƒ½æºå‡ºå£å¯¹å…¶ä»–å›½å®¶äº§ç”Ÿçš„"é”å®š"æ•ˆåº”
- å½“ç¾å›½å‘æŸå›½å‡ºå£èƒ½æºæ—¶ï¼Œè¯„ä¼°è¯¥å›½å¯¹ç¾å›½çš„"è¢«é”å®š"ç¨‹åº¦
- æ ¸å¿ƒé€»è¾‘ï¼šç›®æ ‡å›½è¿›å£é›†ä¸­åº¦ Ã— ç¾å›½åœ¨ç›®æ ‡å›½å¸‚åœºä»½é¢

åŠŸèƒ½ï¼š
1. è®¡ç®—å‡ºå£é”å®šåŠ›æŒ‡æ ‡ (Export Locking Power)
2. è®¡ç®—å‡ºå£æ–¹å‘çš„æŒç»­æ€§ã€åŸºç¡€è®¾æ–½ã€ç¨³å®šæ€§æŒ‡æ ‡
3. åˆæˆå‡ºå£DLIç»¼åˆæŒ‡æ ‡
4. ç”Ÿæˆç‹¬ç«‹çš„å‡ºå£DLIæ•°æ®æ–‡ä»¶

Author: Energy Network Analysis Team
Date: 2025-08-22
Version: 1.0
"""

import pandas as pd
import numpy as np
from pathlib import Path
import logging
from typing import Dict, List, Tuple, Optional
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# å¯¼å…¥å¿…è¦çš„åŸºç¡€è®¡ç®—å‡½æ•°
from dli_calculator import calculate_continuity, calculate_infrastructure, calculate_stability

logger = logging.getLogger(__name__)

class ExportDLICalculator:
    """ç¾å›½å‡ºå£é”å®šDLIè®¡ç®—å™¨"""
    
    def __init__(self, output_dir: Optional[Path] = None):
        """
        åˆå§‹åŒ–å‡ºå£DLIè®¡ç®—å™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•
        """
        self.output_dir = output_dir or Path(__file__).parent
        self.output_dir.mkdir(exist_ok=True)
        
    def calculate_export_locking_power(self, df: pd.DataFrame, global_trade_data: Dict[int, pd.DataFrame]) -> pd.DataFrame:
        """
        è®¡ç®—å‡ºå£é”å®šåŠ›æŒ‡æ ‡ (Export Locking Power) - æ ¸å¿ƒç®—æ³•
        
        ç†è®ºæ¡†æ¶ï¼šå½“ç¾å›½å‘æŸå›½å‡ºå£èƒ½æºæ—¶ï¼Œè¯„ä¼°è¯¥å›½å¯¹ç¾å›½çš„"è¢«é”å®š"ç¨‹åº¦
        
        è®¡ç®—é€»è¾‘ï¼š
        1. å¯¹äºç¾å›½å‘å›½å®¶Xå‡ºå£äº§å“Pçš„æ¯ä¸€æ¡è®°å½•
        2. æŸ¥è¯¢å…¨çƒæ•°æ®ï¼Œæ‰¾åˆ°å›½å®¶Xåœ¨è¯¥å¹´ä»½è¿›å£äº§å“Pçš„æ‰€æœ‰ä¾›åº”å•†
        3. è®¡ç®—å›½å®¶Xåœ¨äº§å“Pä¸Šçš„è¿›å£é›†ä¸­åº¦ï¼ˆä¾›åº”å•†HHIï¼‰
        4. è®¡ç®—ç¾å›½åœ¨å›½å®¶Xçš„äº§å“Pè¿›å£ä¸­çš„ä»½é¢
        5. å‡ºå£é”å®šåŠ› = å›½å®¶Xçš„è¿›å£HHI Ã— ç¾å›½åœ¨Xå›½å¸‚åœºçš„ä»½é¢
        
        Args:
            df: åŒ…å«ç¾å›½è´¸æ˜“æ•°æ®çš„DataFrame
            global_trade_data: å…¨çƒè´¸æ˜“æ•°æ®å­—å…¸ï¼Œæ ¼å¼{year: DataFrame}
            
        Returns:
            æ·»åŠ äº†market_locking_poweråˆ—çš„DataFrameï¼ˆåªè®¡ç®—å‡ºå£éƒ¨åˆ†ï¼‰
        """
        
        logger.info("ğŸ“¤ å¼€å§‹è®¡ç®—å‡ºå£é”å®šåŠ›æŒ‡æ ‡ï¼ˆç‹¬ç«‹æ¨¡å—ï¼‰...")
        
        df_locking = df.copy()
        
        # åªå¤„ç†ç¾å›½ä½œä¸ºå‡ºå£æ–¹çš„æ•°æ®
        export_data = df_locking[df_locking['us_role'] == 'exporter'].copy()
        
        if len(export_data) == 0:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°ç¾å›½å‡ºå£æ•°æ®ï¼Œè¿”å›åŸæ•°æ®")
            return df_locking
        
        if not global_trade_data:
            logger.warning("æœªæä¾›å…¨çƒè´¸æ˜“æ•°æ®ï¼Œå‡ºå£é”å®šåŠ›å°†è®¾ä¸º0")
            df_locking.loc[df_locking['us_role'] == 'exporter', 'market_locking_power'] = 0
            return df_locking
        
        locking_results = []
        
        # ä¸ºæ¯ä¸ªç¾å›½å‡ºå£è®°å½•è®¡ç®—å¯¹åº”çš„å‡ºå£é”å®šåŠ›
        for idx, row in export_data.iterrows():
            year = row['year']
            partner_country = row['us_partner']  # ç¾å›½çš„å‡ºå£ç›®æ ‡å›½
            product = row['energy_product']
            us_export_value = row['trade_value_usd']
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¯¥å¹´ä»½çš„å…¨çƒæ•°æ®
            if year not in global_trade_data:
                logger.debug(f"ç¼ºå°‘{year}å¹´å…¨çƒæ•°æ®ï¼Œè·³è¿‡")
                continue
            
            global_year_data = global_trade_data[year]
            
            # æŸ¥æ‰¾ç›®æ ‡å›½åœ¨è¯¥å¹´ä»½ã€è¯¥äº§å“ä¸Šçš„æ‰€æœ‰è¿›å£è®°å½•
            # æ³¨æ„ï¼šåœ¨å…¨çƒæ•°æ®ä¸­ï¼Œç›®æ ‡å›½ä½œä¸ºreporterï¼Œæµå‘ä¸ºM(Import)
            partner_imports = global_year_data[
                (global_year_data['reporter'] == partner_country) & 
                (global_year_data['flow'] == 'M') & 
                (global_year_data['energy_product'] == product)
            ].copy()
            
            if len(partner_imports) == 0:
                # ç›®æ ‡å›½åœ¨è¯¥äº§å“ä¸Šæ²¡æœ‰è¿›å£è®°å½•ï¼Œé”å®šåŠ›ä¸º0
                locking_results.append({
                    'year': year,
                    'us_partner': partner_country,
                    'energy_product': product,
                    'us_role': 'exporter',
                    'market_locking_power': 0,
                    'target_import_hhi': 0,
                    'us_share_in_target': 0,
                    'target_total_suppliers': 0,
                    'target_total_imports': 0
                })
                continue
            
            # è®¡ç®—ç›®æ ‡å›½çš„æ€»è¿›å£é¢
            total_imports = partner_imports['trade_value_usd'].sum()
            
            if total_imports <= 0:
                locking_results.append({
                    'year': year,
                    'us_partner': partner_country,
                    'energy_product': product,
                    'us_role': 'exporter',
                    'market_locking_power': 0,
                    'target_import_hhi': 0,
                    'us_share_in_target': 0,
                    'target_total_suppliers': 0,
                    'target_total_imports': 0
                })
                continue
            
            # è®¡ç®—ç›®æ ‡å›½å„ä¾›åº”å•†çš„å¸‚åœºä»½é¢
            supplier_shares = partner_imports.groupby('partner')['trade_value_usd'].sum() / total_imports
            
            # è®¡ç®—ç›®æ ‡å›½çš„è¿›å£é›†ä¸­åº¦ï¼ˆä¾›åº”å•†HHIï¼‰
            import_hhi = (supplier_shares ** 2).sum()
            
            # è®¡ç®—ç¾å›½åœ¨ç›®æ ‡å›½å¸‚åœºä¸­çš„ä»½é¢
            us_share = supplier_shares.get('USA', 0)  # å¦‚æœç¾å›½ä¸åœ¨ä¾›åº”å•†åˆ—è¡¨ä¸­ï¼Œä»½é¢ä¸º0
            
            # è®¡ç®—å‡ºå£é”å®šåŠ›ï¼šç›®æ ‡å›½è¿›å£HHI Ã— ç¾å›½åœ¨ç›®æ ‡å›½å¸‚åœºçš„ä»½é¢
            export_locking_power = import_hhi * us_share
            
            locking_results.append({
                'year': year,
                'us_partner': partner_country,
                'energy_product': product,
                'us_role': 'exporter',
                'market_locking_power': export_locking_power,
                'target_import_hhi': import_hhi,
                'us_share_in_target': us_share,
                'target_total_suppliers': len(supplier_shares),
                'target_total_imports': total_imports
            })
        
        # è½¬æ¢ä¸ºDataFrame
        locking_df = pd.DataFrame(locking_results)
        
        # ä¸åŸæ•°æ®åˆå¹¶
        df_with_locking = pd.merge(
            df_locking, 
            locking_df[['year', 'us_partner', 'energy_product', 'us_role', 'market_locking_power']], 
            on=['year', 'us_partner', 'energy_product', 'us_role'], 
            how='left'
        )
        
        # å¡«å……ç¼ºå¤±å€¼ä¸º0
        df_with_locking['market_locking_power'] = df_with_locking['market_locking_power'].fillna(0)
        
        # ç»Ÿè®¡æ‘˜è¦
        if len(locking_df) > 0:
            logger.info(f"ğŸ“Š å‡ºå£é”å®šåŠ›ç»Ÿè®¡:")
            logger.info(f"  å¹³å‡é”å®šåŠ›: {locking_df['market_locking_power'].mean():.4f}")
            logger.info(f"  æœ€é«˜é”å®šåŠ›: {locking_df['market_locking_power'].max():.4f}")
            logger.info(f"  éé›¶é”å®šåŠ›è®°å½•: {(locking_df['market_locking_power'] > 0).sum()} æ¡")
            logger.info(f"  ç¾å›½åœ¨ç›®æ ‡å¸‚åœºå¹³å‡ä»½é¢: {locking_df['us_share_in_target'].mean():.4f}")
            logger.info(f"  ç›®æ ‡å›½å¹³å‡ä¾›åº”å•†æ•°: {locking_df['target_total_suppliers'].mean():.1f}")
            
            # æŒ‰äº§å“åˆ†æ
            product_stats = locking_df.groupby('energy_product').agg({
                'market_locking_power': ['mean', 'max'],
                'target_import_hhi': 'mean',
                'us_share_in_target': 'mean'
            }).round(4)
            
            logger.info(f"  æŒ‰èƒ½æºäº§å“çš„å‡ºå£é”å®šåŠ›:")
            for product in product_stats.index:
                stats = product_stats.loc[product]
                logger.info(f"    {product}: å¹³å‡é”å®šåŠ›={stats[('market_locking_power', 'mean')]:.4f}, " +
                           f"æœ€é«˜é”å®šåŠ›={stats[('market_locking_power', 'max')]:.4f}, " +
                           f"ç›®æ ‡å›½HHI={stats[('target_import_hhi', 'mean')]:.4f}")
        
        logger.info("âœ… å‡ºå£é”å®šåŠ›æŒ‡æ ‡è®¡ç®—å®Œæˆ!")
        return df_with_locking
    
    def calculate_export_dli_composite(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—å‡ºå£DLIç»¼åˆæŒ‡æ ‡
        
        ä½¿ç”¨PCAæ–¹æ³•å¯¹å‡ºå£æ–¹å‘çš„å››ä¸ªç»´åº¦è¿›è¡Œé™ç»´åˆæˆï¼š
        - continuity: è´¸æ˜“æŒç»­æ€§
        - infrastructure: åŸºç¡€è®¾æ–½å¼ºåº¦  
        - stability: è´¸æ˜“ç¨³å®šæ€§
        - market_locking_power: å‡ºå£é”å®šåŠ›
        
        Args:
            df: åŒ…å«æ‰€æœ‰ç»´åº¦æŒ‡æ ‡çš„DataFrame
            
        Returns:
            æ·»åŠ äº†export_dli_scoreåˆ—çš„DataFrame
        """
        
        logger.info("ğŸ§® å¼€å§‹è®¡ç®—å‡ºå£DLIç»¼åˆæŒ‡æ ‡...")
        
        # åªå¤„ç†å‡ºå£æ•°æ®
        export_data = df[df['us_role'] == 'exporter'].copy()
        
        if len(export_data) == 0:
            logger.warning("æ²¡æœ‰å‡ºå£æ•°æ®ï¼Œè·³è¿‡å‡ºå£DLIè®¡ç®—")
            return df
        
        # å®šä¹‰æ‰€éœ€çš„ç»´åº¦
        required_dimensions = ['continuity', 'infrastructure', 'stability', 'market_locking_power']
        
        # æ£€æŸ¥å¿…éœ€ç»´åº¦æ˜¯å¦å­˜åœ¨
        missing_dimensions = [dim for dim in required_dimensions if dim not in export_data.columns]
        if missing_dimensions:
            raise ValueError(f"ç¼ºå°‘å‡ºå£DLIç»´åº¦: {missing_dimensions}")
        
        # å»é™¤æœ‰ç¼ºå¤±å€¼çš„è®°å½•
        complete_data = export_data.dropna(subset=required_dimensions)
        
        if len(complete_data) == 0:
            logger.warning("æ²¡æœ‰å®Œæ•´çš„å‡ºå£DLIæ•°æ®ï¼Œè·³è¿‡è®¡ç®—")
            return df
        
        logger.info(f"ğŸ“Š å‡ºå£DLIç»´åº¦æ•°æ®è´¨é‡æ£€æŸ¥:")
        for dim in required_dimensions:
            logger.info(f"  {dim}: å‡å€¼={complete_data[dim].mean():.4f}, æ ‡å‡†å·®={complete_data[dim].std():.4f}, " + 
                       f"èŒƒå›´=[{complete_data[dim].min():.4f}, {complete_data[dim].max():.4f}]")
        
        # æ ‡å‡†åŒ–å¤„ç†
        scaler = StandardScaler()
        standardized_dimensions = scaler.fit_transform(complete_data[required_dimensions])
        
        # æ‰§è¡ŒPCA
        pca = PCA(n_components=1)
        dli_scores = pca.fit_transform(standardized_dimensions)
        
        # è®¡ç®—æƒé‡ä¿¡æ¯
        weights = pca.components_[0]
        explained_variance = pca.explained_variance_ratio_[0]
        
        logger.info(f"ğŸ“ˆ å‡ºå£DLI PCAåˆ†æç»“æœ:")
        logger.info(f"  è§£é‡Šæ–¹å·®æ¯”ä¾‹: {explained_variance:.3f}")
        logger.info(f"  ç»´åº¦æƒé‡:")
        for i, dim in enumerate(required_dimensions):
            logger.info(f"    {dim}: {weights[i]:.4f}")
        
        # å°†DLIåˆ†æ•°æ·»åŠ åˆ°æ•°æ®ä¸­
        complete_data['export_dli_score'] = dli_scores.flatten()
        
        # å°†ç»“æœåˆå¹¶å›åŸå§‹æ•°æ®
        df_result = df.copy()
        df_result = df_result.merge(
            complete_data[['year', 'us_partner', 'energy_product', 'us_role', 'export_dli_score']],
            on=['year', 'us_partner', 'energy_product', 'us_role'],
            how='left'
        )
        
        # ä¿å­˜æƒé‡ä¿¡æ¯
        self._save_export_weights(weights, explained_variance, required_dimensions)
        
        logger.info("âœ… å‡ºå£DLIç»¼åˆæŒ‡æ ‡è®¡ç®—å®Œæˆ!")
        return df_result
    
    def _save_export_weights(self, weights: np.ndarray, explained_variance: float, dimensions: List[str]):
        """ä¿å­˜å‡ºå£DLIçš„PCAæƒé‡ä¿¡æ¯"""
        import json
        
        weights_info = {
            'version': '1.0',
            'description': 'ç¾å›½å‡ºå£é”å®šDLIæƒé‡ç³»ç»Ÿ',
            'export_pca_weights': {dim: float(weight) for dim, weight in zip(dimensions, weights)},
            'explained_variance_ratio': float(explained_variance),
            'dimensions': dimensions,
            'generation_timestamp': pd.Timestamp.now().isoformat()
        }
        
        weights_path = self.output_dir / "export_dli_weights.json"
        with open(weights_path, 'w', encoding='utf-8') as f:
            json.dump(weights_info, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“„ å‡ºå£DLIæƒé‡ä¿¡æ¯å·²ä¿å­˜è‡³: {weights_path}")
    
    def _add_us_role_field(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ä¸ºåŸå§‹è´¸æ˜“æ•°æ®æ·»åŠ us_roleå­—æ®µ
        
        æ ¹æ®reporterå’Œpartnerå­—æ®µè¯†åˆ«ç¾å›½çš„è´¸æ˜“è§’è‰²ï¼š
        - å½“reporterä¸ºUSAä¸”flowä¸ºXæ—¶ï¼Œus_roleä¸ºexporter  
        - å½“reporterä¸ºUSAä¸”flowä¸ºMæ—¶ï¼Œus_roleä¸ºimporter
        - å½“partnerä¸ºUSAä¸”flowä¸ºXæ—¶ï¼Œus_roleä¸ºimporter
        - å½“partnerä¸ºUSAä¸”flowä¸ºMæ—¶ï¼Œus_roleä¸ºexporter
        
        Args:
            df: åŸå§‹è´¸æ˜“æ•°æ®DataFrame
            
        Returns:
            æ·»åŠ äº†us_roleå’Œus_partnerå­—æ®µçš„DataFrame
        """
        
        logger.info("ğŸ”„ ä¸ºè´¸æ˜“æ•°æ®æ·»åŠ USè§’è‰²æ ‡è¯†...")
        
        df_with_role = df.copy()
        
        # ç­›é€‰æ¶‰åŠç¾å›½çš„è´¸æ˜“è®°å½•
        us_trade = df_with_role[
            (df_with_role['reporter'] == 'USA') | 
            (df_with_role['partner'] == 'USA')
        ].copy()
        
        if len(us_trade) == 0:
            logger.warning("æœªæ‰¾åˆ°æ¶‰åŠç¾å›½çš„è´¸æ˜“è®°å½•")
            return df_with_role
        
        # æ·»åŠ us_roleå­—æ®µ
        conditions = [
            (us_trade['reporter'] == 'USA') & (us_trade['flow'] == 'X'),  # ç¾å›½å‡ºå£
            (us_trade['reporter'] == 'USA') & (us_trade['flow'] == 'M'),  # ç¾å›½è¿›å£ï¼ˆä½œä¸ºreporterï¼‰
            (us_trade['partner'] == 'USA') & (us_trade['flow'] == 'X'),   # å…¶ä»–å›½å®¶å¯¹ç¾å‡ºå£ï¼ˆç¾å›½è¿›å£ï¼‰
            (us_trade['partner'] == 'USA') & (us_trade['flow'] == 'M')    # å…¶ä»–å›½å®¶ä»ç¾è¿›å£ï¼ˆç¾å›½å‡ºå£ï¼‰
        ]
        
        choices = [
            'exporter',   # ç¾å›½å‡ºå£
            'importer',   # ç¾å›½è¿›å£
            'importer',   # ç¾å›½è¿›å£  
            'exporter'    # ç¾å›½å‡ºå£
        ]
        
        us_trade['us_role'] = np.select(conditions, choices, default='unknown')
        
        # æ·»åŠ us_partnerå­—æ®µï¼ˆç¾å›½çš„è´¸æ˜“ä¼™ä¼´ï¼‰
        us_trade['us_partner'] = np.where(
            us_trade['reporter'] == 'USA',
            us_trade['partner'],
            us_trade['reporter']
        )
        
        # åªè¿”å›æ¶‰åŠç¾å›½çš„è´¸æ˜“æ•°æ®
        valid_us_trade = us_trade[us_trade['us_role'] != 'unknown'].copy()
        
        # æ·»åŠ è·ç¦»ä¿¡æ¯
        valid_us_trade = self._add_distance_info(valid_us_trade)
        
        logger.info(f"âœ… ç¾å›½è´¸æ˜“æ•°æ®å¤„ç†å®Œæˆ:")
        logger.info(f"   æ€»è®°å½•æ•°: {len(valid_us_trade):,}")
        logger.info(f"   å‡ºå£è®°å½•: {(valid_us_trade['us_role'] == 'exporter').sum():,}")
        logger.info(f"   è¿›å£è®°å½•: {(valid_us_trade['us_role'] == 'importer').sum():,}")
        logger.info(f"   è´¸æ˜“ä¼™ä¼´æ•°: {valid_us_trade['us_partner'].nunique()}")
        
        return valid_us_trade
    
    def _add_distance_info(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ä¸ºè´¸æ˜“æ•°æ®æ·»åŠ è·ç¦»ä¿¡æ¯
        
        Args:
            df: åŒ…å«us_partnerå­—æ®µçš„è´¸æ˜“æ•°æ®
            
        Returns:
            æ·»åŠ äº†distance_kmå­—æ®µçš„DataFrame
        """
        
        logger.info("ğŸŒ æ·»åŠ åœ°ç†è·ç¦»ä¿¡æ¯...")
        
        try:
            # ä»data_preparationæ¨¡å—åŠ è½½è·ç¦»æ•°æ®
            from data_preparation import load_complete_distance_data
            distance_data = load_complete_distance_data()
            
            # åˆ›å»ºç¾å›½åˆ°å„å›½çš„è·ç¦»æ˜ å°„
            us_distances = {}
            for country_pair, distance in distance_data.items():
                if country_pair[0] == 'USA':
                    us_distances[country_pair[1]] = distance
                elif country_pair[1] == 'USA':
                    us_distances[country_pair[0]] = distance
            
            # ä¸ºæ•°æ®æ·»åŠ è·ç¦»ä¿¡æ¯
            df['distance_km'] = df['us_partner'].map(us_distances)
            
            # å¤„ç†ç¼ºå¤±çš„è·ç¦»æ•°æ®
            missing_distance = df['distance_km'].isnull().sum()
            if missing_distance > 0:
                logger.warning(f"âš ï¸ {missing_distance} æ¡è®°å½•ç¼ºå°‘è·ç¦»æ•°æ®ï¼Œå°†ä½¿ç”¨å¹³å‡è·ç¦»å¡«å……")
                avg_distance = df['distance_km'].mean()
                df['distance_km'] = df['distance_km'].fillna(avg_distance)
            
            logger.info(f"âœ… è·ç¦»ä¿¡æ¯æ·»åŠ å®Œæˆ:")
            logger.info(f"   å¹³å‡è·ç¦»: {df['distance_km'].mean():.0f} km")
            logger.info(f"   è·ç¦»èŒƒå›´: {df['distance_km'].min():.0f} - {df['distance_km'].max():.0f} km")
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•åŠ è½½è·ç¦»æ•°æ®: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤è·ç¦»")
            # ä½¿ç”¨é»˜è®¤è·ç¦»ï¼ˆå…¨çƒå¹³å‡è·ç¦»çº¦10000kmï¼‰
            df['distance_km'] = 10000.0
        
        return df
    
    def generate_export_dli_data(self, trade_data: Optional[pd.DataFrame] = None, 
                                global_trade_data: Optional[Dict[int, pd.DataFrame]] = None,
                                output_filename: str = "export_dli.csv") -> pd.DataFrame:
        """
        ç”Ÿæˆå®Œæ•´çš„å‡ºå£DLIæ•°æ®é›†
        
        Args:
            trade_data: ç¾å›½è´¸æ˜“æ•°æ®
            global_trade_data: å…¨çƒè´¸æ˜“æ•°æ®ï¼ˆè®¡ç®—å‡ºå£é”å®šåŠ›éœ€è¦ï¼‰
            output_filename: è¾“å‡ºæ–‡ä»¶å
            
        Returns:
            å®Œæ•´çš„å‡ºå£DLIæ•°æ®é›†
        """
        
        logger.info("ğŸš€ å¼€å§‹ç”Ÿæˆå‡ºå£DLIæ•°æ®é›†...")
        
        if trade_data is None:
            # ä»æ•°æ®å‡†å¤‡æ¨¡å—åŠ è½½æ•°æ®
            from data_preparation import load_global_trade_data_range
            trade_data_dict = load_global_trade_data_range()
            
            # åˆå¹¶æ‰€æœ‰å¹´ä»½çš„æ•°æ®
            logger.info("ğŸ”„ åˆå¹¶æ‰€æœ‰å¹´ä»½çš„è´¸æ˜“æ•°æ®...")
            trade_data_list = []
            for year, yearly_data in trade_data_dict.items():
                trade_data_list.append(yearly_data)
            trade_data = pd.concat(trade_data_list, ignore_index=True)
            logger.info(f"âœ… åˆå¹¶å®Œæˆï¼Œæ€»è®¡ {len(trade_data):,} æ¡è®°å½•")
            
            # ä¸ºåŸå§‹æ•°æ®æ·»åŠ us_roleå­—æ®µ
            trade_data = self._add_us_role_field(trade_data)
            
            # åŒæ—¶ä¿å­˜global_trade_dataä¾›å‡ºå£é”å®šåŠ›è®¡ç®—ä½¿ç”¨
            if global_trade_data is None:
                global_trade_data = trade_data_dict
        
        # åªä¿ç•™ç¾å›½å‡ºå£æ•°æ®
        export_data = trade_data[trade_data['us_role'] == 'exporter'].copy()
        
        if len(export_data) == 0:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°ç¾å›½å‡ºå£æ•°æ®")
        
        logger.info(f"ğŸ“Š å‡ºå£æ•°æ®åŸºç¡€ä¿¡æ¯:")
        logger.info(f"  è®°å½•æ•°: {len(export_data):,}")
        logger.info(f"  å¹´ä»½èŒƒå›´: {export_data['year'].min()}-{export_data['year'].max()}")
        logger.info(f"  å‡ºå£ç›®æ ‡å›½æ•°: {export_data['us_partner'].nunique()}")
        logger.info(f"  èƒ½æºäº§å“ç±»å‹: {export_data['energy_product'].nunique()}")
        
        # ç¬¬1æ­¥ï¼šè®¡ç®—æŒç»­æ€§æŒ‡æ ‡
        logger.info("1ï¸âƒ£ è®¡ç®—å‡ºå£è´¸æ˜“æŒç»­æ€§...")
        export_data = calculate_continuity(export_data)
        
        # ç¬¬2æ­¥ï¼šè®¡ç®—åŸºç¡€è®¾æ–½å¼ºåº¦
        logger.info("2ï¸âƒ£ è®¡ç®—å‡ºå£åŸºç¡€è®¾æ–½å¼ºåº¦...")
        export_data = calculate_infrastructure(export_data)
        
        # ç¬¬3æ­¥ï¼šè®¡ç®—ç¨³å®šæ€§æŒ‡æ ‡
        logger.info("3ï¸âƒ£ è®¡ç®—å‡ºå£è´¸æ˜“ç¨³å®šæ€§...")
        export_data = calculate_stability(export_data)
        
        # ç¬¬4æ­¥ï¼šè®¡ç®—å‡ºå£é”å®šåŠ›
        logger.info("4ï¸âƒ£ è®¡ç®—å‡ºå£é”å®šåŠ›...")
        if global_trade_data:
            export_data = self.calculate_export_locking_power(export_data, global_trade_data)
        else:
            logger.warning("æœªæä¾›å…¨çƒæ•°æ®ï¼Œå‡ºå£é”å®šåŠ›è®¾ä¸º0")
            export_data['market_locking_power'] = 0
        
        # ç¬¬5æ­¥ï¼šè®¡ç®—å‡ºå£DLIç»¼åˆæŒ‡æ ‡
        logger.info("5ï¸âƒ£ è®¡ç®—å‡ºå£DLIç»¼åˆæŒ‡æ ‡...")
        export_data = self.calculate_export_dli_composite(export_data)
        
        # ç¬¬6æ­¥ï¼šæ•°æ®æ•´ç†å’Œè¾“å‡º
        logger.info("6ï¸âƒ£ æ•´ç†å’Œä¿å­˜å‡ºå£DLIæ•°æ®...")
        
        # é€‰æ‹©è¾“å‡ºåˆ—
        output_columns = [
            'year', 'us_partner', 'energy_product', 'us_role',
            'trade_value_usd', 'distance_km',
            'continuity', 'infrastructure', 'stability', 'market_locking_power',
            'export_dli_score'
        ]
        
        available_columns = [col for col in output_columns if col in export_data.columns]
        df_output = export_data[available_columns].copy()
        
        # æ’åº
        df_output = df_output.sort_values(['year', 'us_partner', 'energy_product'])
        df_output = df_output.reset_index(drop=True)
        
        # æ•°æ®éªŒè¯
        logger.info("ğŸ” å‡ºå£DLIæ•°æ®éªŒè¯:")
        logger.info(f"  æ€»è®°å½•æ•°: {len(df_output):,}")
        logger.info(f"  å‡ºå£ç›®æ ‡å›½: {df_output['us_partner'].nunique()}")
        logger.info(f"  èƒ½æºäº§å“: {df_output['energy_product'].nunique()}")
        
        # æ£€æŸ¥ç¼ºå¤±å€¼
        missing_summary = df_output.isnull().sum()
        missing_cols = missing_summary[missing_summary > 0]
        if len(missing_cols) > 0:
            logger.warning("å­˜åœ¨ç¼ºå¤±å€¼:")
            for col, count in missing_cols.items():
                logger.warning(f"  {col}: {count} ({count/len(df_output)*100:.1f}%)")
        
        # ä¿å­˜æ•°æ®
        output_path = self.output_dir / output_filename
        df_output.to_csv(output_path, index=False)
        
        logger.info(f"ğŸ’¾ å‡ºå£DLIæ•°æ®å·²ä¿å­˜è‡³: {output_path}")
        logger.info("ğŸ‰ å‡ºå£DLIæ•°æ®ç”Ÿæˆå®Œæˆ!")
        
        return df_output

def main():
    """æµ‹è¯•å‡½æ•°"""
    import sys
    from data_preparation import load_global_trade_data_range
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)
    
    try:
        # åˆ›å»ºè®¡ç®—å™¨
        calculator = ExportDLICalculator()
        
        # ç”Ÿæˆå‡ºå£DLIæ•°æ®
        export_dli_data = calculator.generate_export_dli_data()
        
        print(f"\nâœ… å‡ºå£DLIæ•°æ®ç”ŸæˆæˆåŠŸï¼")
        print(f"ğŸ“Š æ•°æ®ç»´åº¦: {export_dli_data.shape}")
        print(f"ğŸ”— å‡ºå£DLIç»¼åˆæŒ‡æ ‡èŒƒå›´: [{export_dli_data['export_dli_score'].min():.4f}, {export_dli_data['export_dli_score'].max():.4f}]")
        print(f"ğŸŒ å‡ºå£ç›®æ ‡å›½æ•°é‡: {export_dli_data['us_partner'].nunique()}")
        
        # æ˜¾ç¤ºå‰5æ¡è®°å½•
        print(f"\nğŸ“‹ æ•°æ®æ ·ä¾‹:")
        print(export_dli_data.head())
        
    except Exception as e:
        logger.error(f"âŒ å‡ºå£DLIè®¡ç®—å¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    main()