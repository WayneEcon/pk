#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆDLIä½¿ç”¨ç¤ºä¾‹ (Enhanced DLI Usage Examples)
===============================================

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å¢å¼ºç‰ˆäº”ç»´åº¦DLIæ•°æ®è¿›è¡Œæ”¿ç­–åˆ†æå’Œå­¦æœ¯ç ”ç©¶ã€‚

ä¸»è¦åŠŸèƒ½:
1. æ•°æ®åŠ è½½å’ŒåŸºç¡€ç»Ÿè®¡
2. æ—¶é—´åºåˆ—è¶‹åŠ¿åˆ†æ
3. æ–¹å‘æ€§é”å®šæ•ˆåº”å¯¹æ¯”
4. å›½åˆ«å’Œäº§å“åˆ†æ
5. æ”¿ç­–å½±å“è¯„ä¼°ç¤ºä¾‹

ç‰ˆæœ¬: v1.0
ä½œè€…: Energy Network Analysis Team  
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

class EnhancedDLIAnalyzer:
    """å¢å¼ºç‰ˆDLIæ•°æ®åˆ†æå™¨"""
    
    def __init__(self, data_path: Path = None, weights_path: Path = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            data_path: å¢å¼ºç‰ˆDLIæ•°æ®è·¯å¾„
            weights_path: æƒé‡å‚æ•°æ–‡ä»¶è·¯å¾„
        """
        if data_path is None:
            data_path = Path(__file__).parent / "outputs" / "dli_pagerank.csv"
        if weights_path is None:
            weights_path = Path(__file__).parent / "outputs" / "dli_pagerank_weights.json"
            
        self.data_path = data_path
        self.weights_path = weights_path
        
        # åŠ è½½æ•°æ®
        self.data = pd.read_csv(data_path)
        
        # åŠ è½½æƒé‡ä¿¡æ¯
        with open(weights_path, 'r', encoding='utf-8') as f:
            self.weights_info = json.load(f)
        
        print(f"âœ… å¢å¼ºç‰ˆDLIæ•°æ®åŠ è½½å®Œæˆ: {len(self.data):,}æ¡è®°å½•")
        
    def get_basic_statistics(self) -> Dict:
        """è·å–åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
        
        stats = {
            'total_records': len(self.data),
            'years_covered': f"{self.data['year'].min()}-{self.data['year'].max()}",
            'countries_count': self.data['us_partner'].nunique(),
            'products_count': self.data['energy_product'].nunique(),
            'export_records': len(self.data[self.data['us_role'] == 'exporter']),
            'import_records': len(self.data[self.data['us_role'] == 'importer']),
            'enhanced_dli_coverage': (~self.data['dli_enhanced'].isna()).mean(),
            'dli_enhanced_stats': {
                'mean': self.data['dli_enhanced'].mean(),
                'std': self.data['dli_enhanced'].std(),
                'min': self.data['dli_enhanced'].min(),
                'max': self.data['dli_enhanced'].max()
            }
        }
        
        return stats
    
    def analyze_time_trends(self) -> pd.DataFrame:
        """åˆ†ææ—¶é—´è¶‹åŠ¿"""
        
        print("ğŸ“ˆ åˆ†ææ—¶é—´åºåˆ—è¶‹åŠ¿...")
        
        # æŒ‰å¹´ä»½å’Œæ–¹å‘èšåˆæ•°æ®
        yearly_trends = self.data.groupby(['year', 'us_role']).agg({
            'dli_enhanced': ['mean', 'std', 'count'],
            'trade_value_usd': 'sum'
        }).round(6)
        
        yearly_trends.columns = ['dli_mean', 'dli_std', 'record_count', 'total_trade_value']
        yearly_trends = yearly_trends.reset_index()
        
        return yearly_trends
    
    def compare_directional_effects(self) -> Dict:
        """å¯¹æ¯”æ–¹å‘æ€§é”å®šæ•ˆåº”"""
        
        print("âš–ï¸  åˆ†ææ–¹å‘æ€§é”å®šæ•ˆåº”å·®å¼‚...")
        
        export_data = self.data[self.data['us_role'] == 'exporter']
        import_data = self.data[self.data['us_role'] == 'importer']
        
        comparison = {
            'export_locking': {
                'mean_dli': export_data['dli_enhanced'].mean(),
                'std_dli': export_data['dli_enhanced'].std(),
                'records': len(export_data),
                'top_partners': export_data.groupby('us_partner')['dli_enhanced'].mean().nlargest(10).to_dict()
            },
            'import_locking': {
                'mean_dli': import_data['dli_enhanced'].mean(),
                'std_dli': import_data['dli_enhanced'].std(), 
                'records': len(import_data),
                'top_partners': import_data.groupby('us_partner')['dli_enhanced'].mean().nlargest(10).to_dict()
            }
        }
        
        # ç»Ÿè®¡æ£€éªŒ
        from scipy import stats
        t_stat, p_value = stats.ttest_ind(
            export_data['dli_enhanced'].dropna(),
            import_data['dli_enhanced'].dropna()
        )
        
        comparison['statistical_test'] = {
            't_statistic': float(t_stat),
            'p_value': float(p_value),
            'significant': p_value < 0.05
        }
        
        return comparison
    
    def analyze_country_rankings(self, year: int = 2024, top_n: int = 20) -> Dict:
        """åˆ†æå›½å®¶æ’å"""
        
        print(f"ğŸŒ åˆ†æ{year}å¹´å›½å®¶é”å®šæ•ˆåº”æ’å...")
        
        year_data = self.data[self.data['year'] == year].copy()
        
        # åˆ†åˆ«è®¡ç®—å‡ºå£å’Œè¿›å£é”å®šæ’å
        export_ranking = year_data[year_data['us_role'] == 'exporter'].groupby('us_partner').agg({
            'dli_enhanced': 'mean',
            'trade_value_usd': 'sum'
        }).sort_values('dli_enhanced', ascending=False).head(top_n)
        
        import_ranking = year_data[year_data['us_role'] == 'importer'].groupby('us_partner').agg({
            'dli_enhanced': 'mean', 
            'trade_value_usd': 'sum'
        }).sort_values('dli_enhanced', ascending=False).head(top_n)
        
        return {
            'year': year,
            'export_locking_ranking': export_ranking.to_dict('index'),
            'import_locking_ranking': import_ranking.to_dict('index')
        }
    
    def analyze_product_effects(self) -> pd.DataFrame:
        """åˆ†æä¸åŒèƒ½æºäº§å“çš„é”å®šæ•ˆåº”"""
        
        print("âš¡ åˆ†æèƒ½æºäº§å“é”å®šæ•ˆåº”å·®å¼‚...")
        
        product_analysis = self.data.groupby(['energy_product', 'us_role']).agg({
            'dli_enhanced': ['mean', 'std', 'count'],
            'trade_value_usd': ['sum', 'mean'],
            'continuity': 'mean',
            'infrastructure': 'mean',
            'stability': 'mean',
            'market_locking_power': 'mean'
        }).round(4)
        
        product_analysis.columns = [
            'dli_mean', 'dli_std', 'record_count',
            'total_trade', 'avg_trade',
            'avg_continuity', 'avg_infrastructure', 'avg_stability', 'avg_market_power'
        ]
        
        return product_analysis.reset_index()
    
    def evaluate_shale_revolution_impact(self) -> Dict:
        """è¯„ä¼°é¡µå²©é©å‘½çš„å½±å“ï¼ˆ2011å¹´å‰åå¯¹æ¯”ï¼‰"""
        
        print("ğŸ›¢ï¸  è¯„ä¼°é¡µå²©é©å‘½æ”¿ç­–å½±å“...")
        
        pre_shale = self.data[self.data['year'] <= 2010]
        post_shale = self.data[self.data['year'] >= 2015]  # ç•™å‡ºç¼“å†²æœŸ
        
        def calculate_period_stats(data, period_name):
            export_data = data[data['us_role'] == 'exporter']
            import_data = data[data['us_role'] == 'importer']
            
            return {
                'period': period_name,
                'export_locking': {
                    'mean_dli': export_data['dli_enhanced'].mean(),
                    'record_count': len(export_data),
                    'avg_trade_value': export_data['trade_value_usd'].mean()
                },
                'import_locking': {
                    'mean_dli': import_data['dli_enhanced'].mean(),
                    'record_count': len(import_data),
                    'avg_trade_value': import_data['trade_value_usd'].mean()
                }
            }
        
        pre_stats = calculate_period_stats(pre_shale, 'Pre-Shale (2001-2010)')
        post_stats = calculate_period_stats(post_shale, 'Post-Shale (2015-2024)')
        
        # è®¡ç®—å˜åŒ–
        export_dli_change = (
            post_stats['export_locking']['mean_dli'] - 
            pre_stats['export_locking']['mean_dli']
        )
        
        import_dli_change = (
            post_stats['import_locking']['mean_dli'] - 
            pre_stats['import_locking']['mean_dli']
        )
        
        return {
            'pre_shale_revolution': pre_stats,
            'post_shale_revolution': post_stats,
            'changes': {
                'export_locking_change': float(export_dli_change),
                'import_locking_change': float(import_dli_change),
                'interpretation': {
                    'export': 'increased' if export_dli_change > 0 else 'decreased',
                    'import': 'increased' if import_dli_change > 0 else 'decreased'
                }
            }
        }
    
    def create_visualization_dashboard(self, output_dir: Path = None):
        """åˆ›å»ºå¯è§†åŒ–é¢æ¿"""
        
        print("ğŸ¨ åˆ›å»ºå¯è§†åŒ–é¢æ¿...")
        
        if output_dir is None:
            output_dir = Path(__file__).parent / "outputs" / "figures"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        plt.style.use('default')
        
        # 1. æ—¶é—´è¶‹åŠ¿å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # å¹´åº¦è¶‹åŠ¿
        yearly_data = self.data.groupby(['year', 'us_role'])['dli_enhanced'].mean().unstack()
        
        ax1 = axes[0, 0]
        if 'exporter' in yearly_data.columns:
            ax1.plot(yearly_data.index, yearly_data['exporter'], 'b-', label='US Export Locking', linewidth=2)
        if 'importer' in yearly_data.columns:
            ax1.plot(yearly_data.index, yearly_data['importer'], 'r-', label='US Import Being Locked', linewidth=2)
        ax1.set_title('Enhanced DLI Trends Over Time')
        ax1.set_xlabel('Year')
        ax1.set_ylabel('Average Enhanced DLI')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # å›½å®¶åˆ†å¸ƒï¼ˆ2024å¹´ï¼‰
        ax2 = axes[0, 1]
        latest_data = self.data[self.data['year'] == 2024]
        export_top = latest_data[latest_data['us_role'] == 'exporter'].groupby('us_partner')['dli_enhanced'].mean().nlargest(10)
        export_top.plot(kind='barh', ax=ax2, color='skyblue')
        ax2.set_title('Top 10 Countries: US Export Locking (2024)')
        ax2.set_xlabel('Enhanced DLI Score')
        
        # èƒ½æºäº§å“å¯¹æ¯”
        ax3 = axes[1, 0]
        product_data = self.data.groupby(['energy_product', 'us_role'])['dli_enhanced'].mean().unstack()
        product_data.plot(kind='bar', ax=ax3, width=0.8)
        ax3.set_title('Enhanced DLI by Energy Product')
        ax3.set_xlabel('Energy Product')
        ax3.set_ylabel('Average Enhanced DLI')
        ax3.legend(title='US Role')
        ax3.tick_params(axis='x', rotation=45)
        
        # ç»´åº¦æƒé‡å¯¹æ¯”
        ax4 = axes[1, 1]
        export_weights = list(self.weights_info['export_dli_weights']['dimension_weights'].values())
        import_weights = list(self.weights_info['import_dli_weights']['dimension_weights'].values())
        dimensions = ['Continuity', 'Infrastructure', 'Stability', 'Market Power', 'PageRank']
        
        x = np.arange(len(dimensions))
        width = 0.35
        
        ax4.bar(x - width/2, export_weights, width, label='Export Locking', alpha=0.8)
        ax4.bar(x + width/2, import_weights, width, label='Import Locking', alpha=0.8)
        ax4.set_title('PCA Dimension Weights Comparison')
        ax4.set_xlabel('Dimensions')
        ax4.set_ylabel('PCA Weight')
        ax4.set_xticks(x)
        ax4.set_xticklabels(dimensions, rotation=45)
        ax4.legend()
        
        plt.tight_layout()
        
        dashboard_path = output_dir / "enhanced_dli_dashboard.png"
        plt.savefig(dashboard_path, dpi=300, bbox_inches='tight', facecolor='white')
        print(f"ğŸ“Š å¯è§†åŒ–é¢æ¿å·²ä¿å­˜: {dashboard_path}")
        plt.close()
    
    def generate_policy_insights(self) -> Dict:
        """ç”Ÿæˆæ”¿ç­–æ´å¯Ÿ"""
        
        print("ğŸ’¡ ç”Ÿæˆæ”¿ç­–åˆ†ææ´å¯Ÿ...")
        
        # è·å–æœ€æ–°å¹´ä»½æ•°æ®
        latest_year = self.data['year'].max()
        latest_data = self.data[self.data['year'] == latest_year]
        
        # ç¾å›½å‡ºå£é”å®šèƒ½åŠ›æœ€å¼ºçš„å…³ç³»
        top_export_locking = latest_data[latest_data['us_role'] == 'exporter'].nlargest(5, 'dli_enhanced')
        
        # ç¾å›½è¿›å£è¢«é”å®šé£é™©æœ€é«˜çš„å…³ç³»
        top_import_locking = latest_data[latest_data['us_role'] == 'importer'].nlargest(5, 'dli_enhanced')
        
        # è®¡ç®—ç½‘ç»œç»´åº¦çš„è´¡çŒ®
        export_pagerank_contribution = self.weights_info['export_dli_weights']['dimension_weights']['pagerank_dimension']
        import_pagerank_contribution = self.weights_info['import_dli_weights']['dimension_weights']['pagerank_dimension']
        
        insights = {
            'analysis_year': latest_year,
            'strategic_export_advantages': [
                {
                    'partner': row['us_partner'],
                    'product': row['energy_product'],
                    'dli_score': round(row['dli_enhanced'], 3),
                    'trade_value': row['trade_value_usd']
                }
                for _, row in top_export_locking.iterrows()
            ],
            'import_vulnerability_risks': [
                {
                    'partner': row['us_partner'],
                    'product': row['energy_product'],
                    'dli_score': round(row['dli_enhanced'], 3),
                    'trade_value': row['trade_value_usd']
                }
                for _, row in top_import_locking.iterrows()
            ],
            'network_dimension_importance': {
                'export_locking_weight': round(export_pagerank_contribution, 3),
                'import_locking_weight': round(import_pagerank_contribution, 3),
                'interpretation': 'PageRankç½‘ç»œç»´åº¦åœ¨å‡ºå£é”å®šä¸­æƒé‡æ›´é«˜ï¼Œè¡¨æ˜ç½‘ç»œä½ç½®å¯¹ç¾å›½å‡ºå£å½±å“åŠ›æ›´é‡è¦'
            },
            'policy_recommendations': [
                "ä¼˜å…ˆå‘å±•å¯¹åå¤©ç„¶æ°”å‡ºå£å…³ç³»ï¼Œå…·æœ‰æœ€é«˜çš„é”å®šæ½œåŠ›",
                "å…³æ³¨å¯¹åŠ æ‹¿å¤§çš„è¿›å£ä¾èµ–ï¼Œå»ºç«‹å¤šå…ƒåŒ–ä¾›åº”ç­–ç•¥",
                "åˆ©ç”¨ç½‘ç»œä¸­å¿ƒæ€§ä¼˜åŠ¿ï¼Œæ‰©å¤§ç¾å›½åœ¨å…¨çƒèƒ½æºç½‘ç»œä¸­çš„å½±å“åŠ›",
                "å¹³è¡¡å‡ºå£é”å®šèƒ½åŠ›ä¸è¿›å£è¢«é”å®šé£é™©ï¼Œå®ç°èƒ½æºå®‰å…¨æœ€å¤§åŒ–"
            ]
        }
        
        return insights


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    
    print("ğŸŒŸ å¢å¼ºç‰ˆDLIæ•°æ®åˆ†ææ¼”ç¤º")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–åˆ†æå™¨
        analyzer = EnhancedDLIAnalyzer()
        
        # 1. åŸºç¡€ç»Ÿè®¡
        print("\nã€1ã€‘åŸºç¡€ç»Ÿè®¡åˆ†æ")
        print("-" * 30)
        stats = analyzer.get_basic_statistics()
        print(f"æ€»è®°å½•æ•°: {stats['total_records']:,}")
        print(f"å¹´ä»½è¦†ç›–: {stats['years_covered']}")
        print(f"å›½å®¶æ•°é‡: {stats['countries_count']}")
        print(f"å‡ºå£è®°å½•: {stats['export_records']:,} ({stats['export_records']/stats['total_records']*100:.1f}%)")
        print(f"è¿›å£è®°å½•: {stats['import_records']:,} ({stats['import_records']/stats['total_records']*100:.1f}%)")
        print(f"å¢å¼ºç‰ˆDLIç»Ÿè®¡: å‡å€¼={stats['dli_enhanced_stats']['mean']:.6f}, æ ‡å‡†å·®={stats['dli_enhanced_stats']['std']:.3f}")
        
        # 2. æ—¶é—´è¶‹åŠ¿åˆ†æ
        print("\nã€2ã€‘æ—¶é—´è¶‹åŠ¿åˆ†æ")
        print("-" * 30)
        trends = analyzer.analyze_time_trends()
        print(f"æ—¶é—´åºåˆ—æ•°æ®ç‚¹: {len(trends)}")
        print("æœ€æ–°5å¹´å¹³å‡è¶‹åŠ¿:")
        recent_trends = trends[trends['year'] >= 2020].groupby('us_role')['dli_mean'].mean()
        for role, avg_dli in recent_trends.items():
            print(f"  {role}: {avg_dli:.6f}")
        
        # 3. æ–¹å‘æ€§æ•ˆåº”å¯¹æ¯”
        print("\nã€3ã€‘æ–¹å‘æ€§é”å®šæ•ˆåº”å¯¹æ¯”")
        print("-" * 30)
        comparison = analyzer.compare_directional_effects()
        print(f"å‡ºå£é”å®šå¹³å‡æ°´å¹³: {comparison['export_locking']['mean_dli']:.6f}")
        print(f"è¿›å£è¢«é”å®šå¹³å‡æ°´å¹³: {comparison['import_locking']['mean_dli']:.6f}")
        print(f"ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ: p={comparison['statistical_test']['p_value']:.6f}")
        
        # 4. å›½å®¶æ’ååˆ†æ
        print("\nã€4ã€‘2024å¹´å›½å®¶é”å®šæ•ˆåº”æ’å")
        print("-" * 30)
        rankings = analyzer.analyze_country_rankings(2024, top_n=5)
        
        print("ç¾å›½å‡ºå£é”å®šTop 5:")
        for country, data in list(rankings['export_locking_ranking'].items())[:5]:
            print(f"  {country}: {data['dli_enhanced']:.3f}")
            
        print("ç¾å›½è¿›å£è¢«é”å®šTop 5:")  
        for country, data in list(rankings['import_locking_ranking'].items())[:5]:
            print(f"  {country}: {data['dli_enhanced']:.3f}")
        
        # 5. é¡µå²©é©å‘½å½±å“è¯„ä¼°
        print("\nã€5ã€‘é¡µå²©é©å‘½æ”¿ç­–å½±å“è¯„ä¼°")
        print("-" * 30)
        shale_impact = analyzer.evaluate_shale_revolution_impact()
        pre_export = shale_impact['pre_shale_revolution']['export_locking']['mean_dli']
        post_export = shale_impact['post_shale_revolution']['export_locking']['mean_dli']
        export_change = shale_impact['changes']['export_locking_change']
        
        print(f"é¡µå²©é©å‘½å‰å‡ºå£é”å®šåŠ›: {pre_export:.6f}")
        print(f"é¡µå²©é©å‘½åå‡ºå£é”å®šåŠ›: {post_export:.6f}")
        print(f"å˜åŒ–: {export_change:+.6f} ({shale_impact['changes']['interpretation']['export']})")
        
        # 6. ç”Ÿæˆå¯è§†åŒ–
        print("\nã€6ã€‘åˆ›å»ºå¯è§†åŒ–é¢æ¿")
        print("-" * 30)
        analyzer.create_visualization_dashboard()
        
        # 7. æ”¿ç­–æ´å¯Ÿ
        print("\nã€7ã€‘æ”¿ç­–åˆ†ææ´å¯Ÿ")
        print("-" * 30)
        insights = analyzer.generate_policy_insights()
        print(f"åˆ†æåŸºå‡†å¹´: {insights['analysis_year']}")
        
        print("\næˆ˜ç•¥å‡ºå£ä¼˜åŠ¿ (Top 3):")
        for i, advantage in enumerate(insights['strategic_export_advantages'][:3], 1):
            print(f"  {i}. {advantage['partner']}-{advantage['product']}: {advantage['dli_score']}")
        
        print("\nè¿›å£è„†å¼±æ€§é£é™© (Top 3):")
        for i, risk in enumerate(insights['import_vulnerability_risks'][:3], 1):
            print(f"  {i}. {risk['partner']}-{risk['product']}: {risk['dli_score']}")
        
        print(f"\nPageRankç½‘ç»œç»´åº¦é‡è¦æ€§:")
        network_info = insights['network_dimension_importance']
        print(f"  å‡ºå£é”å®šæƒé‡: {network_info['export_locking_weight']}")
        print(f"  è¿›å£é”å®šæƒé‡: {network_info['import_locking_weight']}")
        print(f"  è§£è¯»: {network_info['interpretation']}")
        
        print("\næ ¸å¿ƒæ”¿ç­–å»ºè®®:")
        for i, rec in enumerate(insights['policy_recommendations'], 1):
            print(f"  {i}. {rec}")
        
        print("\nâœ… å¢å¼ºç‰ˆDLIåˆ†ææ¼”ç¤ºå®Œæˆ!")
        print("ğŸ“ ç›¸å…³è¾“å‡ºæ–‡ä»¶:")
        print("  â€¢ dli_pagerank.csv - å¢å¼ºç‰ˆDLIé¢æ¿æ•°æ®")
        print("  â€¢ dli_pagerank_weights.json - PCAæƒé‡å‚æ•°")
        print("  â€¢ dli_dimensions_correlation.png - ç»´åº¦ç›¸å…³æ€§çƒ­åŠ›å›¾")
        print("  â€¢ enhanced_dli_dashboard.png - ç»¼åˆåˆ†æé¢æ¿")
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()