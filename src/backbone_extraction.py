#!/usr/bin/env python3
"""
éª¨å¹²ç½‘ç»œæå–æ¨¡å— (04_backbone_extraction)
===========================================

å®ç°ä¸‰ç§ä¸»è¦çš„ç½‘ç»œéª¨å¹²æå–æ–¹æ³•ï¼š
1. Disparity Filter (DF) - å·®å¼‚æ€§è¿‡æ»¤å™¨
2. Polarity Filter (PF) - ææ€§è¿‡æ»¤å™¨  
3. Minimum Spanning Tree (MST) - æœ€å°ç”Ÿæˆæ ‘

è¿™äº›æ–¹æ³•ç”¨äºä»å®Œæ•´çš„è´¸æ˜“ç½‘ç»œä¸­æå–æœ€é‡è¦çš„è¿æ¥ï¼Œ
ç®€åŒ–ç½‘ç»œç»“æ„åŒæ—¶ä¿ç•™å…³é”®çš„è´¸æ˜“å…³ç³»ã€‚

å‚è€ƒæ–‡çŒ®ï¼š
- Serrano et al. (2009) Extracting the multiscale backbone of complex weighted networks
- Tumminello et al. (2011) Statistically Validated Networks in Bipartite Complex Systems
- Kruskal (1956) On the shortest spanning subtree of a graph
"""

import networkx as nx
import pandas as pd
import numpy as np
from typing import Dict, Any, List, Tuple, Optional
from scipy import stats
import logging
from pathlib import Path
import sys

# æ·»åŠ ä¸Šçº§æ¨¡å—è·¯å¾„ä»¥å¯¼å…¥å·¥å…·å‡½æ•°
sys.path.append(str(Path(__file__).parent / "03_metrics"))
from utils import setup_logger, validate_graph, timer_decorator, handle_computation_error

logger = setup_logger(__name__)

class BackboneExtractor:
    """
    ç½‘ç»œéª¨å¹²æå–å™¨ç±»
    
    æä¾›ä¸‰ç§ä¸»è¦çš„éª¨å¹²æå–æ–¹æ³•ï¼Œæ¯ç§æ–¹æ³•éƒ½æœ‰ä¸åŒçš„ç†è®ºåŸºç¡€å’Œé€‚ç”¨åœºæ™¯
    """
    
    def __init__(self, G: nx.DiGraph):
        """
        åˆå§‹åŒ–éª¨å¹²æå–å™¨
        
        Args:
            G: è¾“å…¥çš„åŠ æƒæœ‰å‘å›¾
        """
        validate_graph(G, "BackboneExtractor")
        self.G = G.copy()
        self.logger = setup_logger(f"{__name__}.BackboneExtractor")
        
        # é¢„è®¡ç®—ä¸€äº›å¸¸ç”¨ç»Ÿè®¡é‡
        self._precompute_stats()
    
    def _precompute_stats(self):
        """é¢„è®¡ç®—ç½‘ç»œç»Ÿè®¡é‡"""
        self.n_nodes = self.G.number_of_nodes()
        self.n_edges = self.G.number_of_edges()
        
        # è®¡ç®—èŠ‚ç‚¹çš„æ€»å¼ºåº¦
        self.node_strengths = {}
        for node in self.G.nodes():
            out_strength = sum(self.G[node][neighbor]['weight'] 
                             for neighbor in self.G.neighbors(node))
            in_strength = sum(self.G[pred][node]['weight'] 
                            for pred in self.G.predecessors(node))
            self.node_strengths[node] = {
                'out': out_strength,
                'in': in_strength,
                'total': out_strength + in_strength
            }
    
    @timer_decorator
    def extract_disparity_filter_backbone(self, alpha: float = 0.05, 
                                         direction: str = 'both') -> nx.DiGraph:
        """
        ä½¿ç”¨å·®å¼‚æ€§è¿‡æ»¤å™¨æå–éª¨å¹²ç½‘ç»œ
        
        å·®å¼‚æ€§è¿‡æ»¤å™¨åŸºäºå‡è®¾ï¼šå¦‚æœä¸€ä¸ªèŠ‚ç‚¹çš„è¿æ¥æƒé‡åˆ†å¸ƒæ˜¯éšæœºçš„ï¼Œ
        é‚£ä¹ˆæƒé‡åº”è¯¥æœä»å‡åŒ€åˆ†å¸ƒã€‚æ˜¾è‘—åç¦»è¿™ç§åˆ†å¸ƒçš„è¾¹è¢«è®¤ä¸ºæ˜¯é‡è¦çš„ã€‚
        
        Args:
            alpha: æ˜¾è‘—æ€§æ°´å¹³ (é»˜è®¤ 0.05)
            direction: è¿‡æ»¤æ–¹å‘ ('out', 'in', 'both')
            
        Returns:
            æå–çš„éª¨å¹²ç½‘ç»œ
            
        References:
            Serrano, M. Ã., BoguÃ±Ã¡, M., & Vespignani, A. (2009). 
            Extracting the multiscale backbone of complex weighted networks. 
            PNAS, 106(16), 6483-6488.
        """
        self.logger.info(f"ä½¿ç”¨å·®å¼‚æ€§è¿‡æ»¤å™¨æå–éª¨å¹²ç½‘ç»œ (Î±={alpha}, direction={direction})")
        
        backbone = nx.DiGraph()
        backbone.add_nodes_from(self.G.nodes(data=True))
        
        significant_edges = 0
        
        for u, v, data in self.G.edges(data=True):
            weight = data['weight']
            
            # è®¡ç®—på€¼
            p_values = []
            
            if direction in ['out', 'both']:
                # å‡ºåº¦æ–¹å‘çš„på€¼
                k_out = self.G.out_degree(u)
                if k_out > 1:
                    s_out = self.node_strengths[u]['out']
                    p_out = self._calculate_disparity_p_value(weight, s_out, k_out)
                    p_values.append(p_out)
            
            if direction in ['in', 'both']:
                # å…¥åº¦æ–¹å‘çš„på€¼  
                k_in = self.G.in_degree(v)
                if k_in > 1:
                    s_in = self.node_strengths[v]['in']
                    p_in = self._calculate_disparity_p_value(weight, s_in, k_in)
                    p_values.append(p_in)
            
            # åˆ¤æ–­è¾¹æ˜¯å¦æ˜¾è‘—
            if p_values:
                # ä½¿ç”¨æœ€å°på€¼ï¼ˆæœ€ä¿å®ˆçš„ä¼°è®¡ï¼‰
                min_p_value = min(p_values)
                if min_p_value < alpha:
                    backbone.add_edge(u, v, **data, p_value=min_p_value)
                    significant_edges += 1
        
        self.logger.info(f"å·®å¼‚æ€§è¿‡æ»¤å™¨å®Œæˆ: {significant_edges}/{self.n_edges} æ¡è¾¹è¢«ä¿ç•™ "
                        f"({significant_edges/self.n_edges*100:.1f}%)")
        
        return backbone
    
    def _calculate_disparity_p_value(self, weight: float, total_strength: float, 
                                   degree: int) -> float:
        """
        è®¡ç®—å·®å¼‚æ€§è¿‡æ»¤å™¨çš„på€¼
        
        åŸºäºé›¶å‡è®¾ï¼šæƒé‡æ¯”ä¾‹ p = weight/total_strength æ¥è‡ªå‡åŒ€åˆ†å¸ƒ
        """
        if total_strength == 0 or degree <= 1:
            return 1.0
        
        p = weight / total_strength
        
        # ä½¿ç”¨ç§¯åˆ†å…¬å¼è®¡ç®—på€¼
        # P(X >= p) = (1-p)^(k-1) where k is degree
        p_value = (1 - p) ** (degree - 1)
        
        return p_value
    
    @timer_decorator  
    def extract_polarity_filter_backbone(self, alpha: float = 0.05,
                                        method: str = 'proximity') -> nx.DiGraph:
        """
        ä½¿ç”¨ææ€§è¿‡æ»¤å™¨æå–éª¨å¹²ç½‘ç»œ
        
        ææ€§è¿‡æ»¤å™¨åŸºäºç½‘ç»œä¸­ä¸‰å…ƒç»„ç»“æ„çš„ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œ
        è¯†åˆ«åœ¨å±€éƒ¨æ‹“æ‰‘ä¸­èµ·é‡è¦ä½œç”¨çš„è¾¹ã€‚
        
        Args:
            alpha: æ˜¾è‘—æ€§æ°´å¹³
            method: è®¡ç®—æ–¹æ³• ('proximity', 'similarity')
            
        Returns:
            æå–çš„éª¨å¹²ç½‘ç»œ
            
        References:
            Tumminello, M., MiccichÃ¨, S., Lillo, F., Piilo, J., & Mantegna, R. N. (2011).
            Statistically validated networks in bipartite complex systems.
            PloS one, 6(3), e17994.
        """
        self.logger.info(f"ä½¿ç”¨ææ€§è¿‡æ»¤å™¨æå–éª¨å¹²ç½‘ç»œ (Î±={alpha}, method={method})")
        
        backbone = nx.DiGraph()
        backbone.add_nodes_from(self.G.nodes(data=True))
        
        # è®¡ç®—æ¯æ¡è¾¹çš„ç»Ÿè®¡æ˜¾è‘—æ€§
        significant_edges = 0
        
        for u, v, data in self.G.edges(data=True):
            weight = data['weight']
            
            # è®¡ç®—åŸºäºä¸‰å…ƒç»„çš„ç»Ÿè®¡é‡
            if method == 'proximity':
                p_value = self._calculate_proximity_p_value(u, v, weight)
            elif method == 'similarity':
                p_value = self._calculate_similarity_p_value(u, v, weight)
            else:
                raise ValueError(f"æœªçŸ¥çš„ææ€§è¿‡æ»¤å™¨æ–¹æ³•: {method}")
            
            if p_value < alpha:
                backbone.add_edge(u, v, **data, p_value=p_value)
                significant_edges += 1
        
        self.logger.info(f"ææ€§è¿‡æ»¤å™¨å®Œæˆ: {significant_edges}/{self.n_edges} æ¡è¾¹è¢«ä¿ç•™ "
                        f"({significant_edges/self.n_edges*100:.1f}%)")
        
        return backbone
    
    def _calculate_proximity_p_value(self, u: str, v: str, weight: float) -> float:
        """
        è®¡ç®—åŸºäºé‚»è¿‘æ€§çš„på€¼
        
        è¯„ä¼°èŠ‚ç‚¹uå’Œvä¹‹é—´çš„è¿æ¥ç›¸å¯¹äºå®ƒä»¬çš„å…±åŒé‚»å±…æ˜¯å¦æ˜¾è‘—
        """
        # è·å–å…±åŒé‚»å±…
        u_neighbors = set(self.G.neighbors(u)) | set(self.G.predecessors(u))
        v_neighbors = set(self.G.neighbors(v)) | set(self.G.predecessors(v))
        common_neighbors = u_neighbors & v_neighbors
        
        if len(common_neighbors) == 0:
            return 1.0
        
        # è®¡ç®—åŸºäºå…±åŒé‚»å±…çš„æœŸæœ›æƒé‡
        u_total_weight = self.node_strengths[u]['total']
        v_total_weight = self.node_strengths[v]['total']
        
        # ä½¿ç”¨hypergeometricåˆ†å¸ƒè¿‘ä¼¼
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œå®é™…çš„ææ€§è¿‡æ»¤å™¨å¯èƒ½æ›´å¤æ‚
        expected_weight = (u_total_weight * v_total_weight) / (2 * self.n_edges)
        
        if expected_weight == 0:
            return 1.0
        
        # ä½¿ç”¨æ³Šæ¾åˆ†å¸ƒè¿‘ä¼¼è®¡ç®—på€¼
        lambda_param = expected_weight
        p_value = 1 - stats.poisson.cdf(weight - 1, lambda_param)
        
        return min(p_value, 1.0)
    
    def _calculate_similarity_p_value(self, u: str, v: str, weight: float) -> float:
        """
        è®¡ç®—åŸºäºç›¸ä¼¼æ€§çš„på€¼
        
        è¯„ä¼°èŠ‚ç‚¹uå’Œvçš„ç›¸ä¼¼æ€§æ˜¯å¦è¶³ä»¥è§£é‡Šå®ƒä»¬ä¹‹é—´çš„è¿æ¥å¼ºåº¦
        """
        # è®¡ç®—Jaccardç›¸ä¼¼æ€§
        u_neighbors = set(self.G.neighbors(u)) | set(self.G.predecessors(u))
        v_neighbors = set(self.G.neighbors(v)) | set(self.G.predecessors(v))
        
        intersection = len(u_neighbors & v_neighbors)
        union = len(u_neighbors | v_neighbors)
        
        if union == 0:
            jaccard_similarity = 0
        else:
            jaccard_similarity = intersection / union
        
        # åŸºäºç›¸ä¼¼æ€§è®¡ç®—æœŸæœ›æƒé‡
        max_possible_weight = min(self.node_strengths[u]['total'], 
                                self.node_strengths[v]['total'])
        expected_weight = jaccard_similarity * max_possible_weight
        
        if expected_weight == 0:
            return 1.0
        
        # ä½¿ç”¨æ­£æ€åˆ†å¸ƒè¿‘ä¼¼
        # è¿™æ˜¯ç®€åŒ–å®ç°ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´ç²¾ç¡®çš„ç»Ÿè®¡æ¨¡å‹
        std_dev = np.sqrt(expected_weight)
        if std_dev == 0:
            return 1.0
        
        z_score = (weight - expected_weight) / std_dev
        p_value = 1 - stats.norm.cdf(z_score)
        
        return min(p_value, 1.0)
    
    @timer_decorator
    def extract_mst_backbone(self, algorithm: str = 'kruskal') -> nx.DiGraph:
        """
        ä½¿ç”¨æœ€å°ç”Ÿæˆæ ‘æå–éª¨å¹²ç½‘ç»œ
        
        MSTæ–¹æ³•ä¿ç•™è¿æ¥æ‰€æœ‰èŠ‚ç‚¹æ‰€éœ€çš„æœ€å°æƒé‡è¾¹é›†åˆã€‚
        å¯¹äºæœ‰å‘å›¾ï¼Œæˆ‘ä»¬é¦–å…ˆè½¬æ¢ä¸ºæ— å‘å›¾ï¼Œç„¶åé‡æ–°åˆ†é…æ–¹å‘ã€‚
        
        Args:
            algorithm: MSTç®—æ³• ('kruskal', 'prim')
            
        Returns:
            MSTéª¨å¹²ç½‘ç»œ
            
        References:
            Kruskal, J. B. (1956). On the shortest spanning subtree of a graph 
            and the traveling salesman problem. Proceedings of the American 
            Mathematical society, 7(1), 48-50.
        """
        self.logger.info(f"ä½¿ç”¨æœ€å°ç”Ÿæˆæ ‘æå–éª¨å¹²ç½‘ç»œ (algorithm={algorithm})")
        
        # è½¬æ¢ä¸ºæ— å‘å›¾ç”¨äºMSTè®¡ç®—
        # å¯¹äºæœ‰å‘å›¾ï¼Œæˆ‘ä»¬éœ€è¦èšåˆåŒå‘è¾¹çš„æƒé‡
        undirected_G = nx.Graph()
        
        # æ·»åŠ èŠ‚ç‚¹
        undirected_G.add_nodes_from(self.G.nodes(data=True))
        
        # èšåˆè¾¹æƒé‡
        edge_weights = {}
        for u, v, data in self.G.edges(data=True):
            edge_key = tuple(sorted([u, v]))
            weight = data['weight']
            
            if edge_key in edge_weights:
                edge_weights[edge_key] += weight
            else:
                edge_weights[edge_key] = weight
        
        # æ·»åŠ èšåˆåçš„è¾¹
        for (u, v), weight in edge_weights.items():
            undirected_G.add_edge(u, v, weight=weight)
        
        # è®¡ç®—MST
        if algorithm == 'kruskal':
            mst_edges = nx.minimum_spanning_edges(undirected_G, algorithm='kruskal', 
                                                data=True, weight='weight')
        elif algorithm == 'prim':
            mst_edges = nx.minimum_spanning_edges(undirected_G, algorithm='prim',
                                                data=True, weight='weight')
        else:
            raise ValueError(f"æœªçŸ¥çš„MSTç®—æ³•: {algorithm}")
        
        # åˆ›å»ºéª¨å¹²ç½‘ç»œ
        backbone = nx.DiGraph()
        backbone.add_nodes_from(self.G.nodes(data=True))
        
        # å°†MSTè¾¹é‡æ–°æ·»åŠ ä¸ºæœ‰å‘è¾¹
        mst_edge_set = set()
        for u, v, data in mst_edges:
            mst_edge_set.add((u, v))
            mst_edge_set.add((v, u))  # ä¸¤ä¸ªæ–¹å‘éƒ½è€ƒè™‘
        
        # ä»åŸå›¾ä¸­æ·»åŠ MSTåŒ…å«çš„è¾¹
        added_edges = 0
        for u, v, data in self.G.edges(data=True):
            if (u, v) in mst_edge_set or (v, u) in mst_edge_set:
                backbone.add_edge(u, v, **data)
                added_edges += 1
        
        self.logger.info(f"æœ€å°ç”Ÿæˆæ ‘å®Œæˆ: {added_edges}/{self.n_edges} æ¡è¾¹è¢«ä¿ç•™ "
                        f"({added_edges/self.n_edges*100:.1f}%)")
        
        return backbone
    
    def extract_all_backbones(self, df_alpha: float = 0.05, 
                            pf_alpha: float = 0.05,
                            mst_algorithm: str = 'kruskal') -> Dict[str, nx.DiGraph]:
        """
        ä¸€æ¬¡æ€§æå–æ‰€æœ‰ä¸‰ç§éª¨å¹²ç½‘ç»œ
        
        Args:
            df_alpha: å·®å¼‚æ€§è¿‡æ»¤å™¨çš„æ˜¾è‘—æ€§æ°´å¹³
            pf_alpha: ææ€§è¿‡æ»¤å™¨çš„æ˜¾è‘—æ€§æ°´å¹³
            mst_algorithm: MSTç®—æ³•
            
        Returns:
            åŒ…å«ä¸‰ç§éª¨å¹²ç½‘ç»œçš„å­—å…¸
        """
        self.logger.info("å¼€å§‹æå–æ‰€æœ‰éª¨å¹²ç½‘ç»œ...")
        
        backbones = {}
        
        try:
            # å·®å¼‚æ€§è¿‡æ»¤å™¨
            backbones['disparity_filter'] = self.extract_disparity_filter_backbone(df_alpha)
            
            # ææ€§è¿‡æ»¤å™¨
            backbones['polarity_filter'] = self.extract_polarity_filter_backbone(pf_alpha)
            
            # æœ€å°ç”Ÿæˆæ ‘
            backbones['minimum_spanning_tree'] = self.extract_mst_backbone(mst_algorithm)
            
            self.logger.info("æ‰€æœ‰éª¨å¹²ç½‘ç»œæå–å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"éª¨å¹²ç½‘ç»œæå–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            raise
        
        return backbones
    
    def compare_backbones(self, backbones: Dict[str, nx.DiGraph]) -> pd.DataFrame:
        """
        æ¯”è¾ƒä¸åŒéª¨å¹²ç½‘ç»œçš„ç»Ÿè®¡ç‰¹å¾
        
        Args:
            backbones: éª¨å¹²ç½‘ç»œå­—å…¸
            
        Returns:
            æ¯”è¾ƒç»“æœDataFrame
        """
        comparison_data = []
        
        # åŸå§‹ç½‘ç»œç»Ÿè®¡
        original_stats = self._calculate_network_stats(self.G, "Original")
        comparison_data.append(original_stats)
        
        # å„éª¨å¹²ç½‘ç»œç»Ÿè®¡
        for method_name, backbone in backbones.items():
            stats = self._calculate_network_stats(backbone, method_name)
            comparison_data.append(stats)
        
        comparison_df = pd.DataFrame(comparison_data)
        
        self.logger.info("éª¨å¹²ç½‘ç»œæ¯”è¾ƒåˆ†æå®Œæˆ")
        
        return comparison_df
    
    def _calculate_network_stats(self, G: nx.DiGraph, method_name: str) -> Dict[str, Any]:
        """è®¡ç®—ç½‘ç»œç»Ÿè®¡æŒ‡æ ‡"""
        stats = {
            'method': method_name,
            'nodes': G.number_of_nodes(),
            'edges': G.number_of_edges(),
            'density': nx.density(G),
            'edge_retention_rate': G.number_of_edges() / self.n_edges if self.n_edges > 0 else 0
        }
        
        # è®¡ç®—è¿é€šæ€§
        try:
            if G.number_of_edges() > 0:
                stats['avg_clustering'] = nx.average_clustering(G.to_undirected())
                
                # è½¬ä¸ºæ— å‘å›¾è®¡ç®—è¿é€šç»„ä»¶
                undirected = G.to_undirected()
                stats['connected_components'] = nx.number_connected_components(undirected)
                stats['largest_component_size'] = len(max(nx.connected_components(undirected), key=len))
            else:
                stats['avg_clustering'] = 0
                stats['connected_components'] = stats['nodes']
                stats['largest_component_size'] = 1 if stats['nodes'] > 0 else 0
                
        except Exception as e:
            self.logger.warning(f"è®¡ç®—{method_name}ç½‘ç»œç»Ÿè®¡æ—¶å‡ºé”™: {e}")
            stats['avg_clustering'] = 0
            stats['connected_components'] = stats['nodes']
            stats['largest_component_size'] = 1 if stats['nodes'] > 0 else 0
        
        return stats


def extract_backbones_for_year(G: nx.DiGraph, year: int, 
                              methods: List[str] = ['df', 'pf', 'mst'],
                              **kwargs) -> Dict[str, nx.DiGraph]:
    """
    ä¸ºå•ä¸ªå¹´ä»½æå–éª¨å¹²ç½‘ç»œçš„ä¾¿æ·å‡½æ•°
    
    Args:
        G: ç½‘ç»œå›¾
        year: å¹´ä»½
        methods: è¦ä½¿ç”¨çš„æ–¹æ³•åˆ—è¡¨ ('df', 'pf', 'mst')
        **kwargs: ä¼ é€’ç»™å„æ–¹æ³•çš„å‚æ•°
        
    Returns:
        éª¨å¹²ç½‘ç»œå­—å…¸
    """
    logger.info(f"ğŸ” {year}: å¼€å§‹æå–éª¨å¹²ç½‘ç»œ...")
    
    extractor = BackboneExtractor(G)
    backbones = {}
    
    if 'df' in methods:
        df_alpha = kwargs.get('df_alpha', 0.05)
        backbones['disparity_filter'] = extractor.extract_disparity_filter_backbone(df_alpha)
    
    if 'pf' in methods:
        pf_alpha = kwargs.get('pf_alpha', 0.05)
        pf_method = kwargs.get('pf_method', 'proximity')
        backbones['polarity_filter'] = extractor.extract_polarity_filter_backbone(pf_alpha, pf_method)
    
    if 'mst' in methods:
        mst_algorithm = kwargs.get('mst_algorithm', 'kruskal')
        backbones['minimum_spanning_tree'] = extractor.extract_mst_backbone(mst_algorithm)
    
    logger.info(f"âœ… {year}: éª¨å¹²ç½‘ç»œæå–å®Œæˆ")
    
    return backbones


def analyze_backbone_evolution(annual_networks: Dict[int, nx.DiGraph],
                             methods: List[str] = ['df', 'pf', 'mst'],
                             **kwargs) -> pd.DataFrame:
    """
    åˆ†æéª¨å¹²ç½‘ç»œéšæ—¶é—´çš„æ¼”åŒ–
    
    Args:
        annual_networks: å¹´åº¦ç½‘ç»œå­—å…¸
        methods: è¦åˆ†æçš„æ–¹æ³•
        **kwargs: ä¼ é€’ç»™æå–æ–¹æ³•çš„å‚æ•°
        
    Returns:
        æ¼”åŒ–åˆ†æç»“æœDataFrame
    """
    logger.info(f"ğŸŒŸ å¼€å§‹åˆ†æéª¨å¹²ç½‘ç»œæ¼”åŒ– - {len(annual_networks)} ä¸ªå¹´ä»½")
    
    evolution_data = []
    
    for year in sorted(annual_networks.keys()):
        G = annual_networks[year]
        
        try:
            # æå–éª¨å¹²ç½‘ç»œ
            backbones = extract_backbones_for_year(G, year, methods, **kwargs)
            
            # åˆ†ææ¯ç§æ–¹æ³•
            extractor = BackboneExtractor(G)
            year_comparison = extractor.compare_backbones(backbones)
            year_comparison['year'] = year
            
            evolution_data.append(year_comparison)
            
        except Exception as e:
            logger.error(f"âŒ {year}å¹´éª¨å¹²ç½‘ç»œåˆ†æå¤±è´¥: {e}")
            continue
    
    if evolution_data:
        # åˆå¹¶æ‰€æœ‰å¹´ä»½çš„æ•°æ®
        all_data = pd.concat(evolution_data, ignore_index=True)
        logger.info(f"âœ… éª¨å¹²ç½‘ç»œæ¼”åŒ–åˆ†æå®Œæˆ")
        return all_data
    else:
        logger.error("æ‰€æœ‰å¹´ä»½åˆ†æéƒ½å¤±è´¥äº†")
        return pd.DataFrame()


# å¯¼å‡ºçš„ä¸»è¦å‡½æ•°
__all__ = [
    'BackboneExtractor',
    'extract_backbones_for_year', 
    'analyze_backbone_evolution'
]