#!/usr/bin/env python3
"""
analysis.py - æ ¸å¿ƒç»Ÿè®¡åˆ†æåŠŸèƒ½
å®ç°ç¾å›½èƒ½æºç‹¬ç«‹æ”¿ç­–å½±å“çš„äº‹å‰-äº‹åå¯¹æ¯”åˆ†æ
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any, Optional
from pathlib import Path
import logging
from scipy import stats
import warnings

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_and_prepare_data(filepath: str) -> pd.DataFrame:
    """
    åŠ è½½å¹¶å‡†å¤‡åˆ†ææ•°æ®
    
    Args:
        filepath: all_metrics.csvæ–‡ä»¶è·¯å¾„
        
    Returns:
        æ·»åŠ äº†periodåˆ—çš„DataFrame
        
    Raises:
        FileNotFoundError: å½“æ–‡ä»¶ä¸å­˜åœ¨æ—¶
        ValueError: å½“æ•°æ®æ ¼å¼ä¸æ­£ç¡®æ—¶
    """
    logger.info(f"ğŸ“– åŠ è½½æ•°æ®æ–‡ä»¶: {filepath}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(filepath).exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶: {filepath}")
    
    # åŠ è½½æ•°æ®
    try:
        df = pd.read_csv(filepath)
        logger.info(f"âœ… æˆåŠŸåŠ è½½æ•°æ®: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
    except Exception as e:
        raise ValueError(f"è¯»å–æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
    
    # éªŒè¯å¿…è¦åˆ—
    required_columns = ['year', 'country_code']
    missing_columns = set(required_columns) - set(df.columns)
    if missing_columns:
        raise ValueError(f"æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
    
    # æ·»åŠ æ”¿ç­–æœŸé—´æ ‡è¯†
    df = df.copy()
    
    def assign_period(year: int) -> str:
        """æ ¹æ®å¹´ä»½åˆ†é…æ”¿ç­–æœŸé—´"""
        if 2001 <= year <= 2008:
            return 'pre'
        elif 2009 <= year <= 2015:
            return 'transition'
        elif 2016 <= year <= 2024:
            return 'post'
        else:
            return 'unknown'
    
    df['period'] = df['year'].apply(assign_period)
    
    # ç»Ÿè®¡å„æœŸé—´çš„æ•°æ®
    period_counts = df['period'].value_counts()
    logger.info(f"ğŸ“Š æ”¿ç­–æœŸé—´æ•°æ®åˆ†å¸ƒ:")
    for period, count in period_counts.items():
        logger.info(f"  {period}: {count} æ¡è®°å½•")
    
    # éªŒè¯å¹´ä»½èŒƒå›´
    year_range = (df['year'].min(), df['year'].max())
    logger.info(f"ğŸ“… æ•°æ®å¹´ä»½èŒƒå›´: {year_range[0]} - {year_range[1]}")
    
    return df

def run_pre_post_analysis(df: pd.DataFrame, 
                         countries_of_interest: List[str] = None,
                         metrics_of_interest: List[str] = None) -> pd.DataFrame:
    """
    æ‰§è¡Œäº‹å‰-äº‹åå¯¹æ¯”åˆ†æ
    
    Args:
        df: åŒ…å«periodåˆ—çš„å®Œæ•´æ•°æ®
        countries_of_interest: å…³æ³¨çš„å›½å®¶åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰å›½å®¶
        metrics_of_interest: å…³æ³¨çš„æŒ‡æ ‡åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰æ•°å€¼æŒ‡æ ‡
        
    Returns:
        åŒ…å«å¯¹æ¯”åˆ†æç»“æœçš„DataFrame
    """
    logger.info("ğŸ” å¼€å§‹äº‹å‰-äº‹åå¯¹æ¯”åˆ†æ...")
    
    # ç­›é€‰æ•°æ®
    analysis_df = df.copy()
    
    if countries_of_interest:
        analysis_df = analysis_df[analysis_df['country_code'].isin(countries_of_interest)]
        logger.info(f"ğŸŒ åˆ†æå›½å®¶: {len(countries_of_interest)} ä¸ª")
    
    # åªä¿ç•™preå’ŒpostæœŸé—´
    analysis_df = analysis_df[analysis_df['period'].isin(['pre', 'post'])]
    
    if len(analysis_df) == 0:
        raise ValueError("ç­›é€‰åæ²¡æœ‰å¯åˆ†æçš„æ•°æ®")
    
    # è¯†åˆ«æ•°å€¼æŒ‡æ ‡åˆ—
    if metrics_of_interest is None:
        # è‡ªåŠ¨è¯†åˆ«æ•°å€¼åˆ—ï¼Œæ’é™¤æ ‡è¯†åˆ—
        exclude_columns = ['year', 'country_code', 'country_name', 'period']
        numeric_columns = analysis_df.select_dtypes(include=[np.number]).columns
        metrics_of_interest = [col for col in numeric_columns if col not in exclude_columns]
    
    logger.info(f"ğŸ“Š åˆ†ææŒ‡æ ‡: {len(metrics_of_interest)} ä¸ª")
    
    # æŒ‰country_codeå’Œperiodåˆ†ç»„è®¡ç®—å‡å€¼
    logger.info("ğŸ“ˆ è®¡ç®—æœŸé—´å‡å€¼...")
    grouped = analysis_df.groupby(['country_code', 'period'])[metrics_of_interest].mean().reset_index()
    
    # é‡å¡‘æ•°æ®ï¼šå°†periodä½œä¸ºåˆ—
    logger.info("ğŸ”„ é‡å¡‘æ•°æ®æ ¼å¼...")
    pivot_df = grouped.pivot(index='country_code', columns='period', values=metrics_of_interest)
    
    # æ‰å¹³åŒ–åˆ—å
    pivot_df.columns = [f'{metric}_{period}' for metric, period in pivot_df.columns]
    pivot_df.reset_index(inplace=True)
    
    # è®¡ç®—å˜åŒ–é‡å’Œå˜åŒ–ç‡
    logger.info("ğŸ“Š è®¡ç®—å˜åŒ–æŒ‡æ ‡...")
    for metric in metrics_of_interest:
        pre_col = f'{metric}_pre'
        post_col = f'{metric}_post'
        
        if pre_col in pivot_df.columns and post_col in pivot_df.columns:
            # ç»å¯¹å˜åŒ–
            pivot_df[f'{metric}_change'] = pivot_df[post_col] - pivot_df[pre_col]
            
            # ç›¸å¯¹å˜åŒ–ï¼ˆç™¾åˆ†æ¯”ï¼‰
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                pivot_df[f'{metric}_pct_change'] = (
                    (pivot_df[post_col] - pivot_df[pre_col]) / 
                    pivot_df[pre_col].abs() * 100
                )
                # å¤„ç†æ— ç©·å¤§å’ŒNaNå€¼
                pivot_df[f'{metric}_pct_change'] = pivot_df[f'{metric}_pct_change'].replace([np.inf, -np.inf], np.nan)
    
    logger.info(f"âœ… å¯¹æ¯”åˆ†æå®Œæˆ: {len(pivot_df)} ä¸ªå›½å®¶")
    
    return pivot_df

def calculate_policy_impact_statistics(df: pd.DataFrame, 
                                     comparison_df: pd.DataFrame,
                                     metrics_of_interest: List[str] = None) -> Dict[str, Any]:
    """
    è®¡ç®—æ”¿ç­–å½±å“ç»Ÿè®¡é‡
    
    Args:
        df: åŸå§‹æ•°æ®ï¼ˆåŒ…å«periodåˆ—ï¼‰
        comparison_df: å¯¹æ¯”åˆ†æç»“æœ
        metrics_of_interest: å…³æ³¨çš„æŒ‡æ ‡åˆ—è¡¨
        
    Returns:
        åŒ…å«ç»Ÿè®¡ç»“æœçš„å­—å…¸
    """
    logger.info("ğŸ“Š è®¡ç®—æ”¿ç­–å½±å“ç»Ÿè®¡é‡...")
    
    if metrics_of_interest is None:
        # ä»comparison_dfä¸­æå–æŒ‡æ ‡å
        change_cols = [col for col in comparison_df.columns if col.endswith('_change')]
        metrics_of_interest = [col.replace('_change', '') for col in change_cols]
    
    statistics = {
        'summary': {},
        'significance_tests': {},
        'top_winners': {},
        'top_losers': {},
        'period_aggregates': {}
    }
    
    # 1. åŸºæœ¬ç»Ÿè®¡æ‘˜è¦
    logger.info("ğŸ“ˆ è®¡ç®—åŸºæœ¬ç»Ÿè®¡æ‘˜è¦...")
    for metric in metrics_of_interest:
        change_col = f'{metric}_change'
        pct_change_col = f'{metric}_pct_change'
        
        if change_col in comparison_df.columns:
            changes = comparison_df[change_col].dropna()
            
            # æ£€æŸ¥ç™¾åˆ†æ¯”å˜åŒ–åˆ—æ˜¯å¦å­˜åœ¨
            pct_changes = pd.Series(dtype=float)
            if pct_change_col in comparison_df.columns:
                pct_changes = comparison_df[pct_change_col].dropna()
            
            statistics['summary'][metric] = {
                'mean_change': changes.mean(),
                'median_change': changes.median(),
                'std_change': changes.std(),
                'mean_pct_change': pct_changes.mean() if len(pct_changes) > 0 else np.nan,
                'median_pct_change': pct_changes.median() if len(pct_changes) > 0 else np.nan,
                'countries_increased': (changes > 0).sum(),
                'countries_decreased': (changes < 0).sum(),
                'countries_unchanged': (changes == 0).sum()
            }
    
    # 2. æ˜¾è‘—æ€§æ£€éªŒï¼ˆé…å¯¹tæ£€éªŒï¼‰
    logger.info("ğŸ”¬ æ‰§è¡Œæ˜¾è‘—æ€§æ£€éªŒ...")
    for metric in metrics_of_interest:
        pre_col = f'{metric}_pre'
        post_col = f'{metric}_post'
        
        if pre_col in comparison_df.columns and post_col in comparison_df.columns:
            pre_values = comparison_df[pre_col].dropna()
            post_values = comparison_df[post_col].dropna()
            
            # ç¡®ä¿é…å¯¹æ•°æ®
            common_countries = comparison_df.dropna(subset=[pre_col, post_col])['country_code']
            if len(common_countries) > 3:  # è‡³å°‘éœ€è¦å‡ ä¸ªè§‚æµ‹å€¼
                pre_paired = comparison_df.loc[comparison_df['country_code'].isin(common_countries), pre_col]
                post_paired = comparison_df.loc[comparison_df['country_code'].isin(common_countries), post_col]
                
                try:
                    t_stat, p_value = stats.ttest_rel(post_paired, pre_paired)
                    statistics['significance_tests'][metric] = {
                        't_statistic': t_stat,
                        'p_value': p_value,
                        'is_significant': p_value < 0.05,
                        'sample_size': len(common_countries)
                    }
                except Exception as e:
                    logger.warning(f"âš ï¸  {metric}æ˜¾è‘—æ€§æ£€éªŒå¤±è´¥: {e}")
    
    # 3. æœ€å¤§å—ç›Šè€…å’Œå—æŸè€…
    logger.info("ğŸ† è¯†åˆ«æœ€å¤§å—ç›Šè€…å’Œå—æŸè€…...")
    for metric in metrics_of_interest:
        change_col = f'{metric}_change'
        
        if change_col in comparison_df.columns:
            # æŒ‰å˜åŒ–é‡æ’åº
            sorted_df = comparison_df.sort_values(change_col, ascending=False).dropna(subset=[change_col])
            
            statistics['top_winners'][metric] = sorted_df.head(5)[['country_code', change_col]].to_dict('records')
            statistics['top_losers'][metric] = sorted_df.tail(5)[['country_code', change_col]].to_dict('records')
    
    # 4. æœŸé—´èšåˆç»Ÿè®¡
    logger.info("ğŸ“Š è®¡ç®—æœŸé—´èšåˆç»Ÿè®¡...")
    for period in ['pre', 'post']:
        period_data = df[df['period'] == period]
        if len(period_data) > 0:
            period_stats = {}
            for metric in metrics_of_interest:
                if metric in period_data.columns:
                    values = period_data[metric].dropna()
                    if len(values) > 0:
                        period_stats[metric] = {
                            'mean': values.mean(),
                            'median': values.median(),
                            'std': values.std(),
                            'min': values.min(),
                            'max': values.max()
                        }
            statistics['period_aggregates'][period] = period_stats
    
    logger.info("âœ… æ”¿ç­–å½±å“ç»Ÿè®¡é‡è®¡ç®—å®Œæˆ")
    
    return statistics

def export_analysis_results(comparison_df: pd.DataFrame, 
                          statistics: Dict[str, Any],
                          output_dir: str = "outputs/tables") -> Dict[str, str]:
    """
    å¯¼å‡ºåˆ†æç»“æœ
    
    Args:
        comparison_df: å¯¹æ¯”åˆ†æç»“æœ
        statistics: ç»Ÿè®¡ç»“æœ
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        å¯¼å‡ºæ–‡ä»¶è·¯å¾„å­—å…¸
    """
    logger.info(f"ğŸ’¾ å¯¼å‡ºåˆ†æç»“æœåˆ° {output_dir}...")
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    exported_files = {}
    
    try:
        # 1. å¯¼å‡ºå¯¹æ¯”åˆ†æè¡¨æ ¼
        comparison_file = output_path / "policy_impact_summary.csv"
        comparison_df.to_csv(comparison_file, index=False)
        exported_files['comparison'] = str(comparison_file)
        logger.info(f"âœ… å¯¹æ¯”åˆ†æè¡¨æ ¼: {comparison_file}")
        
        # 2. å¯¼å‡ºç»Ÿè®¡æ‘˜è¦
        import json
        statistics_file = output_path / "policy_impact_statistics.json"
        
        # å¤„ç†numpyç±»å‹ä»¥ä¾¿JSONåºåˆ—åŒ–
        def convert_numpy(obj):
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            return obj
        
        # é€’å½’è½¬æ¢statisticså­—å…¸
        def convert_dict(d):
            if isinstance(d, dict):
                return {k: convert_dict(v) for k, v in d.items()}
            elif isinstance(d, list):
                return [convert_dict(item) for item in d]
            else:
                return convert_numpy(d)
        
        clean_statistics = convert_dict(statistics)
        
        with open(statistics_file, 'w', encoding='utf-8') as f:
            json.dump(clean_statistics, f, ensure_ascii=False, indent=2)
        exported_files['statistics'] = str(statistics_file)
        logger.info(f"âœ… ç»Ÿè®¡ç»“æœ: {statistics_file}")
        
        # 3. åˆ›å»ºå¯è¯»çš„æ‘˜è¦æŠ¥å‘Š
        summary_file = output_path / "policy_impact_report.md"
        create_summary_report(comparison_df, statistics, summary_file)
        exported_files['report'] = str(summary_file)
        logger.info(f"âœ… åˆ†ææŠ¥å‘Š: {summary_file}")
        
    except Exception as e:
        logger.error(f"âŒ å¯¼å‡ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        
    return exported_files

def create_summary_report(comparison_df: pd.DataFrame, 
                        statistics: Dict[str, Any],
                        output_file: Path) -> None:
    """åˆ›å»ºå¯è¯»çš„Markdownæ ¼å¼æ‘˜è¦æŠ¥å‘Š"""
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# ç¾å›½èƒ½æºç‹¬ç«‹æ”¿ç­–å½±å“åˆ†ææŠ¥å‘Š\n\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        f.write("## åˆ†ææ¦‚è¦\n\n")
        f.write("æœ¬æŠ¥å‘Šé‡‡ç”¨\"äº‹å‰-äº‹å\"å¯¹æ¯”åˆ†ææ–¹æ³•ï¼Œè¯„ä¼°ç¾å›½èƒ½æºç‹¬ç«‹æ”¿ç­–å¯¹å…¨çƒèƒ½æºè´¸æ˜“ç½‘ç»œçš„å½±å“ã€‚\n\n")
        
        f.write("### æ—¶é—´çª—å£åˆ’åˆ†\n\n")
        f.write("- **äº‹å‰æœŸ (Pre-Period)**: 2001-2008å¹´ - åŸºå‡†æœŸ\n")
        f.write("- **è½¬å‹æœŸ (Transition)**: 2009-2015å¹´ - é¡µå²©æ²¹é©å‘½åŠ é€ŸæœŸ\n")
        f.write("- **äº‹åæœŸ (Post-Period)**: 2016-2024å¹´ - ç¾å›½æˆä¸ºèƒ½æºå‡ºå£å›½\n\n")
        
        f.write("## ä¸»è¦å‘ç°\n\n")
        
        # æ˜¾è‘—æ€§æ£€éªŒç»“æœ
        if 'significance_tests' in statistics:
            f.write("### ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ\n\n")
            f.write("| æŒ‡æ ‡ | tç»Ÿè®¡é‡ | på€¼ | æ˜¾è‘—æ€§ | æ ·æœ¬é‡ |\n")
            f.write("|------|---------|-----|--------|--------|\n")
            
            for metric, test_result in statistics['significance_tests'].items():
                significance = "âœ… æ˜¾è‘—" if test_result['is_significant'] else "âŒ ä¸æ˜¾è‘—"
                f.write(f"| {metric} | {test_result['t_statistic']:.3f} | {test_result['p_value']:.3f} | {significance} | {test_result['sample_size']} |\n")
            f.write("\n")
        
        # åŸºæœ¬ç»Ÿè®¡æ‘˜è¦
        if 'summary' in statistics:
            f.write("### æ•´ä½“å˜åŒ–è¶‹åŠ¿\n\n")
            f.write("| æŒ‡æ ‡ | å¹³å‡å˜åŒ– | ä¸­ä½å˜åŒ– | å¹³å‡å˜åŒ–ç‡ | ä¸Šå‡å›½å®¶æ•° | ä¸‹é™å›½å®¶æ•° |\n")
            f.write("|------|----------|----------|------------|------------|------------|\n")
            
            for metric, summary in statistics['summary'].items():
                f.write(f"| {metric} | {summary['mean_change']:.4f} | {summary['median_change']:.4f} | {summary['mean_pct_change']:.2f}% | {summary['countries_increased']} | {summary['countries_decreased']} |\n")
            f.write("\n")
        
        f.write("## åˆ†æç»“è®º\n\n")
        f.write("1. **æ”¿ç­–å†²å‡»æ•ˆåº”**: é€šè¿‡ç»Ÿè®¡æ£€éªŒå¯ä»¥è¯†åˆ«å‡ºå…·æœ‰æ˜¾è‘—å½±å“çš„ç½‘ç»œæŒ‡æ ‡\n")
        f.write("2. **ç»“æ„æ€§å˜åŒ–**: ç½‘ç»œä¸­å¿ƒæ€§æŒ‡æ ‡çš„å˜åŒ–åæ˜ äº†å…¨çƒèƒ½æºè´¸æ˜“æ ¼å±€çš„é‡æ„\n")
        f.write("3. **å›½å®¶å·®å¼‚åŒ–å½±å“**: ä¸åŒå›½å®¶åœ¨æ”¿ç­–å†²å‡»ä¸‹è¡¨ç°å‡ºä¸åŒçš„é€‚åº”æ€§å’Œå—å½±å“ç¨‹åº¦\n\n")
        
        f.write("## æ–¹æ³•è®ºè¯´æ˜\n\n")
        f.write("- **åˆ†ææ–¹æ³•**: äº‹å‰-äº‹åå¯¹æ¯”åˆ†æ (Pre-Post Comparison)\n")
        f.write("- **ç»Ÿè®¡æ£€éªŒ**: é…å¯¹tæ£€éªŒ (Paired t-test)\n")
        f.write("- **æ˜¾è‘—æ€§æ°´å¹³**: Î± = 0.05\n")
        f.write("- **æ•°æ®æ¥æº**: UN Comtradeå…¨çƒè´¸æ˜“æ•°æ®åº“\n")
        f.write("- **äº§å“èŒƒå›´**: èƒ½æºäº§å“ (HSç¼–ç : 2701, 2709, 2710, 2711)\n\n")

# ä¾¿æ·å‡½æ•°
def quick_policy_analysis(filepath: str = "outputs/tables/all_metrics.csv",
                        countries: List[str] = None,
                        metrics: List[str] = None) -> Tuple[pd.DataFrame, Dict[str, Any]]:
    """
    å¿«é€Ÿæ‰§è¡Œå®Œæ•´çš„æ”¿ç­–å½±å“åˆ†æ
    
    Args:
        filepath: æ•°æ®æ–‡ä»¶è·¯å¾„
        countries: å…³æ³¨çš„å›½å®¶åˆ—è¡¨
        metrics: å…³æ³¨çš„æŒ‡æ ‡åˆ—è¡¨
        
    Returns:
        (å¯¹æ¯”åˆ†æç»“æœ, ç»Ÿè®¡ç»“æœ)
    """
    logger.info("ğŸš€ å¼€å§‹å¿«é€Ÿæ”¿ç­–å½±å“åˆ†æ...")
    
    # åŠ è½½æ•°æ®
    df = load_and_prepare_data(filepath)
    
    # å¯¹æ¯”åˆ†æ
    comparison_df = run_pre_post_analysis(df, countries, metrics)
    
    # ç»Ÿè®¡åˆ†æ
    statistics = calculate_policy_impact_statistics(df, comparison_df, metrics)
    
    # å¯¼å‡ºç»“æœ
    export_analysis_results(comparison_df, statistics)
    
    logger.info("âœ… å¿«é€Ÿåˆ†æå®Œæˆ")
    
    return comparison_df, statistics