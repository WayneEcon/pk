#!/usr/bin/env python3
"""
DLIæŒ‡æ ‡è®¡ç®—æ¨¡å— (DLI Calculator Module)
==========================================

æœ¬æ¨¡å—å®ç°åŠ¨æ€é”å®šæŒ‡æ•°(Dynamic Locking Index)çš„æ ¸å¿ƒè®¡ç®—ç®—æ³•ã€‚
DLIé€šè¿‡å››ä¸ªç»´åº¦é‡åŒ–å›½å®¶é—´èƒ½æºè´¸æ˜“å…³ç³»çš„è·¯å¾„ä¾èµ–å’Œè½¬æ¢æˆæœ¬ï¼š

1. è´¸æ˜“æŒç»­æ€§ (Continuity): è¡¡é‡å…³ç³»çš„é•¿æœŸæ€§
2. åŸºç¡€è®¾æ–½å¼ºåº¦ (Infrastructure): è¡¡é‡ä¸“ç”¨æ€§èµ„äº§å¯¼è‡´çš„é”å®š
3. è´¸æ˜“ç¨³å®šæ€§ (Stability): è¡¡é‡å…³ç³»çš„å¯é æ€§
4. å¸‚åœºé”å®šåŠ› (Market Locking Power): è¡¡é‡å¸‚åœºç»“æ„å¯¼è‡´çš„é”å®šæ•ˆåº”

æœ€ç»ˆé€šè¿‡ä¸»æˆåˆ†åˆ†æ(PCA)ç¡®å®šæƒé‡ï¼ŒåˆæˆDLIæ€»åˆ†ã€‚

ä½œè€…ï¼šEnergy Network Analysis Team
"""

import pandas as pd
import numpy as np
from pathlib import Path
import logging
from typing import Dict, List, Tuple, Optional, Union
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def calculate_continuity(df: pd.DataFrame) -> pd.DataFrame:
    """
    è®¡ç®—è´¸æ˜“æŒç»­æ€§æŒ‡æ ‡ (Continuity)
    
    å…¬å¼: Continuity_ijt = (ä»2001å¹´åˆ°tå¹´å­˜åœ¨è´¸æ˜“çš„å¹´æ•°) / (t - 2001 + 1)
    
    è§£é‡Š: è¡¡é‡ç¾å›½ä¸ä¼™ä¼´å›½jåœ¨èƒ½æºäº§å“iä¸Šçš„è´¸æ˜“å…³ç³»æŒç»­æ€§ã€‚
    å€¼è¶Šæ¥è¿‘1ï¼Œè¡¨ç¤ºè´¸æ˜“å…³ç³»è¶Šç¨³å®šæŒç»­ï¼›å€¼è¶Šæ¥è¿‘0ï¼Œè¡¨ç¤ºè´¸æ˜“å…³ç³»è¶Šä¸ç¨³å®šã€‚
    
    Args:
        df: åŒ…å«ç¾å›½è´¸æ˜“æ•°æ®çš„DataFrame
        å¿…é¡»åŒ…å«åˆ—: year, us_partner, energy_product, trade_value_usd
        
    Returns:
        æ·»åŠ äº†continuityåˆ—çš„DataFrame
        
    ç¤ºä¾‹:
        å¦‚æœç¾å›½ä¸åŠ æ‹¿å¤§çš„åŸæ²¹è´¸æ˜“åœ¨2001-2010å¹´é—´æœ‰8å¹´å­˜åœ¨è´¸æ˜“ï¼Œ
        é‚£ä¹ˆ2010å¹´çš„æŒç»­æ€§ = 8 / (2010-2001+1) = 8/10 = 0.8
    """
    
    logger.info("ğŸ”„ å¼€å§‹è®¡ç®—è´¸æ˜“æŒç»­æ€§æŒ‡æ ‡...")
    
    df_continuity = df.copy()
    
    # æŒ‰ä¼™ä¼´å›½å’Œèƒ½æºäº§å“åˆ†ç»„è®¡ç®—æŒç»­æ€§
    continuity_results = []
    
    # è·å–æ‰€æœ‰uniqueç»„åˆï¼ˆå¿…é¡»åŒ…å«us_roleä»¥åŒºåˆ†è¿›å‡ºå£ï¼‰
    if 'us_role' in df_continuity.columns:
        groups = df_continuity.groupby(['us_partner', 'energy_product', 'us_role'])
    else:
        logger.warning("ç¼ºå°‘us_roleå­—æ®µï¼Œå°†æŒ‰å›½å®¶-äº§å“ç»„åˆè®¡ç®—æŒç»­æ€§ï¼ˆå¯èƒ½æ··åˆè¿›å‡ºå£æ•°æ®ï¼‰")
        groups = df_continuity.groupby(['us_partner', 'energy_product'])
    
    for group_key, group_data in groups:
        # è§£åŒ…ç»„åˆé”®
        if 'us_role' in df_continuity.columns:
            partner, product, us_role = group_key
        else:
            partner, product = group_key
            us_role = None
            
        # è·å–è¯¥ç»„åˆçš„æ‰€æœ‰å¹´ä»½
        trade_years = set(group_data['year'].unique())
        
        # ä¸ºæ¯ä¸€å¹´è®¡ç®—æŒç»­æ€§
        for year in trade_years:
            # è®¡ç®—ä»2001å¹´åˆ°å½“å‰å¹´ä»½åº”æœ‰çš„å¹´æ•°
            total_possible_years = year - 2001 + 1
            
            # è®¡ç®—ä»2001å¹´åˆ°å½“å‰å¹´ä»½å®é™…å­˜åœ¨è´¸æ˜“çš„å¹´æ•°
            actual_trade_years = len([y for y in trade_years if 2001 <= y <= year])
            
            # è®¡ç®—æŒç»­æ€§
            continuity = actual_trade_years / total_possible_years if total_possible_years > 0 else 0
            
            result_record = {
                'year': year,
                'us_partner': partner,
                'energy_product': product,
                'continuity': continuity,
                'actual_trade_years': actual_trade_years,
                'total_possible_years': total_possible_years
            }
            
            if us_role is not None:
                result_record['us_role'] = us_role
                
            continuity_results.append(result_record)
    
    # è½¬æ¢ä¸ºDataFrame
    continuity_df = pd.DataFrame(continuity_results)
    
    # ä¸åŸæ•°æ®åˆå¹¶ï¼ˆç¡®ä¿åŒ…å«us_roleå­—æ®µé¿å…è¿›å‡ºå£æ•°æ®æ··æ·†ï¼‰
    merge_keys = ['year', 'us_partner', 'energy_product']
    if 'us_role' in df_continuity.columns:
        merge_keys.append('us_role')
    
    df_with_continuity = pd.merge(
        df_continuity, 
        continuity_df[merge_keys + ['continuity']], 
        on=merge_keys, 
        how='left'
    )
    
    # æ•°æ®éªŒè¯
    assert df_with_continuity['continuity'].isnull().sum() == 0, "æŒç»­æ€§æŒ‡æ ‡è®¡ç®—ä¸­å­˜åœ¨ç¼ºå¤±å€¼"
    assert (df_with_continuity['continuity'] >= 0).all() and (df_with_continuity['continuity'] <= 1).all(), "æŒç»­æ€§æŒ‡æ ‡å€¼è¶…å‡º[0,1]èŒƒå›´"
    
    # ç»Ÿè®¡æ‘˜è¦
    logger.info(f"ğŸ“Š è´¸æ˜“æŒç»­æ€§ç»Ÿè®¡:")
    logger.info(f"  å¹³å‡æŒç»­æ€§: {df_with_continuity['continuity'].mean():.3f}")
    logger.info(f"  ä¸­ä½æ•°æŒç»­æ€§: {df_with_continuity['continuity'].median():.3f}")
    logger.info(f"  æœ€é«˜æŒç»­æ€§: {df_with_continuity['continuity'].max():.3f}")
    logger.info(f"  æœ€ä½æŒç»­æ€§: {df_with_continuity['continuity'].min():.3f}")
    logger.info(f"  å®Œå…¨æŒç»­å…³ç³»(=1): {(df_with_continuity['continuity'] == 1).sum()} æ¡è®°å½•")
    
    logger.info("âœ… è´¸æ˜“æŒç»­æ€§æŒ‡æ ‡è®¡ç®—å®Œæˆ!")
    return df_with_continuity

def calculate_infrastructure(df: pd.DataFrame) -> pd.DataFrame:
    """
    è®¡ç®—åŸºç¡€è®¾æ–½å¼ºåº¦æŒ‡æ ‡ (Infrastructure)
    
    å…¬å¼: Infrastructure_ijt = log(Trade_Volume_ijt / Distance_ij + 1)
    
    æ–¹æ³•è®ºè¯´æ˜:
    ç›®æ ‡: è¡¡é‡ç”±é«˜æ²‰æ²¡æˆæœ¬çš„ä¸“ç”¨æ€§èµ„äº§ï¼ˆå¦‚ç®¡é“ã€ä¸“ç”¨æ¸¯å£ï¼‰å¯¼è‡´çš„é”å®šã€‚
    æŒ‘æˆ˜: è¿™äº›èµ„äº§çš„ä»·å€¼æ˜¯ä¸å¯è§‚æµ‹çš„ã€‚
    è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨ä»£ç†å˜é‡ã€‚ç»æµå­¦é€»è¾‘æ˜¯ï¼šåªæœ‰åœ¨åœ°ç†è·ç¦»è¿‘ä¸”è´¸æ˜“é‡å·¨å¤§çš„æƒ…å†µä¸‹ï¼Œ
    æŠ•èµ„æ˜‚è´µçš„ã€ä¸å¯ç§»åŠ¨çš„ä¸“ç”¨æ€§åŸºç¡€è®¾æ–½æ‰å…·æœ‰ç»æµåˆç†æ€§ã€‚
    å› æ­¤ï¼Œè´¸æ˜“é¢/è·ç¦» è¿™ä¸ªæ¯”å€¼ï¼Œå¯ä»¥ä½œä¸ºè¡¡é‡è¿™ç§"åŸºç¡€è®¾æ–½ç»‘å®š"å¼ºåº¦çš„æœ‰æ•ˆä»£ç†ã€‚
    
    Args:
        df: åŒ…å«ç¾å›½è´¸æ˜“æ•°æ®çš„DataFrame
        å¿…é¡»åŒ…å«åˆ—: trade_value_usd, distance_km
        
    Returns:
        æ·»åŠ äº†infrastructureåˆ—çš„DataFrame
        
    ç¤ºä¾‹:
        ç¾å›½ä¸åŠ æ‹¿å¤§åŸæ²¹è´¸æ˜“é¢1000ä¸‡ç¾å…ƒï¼Œè·ç¦»735å…¬é‡Œ
        Infrastructure = log(10000000 / 735 + 1) = log(13606 + 1) = log(13607) â‰ˆ 9.52
    """
    
    logger.info("ğŸ—ï¸ å¼€å§‹è®¡ç®—åŸºç¡€è®¾æ–½å¼ºåº¦æŒ‡æ ‡...")
    
    df_infrastructure = df.copy()
    
    # æ•°æ®éªŒè¯
    assert 'trade_value_usd' in df_infrastructure.columns, "ç¼ºå°‘trade_value_usdåˆ—"
    assert 'distance_km' in df_infrastructure.columns, "ç¼ºå°‘distance_kmåˆ—"
    assert (df_infrastructure['trade_value_usd'] > 0).all(), "è´¸æ˜“å€¼å¿…é¡»å¤§äº0"
    assert (df_infrastructure['distance_km'] > 0).all(), "è·ç¦»å¿…é¡»å¤§äº0"
    
    # è®¡ç®—åŸºç¡€è®¾æ–½å¼ºåº¦
    # ä½¿ç”¨+1é¿å…log(0)çš„æƒ…å†µï¼Œè™½ç„¶åœ¨æˆ‘ä»¬çš„æ•°æ®ä¸­ä¸å¤ªå¯èƒ½å‡ºç°
    df_infrastructure['trade_distance_ratio'] = df_infrastructure['trade_value_usd'] / df_infrastructure['distance_km']
    df_infrastructure['infrastructure'] = np.log(df_infrastructure['trade_distance_ratio'] + 1)
    
    # æ•°æ®éªŒè¯
    assert df_infrastructure['infrastructure'].isnull().sum() == 0, "åŸºç¡€è®¾æ–½æŒ‡æ ‡è®¡ç®—ä¸­å­˜åœ¨ç¼ºå¤±å€¼"
    assert (df_infrastructure['infrastructure'] >= 0).all(), "åŸºç¡€è®¾æ–½æŒ‡æ ‡å€¼ä¸èƒ½ä¸ºè´Ÿ"
    
    # ç»Ÿè®¡æ‘˜è¦
    logger.info(f"ğŸ“Š åŸºç¡€è®¾æ–½å¼ºåº¦ç»Ÿè®¡:")
    logger.info(f"  å¹³å‡å¼ºåº¦: {df_infrastructure['infrastructure'].mean():.3f}")
    logger.info(f"  ä¸­ä½æ•°å¼ºåº¦: {df_infrastructure['infrastructure'].median():.3f}")
    logger.info(f"  æœ€é«˜å¼ºåº¦: {df_infrastructure['infrastructure'].max():.3f}")
    logger.info(f"  æœ€ä½å¼ºåº¦: {df_infrastructure['infrastructure'].min():.3f}")
    logger.info(f"  æ ‡å‡†å·®: {df_infrastructure['infrastructure'].std():.3f}")
    
    # æŒ‰è·ç¦»åŒºé—´åˆ†æ
    if 'distance_category' in df_infrastructure.columns:
        distance_infra_stats = df_infrastructure.groupby('distance_category')['infrastructure'].agg(['mean', 'std', 'count'])
        logger.info(f"  æŒ‰è·ç¦»åŒºé—´çš„åŸºç¡€è®¾æ–½å¼ºåº¦:")
        for category, stats in distance_infra_stats.iterrows():
            logger.info(f"    {category}: å‡å€¼={stats['mean']:.3f}, æ ‡å‡†å·®={stats['std']:.3f}, è®°å½•æ•°={stats['count']}")
    
    logger.info("âœ… åŸºç¡€è®¾æ–½å¼ºåº¦æŒ‡æ ‡è®¡ç®—å®Œæˆ!")
    return df_infrastructure

def calculate_stability(df: pd.DataFrame, window_years: int = 5) -> pd.DataFrame:
    """
    è®¡ç®—è´¸æ˜“ç¨³å®šæ€§æŒ‡æ ‡ (Stability)
    
    å…¬å¼: Stability_ijt = 1 / (CV_ijt + 0.1)
    å…¶ä¸­ CV_ijt æ˜¯ä¼™ä¼´jåœ¨äº§å“iä¸Šè¿‡å»window_yearså¹´è´¸æ˜“é¢çš„å˜å¼‚ç³»æ•° (æ ‡å‡†å·®/å¹³å‡å€¼)
    
    è§£é‡Š: è¡¡é‡å…³ç³»çš„å¯é æ€§ï¼Œæ³¢åŠ¨è¶Šå°ï¼Œé”å®šè¶Šå¼ºã€‚
    å˜å¼‚ç³»æ•°è¶Šå°ï¼Œç¨³å®šæ€§æŒ‡æ ‡è¶Šå¤§ï¼Œè¡¨ç¤ºè´¸æ˜“å…³ç³»è¶Šç¨³å®šã€‚
    
    Args:
        df: åŒ…å«ç¾å›½è´¸æ˜“æ•°æ®çš„DataFrame
        window_years: è®¡ç®—ç¨³å®šæ€§çš„æ»‘åŠ¨çª—å£å¹´æ•°ï¼Œé»˜è®¤ä¸º5å¹´
        
    Returns:
        æ·»åŠ äº†stabilityåˆ—çš„DataFrame
        
    ç¤ºä¾‹:
        å¦‚æœæŸå›½æŸäº§å“è¿‡å»5å¹´è´¸æ˜“é¢æ ‡å‡†å·®ä¸º1000ä¸‡ï¼Œå¹³å‡å€¼ä¸º5000ä¸‡
        CV = 1000/5000 = 0.2
        Stability = 1 / (0.2 + 0.1) = 1 / 0.3 = 3.33
    """
    
    logger.info(f"ğŸ“ˆ å¼€å§‹è®¡ç®—è´¸æ˜“ç¨³å®šæ€§æŒ‡æ ‡ (çª—å£æœŸ={window_years}å¹´)...")
    
    df_stability = df.copy()
    
    # æŒ‰ä¼™ä¼´å›½ã€èƒ½æºäº§å“å’Œè´¸æ˜“è§’è‰²åˆ†ç»„ï¼Œè®¡ç®—æ¯å¹´çš„ç¨³å®šæ€§
    stability_results = []
    
    if 'us_role' in df_stability.columns:
        groups = df_stability.groupby(['us_partner', 'energy_product', 'us_role'])
    else:
        logger.warning("ç¼ºå°‘us_roleå­—æ®µï¼Œå°†æŒ‰å›½å®¶-äº§å“ç»„åˆè®¡ç®—ç¨³å®šæ€§ï¼ˆå¯èƒ½æ··åˆè¿›å‡ºå£æ•°æ®ï¼‰")
        groups = df_stability.groupby(['us_partner', 'energy_product'])
    
    for group_key, group_data in groups:
        # è§£åŒ…ç»„åˆé”®
        if 'us_role' in df_stability.columns:
            partner, product, us_role = group_key
        else:
            partner, product = group_key
            us_role = None
        # æŒ‰å¹´ä»½æ’åº
        group_data = group_data.sort_values('year')
        
        # èšåˆæ¯å¹´çš„è´¸æ˜“é¢ï¼ˆå› ä¸ºå¯èƒ½æœ‰è¿›å£å’Œå‡ºå£ï¼‰
        yearly_trade = group_data.groupby('year')['trade_value_usd'].sum().reset_index()
        
        # ä¸ºæ¯ä¸€å¹´è®¡ç®—ç¨³å®šæ€§
        for i, row in yearly_trade.iterrows():
            current_year = row['year']
            
            # è·å–è¿‡å»window_yearså¹´çš„å†å²æ•°æ®ï¼ˆä¸åŒ…æ‹¬å½“å‰å¹´ï¼Œé¿å…å‰è§†åè¯¯ï¼‰
            start_year = current_year - window_years
            window_data = yearly_trade[
                (yearly_trade['year'] >= start_year) & 
                (yearly_trade['year'] < current_year)  # ä¸¥æ ¼å°äºå½“å‰å¹´
            ]
            
            if len(window_data) >= 3:  # è‡³å°‘éœ€è¦3ä¸ªå†å²è§‚æµ‹å€¼æ‰å¯é 
                trade_values = window_data['trade_value_usd'].values
                
                # è®¡ç®—å˜å¼‚ç³»æ•° (CV = std / mean)
                mean_trade = np.mean(trade_values)
                std_trade = np.std(trade_values)
                
                if mean_trade > 0:
                    cv = std_trade / mean_trade
                    stability = 1 / (cv + 0.1)  # åŠ 0.1é¿å…åˆ†æ¯ä¸º0
                else:
                    # å‡å€¼ä¸º0è¡¨ç¤ºæ•°æ®è´¨é‡é—®é¢˜ï¼Œæ ‡è®°ä¸ºç¼ºå¤±
                    stability = np.nan
                    cv = np.nan
                
                result_record = {
                    'year': current_year,
                    'us_partner': partner,
                    'energy_product': product,
                    'stability': stability,
                    'cv': cv,
                    'window_years_used': len(window_data),
                    'mean_trade_value': mean_trade,
                    'std_trade_value': std_trade
                }
                
                if us_role is not None:
                    result_record['us_role'] = us_role
                    
                stability_results.append(result_record)
            elif len(window_data) == 2:
                # å†å²æ•°æ®ä¸è¶³ä½†æœ‰ä¸€äº›ä¿¡æ¯ï¼Œç»™äºˆä¸­ç­‰ç¨³å®šæ€§è¯„åˆ†
                result_record = {
                    'year': current_year,
                    'us_partner': partner,
                    'energy_product': product,
                    'stability': 5.0,  # ä¸­ç­‰æ°´å¹³ç¨³å®šæ€§
                    'cv': np.nan,
                    'window_years_used': len(window_data),
                    'mean_trade_value': np.mean(window_data['trade_value_usd'].values),
                    'std_trade_value': np.std(window_data['trade_value_usd'].values)
                }
                
                if us_role is not None:
                    result_record['us_role'] = us_role
                    
                stability_results.append(result_record)
            else:
                # å†å²æ•°æ®ä¸¥é‡ä¸è¶³ï¼Œæ ‡è®°ä¸ºç¼ºå¤±å€¼ä½†è®°å½•å½“å‰å¹´ä¿¡æ¯
                result_record = {
                    'year': current_year,
                    'us_partner': partner,
                    'energy_product': product,
                    'stability': np.nan,  # æ•°æ®ä¸è¶³ï¼Œæ ‡è®°ä¸ºç¼ºå¤±
                    'cv': np.nan,
                    'window_years_used': len(window_data),
                    'mean_trade_value': row['trade_value_usd'],
                    'std_trade_value': 0
                }
                
                if us_role is not None:
                    result_record['us_role'] = us_role
                    
                stability_results.append(result_record)
    
    # è½¬æ¢ä¸ºDataFrame
    stability_df = pd.DataFrame(stability_results)
    
    # ä¸åŸæ•°æ®åˆå¹¶ï¼ˆç¡®ä¿åŒ…å«us_roleå­—æ®µé¿å…è¿›å‡ºå£æ•°æ®æ··æ·†ï¼‰
    merge_keys = ['year', 'us_partner', 'energy_product']
    if 'us_role' in df_stability.columns:
        merge_keys.append('us_role')
        
    df_with_stability = pd.merge(
        df_stability, 
        stability_df[merge_keys + ['stability']], 
        on=merge_keys, 
        how='left'
    )
    
    # å¤„ç†ç¼ºå¤±å€¼ï¼šå¯¹äºå†å²æ•°æ®ä¸è¶³çš„æƒ…å†µï¼Œä½¿ç”¨å…¨å±€å¹³å‡ç¨³å®šæ€§
    missing_stability_count = df_with_stability['stability'].isnull().sum()
    if missing_stability_count > 0:
        logger.warning(f"å‘ç° {missing_stability_count} æ¡ç¨³å®šæ€§æŒ‡æ ‡ç¼ºå¤±å€¼ï¼Œå°†ä½¿ç”¨å…¨å±€å‡å€¼å¡«å……")
        global_mean_stability = df_with_stability['stability'].mean()
        df_with_stability['stability'] = df_with_stability['stability'].fillna(global_mean_stability)
    
    # æ•°æ®éªŒè¯ï¼ˆä¿®æ”¹åçš„éªŒè¯é€»è¾‘ï¼‰
    assert df_with_stability['stability'].isnull().sum() == 0, "ç¨³å®šæ€§æŒ‡æ ‡è®¡ç®—ä¸­ä»å­˜åœ¨ç¼ºå¤±å€¼"
    valid_stability = df_with_stability['stability'][df_with_stability['stability'].notna()]
    if len(valid_stability) > 0:
        assert (valid_stability > 0).all(), "ç¨³å®šæ€§æŒ‡æ ‡å€¼å¿…é¡»å¤§äº0"
    
    # ç»Ÿè®¡æ‘˜è¦
    logger.info(f"ğŸ“Š è´¸æ˜“ç¨³å®šæ€§ç»Ÿè®¡:")
    logger.info(f"  å¹³å‡ç¨³å®šæ€§: {df_with_stability['stability'].mean():.3f}")
    logger.info(f"  ä¸­ä½æ•°ç¨³å®šæ€§: {df_with_stability['stability'].median():.3f}")
    logger.info(f"  æœ€é«˜ç¨³å®šæ€§: {df_with_stability['stability'].max():.3f}")
    logger.info(f"  æœ€ä½ç¨³å®šæ€§: {df_with_stability['stability'].min():.3f}")
    logger.info(f"  æ ‡å‡†å·®: {df_with_stability['stability'].std():.3f}")
    
    # æŒ‰äº§å“åˆ†æç¨³å®šæ€§
    product_stability = df_with_stability.groupby('energy_product')['stability'].agg(['mean', 'std', 'count'])
    logger.info(f"  æŒ‰èƒ½æºäº§å“çš„ç¨³å®šæ€§:")
    for product, stats in product_stability.iterrows():
        logger.info(f"    {product}: å‡å€¼={stats['mean']:.3f}, æ ‡å‡†å·®={stats['std']:.3f}, è®°å½•æ•°={stats['count']}")
    
    logger.info("âœ… è´¸æ˜“ç¨³å®šæ€§æŒ‡æ ‡è®¡ç®—å®Œæˆ!")
    return df_with_stability

def calculate_market_locking_power(df: pd.DataFrame) -> pd.DataFrame:
    """
    è®¡ç®—å¸‚åœºé”å®šåŠ›æŒ‡æ ‡ (Market Locking Power)
    
    å…¬å¼: Market_Locking_Power_ijt = HHI_it * share_ijt
    
    è§£é‡Š: æ­¤æŒ‡æ ‡ç›´æ¥è¡¡é‡å¸‚åœºç»“æ„å¯¼è‡´çš„é”å®šæ•ˆåº”ã€‚
    ç¾å›½åœ¨æŸäº§å“iä¸Šçš„ä¾›åº”å•†å¸‚åœºè¶Šé›†ä¸­ï¼ˆèµ«èŠ¬è¾¾å°”-èµ«å¸Œæ›¼æŒ‡æ•°HHI_itè¶Šé«˜ï¼‰ï¼Œ
    ä¸”å½“å‰ä¼™ä¼´jçš„è´¸æ˜“ä»½é¢(share_ijt)è¶Šé«˜ï¼Œæ„å‘³ç€æ›¿æ¢è¯¥ä¼™ä¼´çš„éš¾åº¦è¶Šå¤§ï¼Œ
    å› æ­¤å…¶å¸‚åœºé”å®šåŠ›è¶Šå¼ºã€‚
    
    Args:
        df: åŒ…å«ç¾å›½è´¸æ˜“æ•°æ®çš„DataFrame
        å¿…é¡»åŒ…å«åˆ—: year, us_partner, energy_product, trade_value_usd, us_role
        
    Returns:
        æ·»åŠ äº†market_locking_poweråˆ—çš„DataFrame
        
    è®¡ç®—æ­¥éª¤:
        1. æŒ‰å¹´ä»½å’Œäº§å“åˆ†ç»„è®¡ç®—HHIï¼ˆåŸºäºè¿›å£ä»½é¢ï¼‰
        2. è®¡ç®—æ¯ä¸ªä¼™ä¼´å›½åœ¨æ¯ç§äº§å“ä¸Šçš„å¸‚åœºä»½é¢
        3. å¸‚åœºé”å®šåŠ› = HHI Ã— å¸‚åœºä»½é¢
    """
    
    logger.info("ğŸ”’ å¼€å§‹è®¡ç®—å¸‚åœºé”å®šåŠ›æŒ‡æ ‡...")
    
    df_locking = df.copy()
    
    # åªè€ƒè™‘ç¾å›½ä½œä¸ºè¿›å£æ–¹çš„æ•°æ®æ¥è®¡ç®—ä¾›åº”å•†é›†ä¸­åº¦
    import_data = df_locking[df_locking['us_role'] == 'importer'].copy()
    
    if len(import_data) == 0:
        logger.warning("æ²¡æœ‰æ‰¾åˆ°ç¾å›½è¿›å£æ•°æ®ï¼Œå¸‚åœºé”å®šåŠ›å°†è®¾ä¸º0")
        df_locking['market_locking_power'] = 0
        return df_locking
    
    locking_results = []
    
    # æŒ‰å¹´ä»½å’Œäº§å“è®¡ç®—HHIå’Œå¸‚åœºä»½é¢
    for year in import_data['year'].unique():
        year_data = import_data[import_data['year'] == year]
        
        for product in year_data['energy_product'].unique():
            product_data = year_data[year_data['energy_product'] == product]
            
            # è®¡ç®—æ€»è¿›å£é¢
            total_import = product_data['trade_value_usd'].sum()
            
            if total_import > 0:
                # è®¡ç®—æ¯ä¸ªä¾›åº”å•†çš„å¸‚åœºä»½é¢
                supplier_shares = product_data.groupby('us_partner')['trade_value_usd'].sum() / total_import
                
                # è®¡ç®—HHI (Herfindahl-Hirschman Index)
                # HHI = Î£(market_share_i)^2
                hhi = (supplier_shares ** 2).sum()
                
                # ä¸ºæ¯ä¸ªä¾›åº”å•†è®¡ç®—å¸‚åœºé”å®šåŠ›
                for partner, share in supplier_shares.items():
                    market_locking_power = hhi * share
                    
                    locking_results.append({
                        'year': year,
                        'us_partner': partner,
                        'energy_product': product,
                        'us_role': 'importer',
                        'market_locking_power': market_locking_power,
                        'market_share': share,
                        'hhi': hhi,
                        'total_suppliers': len(supplier_shares)
                    })
    
    # è½¬æ¢ä¸ºDataFrame
    locking_df = pd.DataFrame(locking_results)
    
    # è®¡ç®—å‡ºå£æ•°æ®çš„ä¹°æ–¹é›†ä¸­åº¦ï¼ˆæ”¹è¿›çš„åŒå‘è®¡ç®—ï¼‰
    export_data = df_locking[df_locking['us_role'] == 'exporter'].copy()
    export_locking_results = []
    
    if len(export_data) > 0:
        logger.info("è®¡ç®—ç¾å›½å‡ºå£çš„ä¹°æ–¹é›†ä¸­åº¦...")
        
        # æŒ‰å¹´ä»½å’Œäº§å“è®¡ç®—ä¹°æ–¹HHIå’Œé”å®šåŠ›
        for year in export_data['year'].unique():
            year_data = export_data[export_data['year'] == year]
            
            for product in year_data['energy_product'].unique():
                product_data = year_data[year_data['energy_product'] == product]
                
                # è®¡ç®—æ€»å‡ºå£é¢
                total_export = product_data['trade_value_usd'].sum()
                
                if total_export > 0:
                    # è®¡ç®—æ¯ä¸ªä¹°æ–¹çš„å¸‚åœºä»½é¢
                    buyer_shares = product_data.groupby('us_partner')['trade_value_usd'].sum() / total_export
                    
                    # è®¡ç®—ä¹°æ–¹HHI (Herfindahl-Hirschman Index)
                    buyer_hhi = (buyer_shares ** 2).sum()
                    
                    # ä¸ºæ¯ä¸ªä¹°æ–¹è®¡ç®—å¸‚åœºé”å®šåŠ›
                    for partner, share in buyer_shares.items():
                        buyer_locking_power = buyer_hhi * share
                        
                        export_locking_results.append({
                            'year': year,
                            'us_partner': partner,
                            'energy_product': product,
                            'us_role': 'exporter',
                            'market_locking_power': buyer_locking_power,
                            'market_share': share,
                            'hhi': buyer_hhi,
                            'total_buyers': len(buyer_shares)
                        })
        
        # è½¬æ¢ä¸ºDataFrame
        export_locking_df = pd.DataFrame(export_locking_results)
        
        # åˆå¹¶è¿›å£å’Œå‡ºå£çš„é”å®šåŠ›æ•°æ®
        if len(export_locking_df) > 0:
            all_locking = pd.concat([locking_df, export_locking_df], ignore_index=True)
        else:
            # å¦‚æœå‡ºå£é”å®šåŠ›è®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°åŸæ¥çš„ç®€å•å¤„ç†
            export_locking_simple = export_data[['year', 'us_partner', 'energy_product', 'us_role']].copy()
            export_locking_simple['market_locking_power'] = 0
            all_locking = pd.concat([locking_df, export_locking_simple], ignore_index=True)
    else:
        all_locking = locking_df
    
    # ä¸åŸæ•°æ®åˆå¹¶ï¼ˆå·²ç»åŒ…å«å®Œæ•´é”®å€¼åŒ…æ‹¬us_roleï¼‰
    df_with_locking = pd.merge(
        df_locking, 
        all_locking[['year', 'us_partner', 'energy_product', 'us_role', 'market_locking_power']], 
        on=['year', 'us_partner', 'energy_product', 'us_role'], 
        how='left'
    )
    
    # å¡«å……ç¼ºå¤±å€¼ä¸º0
    df_with_locking['market_locking_power'] = df_with_locking['market_locking_power'].fillna(0)
    
    # æ•°æ®éªŒè¯
    assert df_with_locking['market_locking_power'].isnull().sum() == 0, "å¸‚åœºé”å®šåŠ›æŒ‡æ ‡è®¡ç®—ä¸­å­˜åœ¨ç¼ºå¤±å€¼"
    assert (df_with_locking['market_locking_power'] >= 0).all(), "å¸‚åœºé”å®šåŠ›æŒ‡æ ‡å€¼ä¸èƒ½ä¸ºè´Ÿ"
    
    # ç»Ÿè®¡æ‘˜è¦
    logger.info(f"ğŸ“Š å¸‚åœºé”å®šåŠ›ç»Ÿè®¡:")
    logger.info(f"  å¹³å‡é”å®šåŠ›: {df_with_locking['market_locking_power'].mean():.4f}")
    logger.info(f"  ä¸­ä½æ•°é”å®šåŠ›: {df_with_locking['market_locking_power'].median():.4f}")
    logger.info(f"  æœ€é«˜é”å®šåŠ›: {df_with_locking['market_locking_power'].max():.4f}")
    logger.info(f"  æœ€ä½é”å®šåŠ›: {df_with_locking['market_locking_power'].min():.4f}")
    logger.info(f"  éé›¶é”å®šåŠ›è®°å½•: {(df_with_locking['market_locking_power'] > 0).sum()} æ¡")
    
    # æŒ‰äº§å“åˆ†æé”å®šåŠ›ï¼ˆä»…è¿›å£æ•°æ®ï¼‰
    if len(locking_df) > 0:
        product_locking = locking_df.groupby('energy_product').agg({
            'market_locking_power': ['mean', 'max'],
            'hhi': 'mean',
            'total_suppliers': 'mean'
        }).round(4)
        
        logger.info(f"  æŒ‰èƒ½æºäº§å“çš„å¸‚åœºé›†ä¸­åº¦:")
        for product in product_locking.index:
            stats = product_locking.loc[product]
            logger.info(f"    {product}: å¹³å‡HHI={stats[('hhi', 'mean')]:.4f}, " +
                       f"å¹³å‡é”å®šåŠ›={stats[('market_locking_power', 'mean')]:.4f}, " +
                       f"å¹³å‡ä¾›åº”å•†æ•°={stats[('total_suppliers', 'mean')]:.1f}")
    
    logger.info("âœ… å¸‚åœºé”å®šåŠ›æŒ‡æ ‡è®¡ç®—å®Œæˆ!")
    return df_with_locking

def calculate_dli_composite(df: pd.DataFrame, 
                           use_pca: bool = True, 
                           custom_weights: Dict[str, float] = None) -> pd.DataFrame:
    """
    è®¡ç®—DLIç»¼åˆæŒ‡æ ‡
    
    æ­¥éª¤:
    1. æ ‡å‡†åŒ–å››ä¸ªç»´åº¦çš„åˆ†å€¼ï¼ˆå‡å€¼=0ï¼Œæ ‡å‡†å·®=1ï¼‰
    2. ä½¿ç”¨PCAç¡®å®šæƒé‡ï¼ˆç¬¬ä¸€ä¸»æˆåˆ†çš„è½½è·ä½œä¸ºæƒé‡ï¼‰
    3. è®¡ç®—åŠ æƒç»¼åˆå¾—åˆ†
    
    Args:
        df: åŒ…å«å››ä¸ªDLIç»´åº¦çš„DataFrame
        use_pca: æ˜¯å¦ä½¿ç”¨PCAç¡®å®šæƒé‡ï¼ŒFalseåˆ™ä½¿ç”¨ç­‰æƒé‡æˆ–è‡ªå®šä¹‰æƒé‡
        custom_weights: è‡ªå®šä¹‰æƒé‡å­—å…¸ï¼Œå¦‚ {'continuity': 0.3, 'infrastructure': 0.3, ...}
        
    Returns:
        æ·»åŠ äº†dli_compositeåˆ—çš„DataFrame
        
    DLIå…¬å¼:
        DLI_ijt = w1 * Continuity_ijt + w2 * Infrastructure_ijt + w3 * Stability_ijt + w4 * Market_Locking_Power_ijt
        æƒé‡ç”±PCAç¬¬ä¸€ä¸»æˆåˆ†ç¡®å®š
    """
    
    logger.info("ğŸ¯ å¼€å§‹è®¡ç®—DLIç»¼åˆæŒ‡æ ‡...")
    
    df_composite = df.copy()
    
    # æ£€æŸ¥å¿…éœ€çš„åˆ—
    required_columns = ['continuity', 'infrastructure', 'stability', 'market_locking_power']
    missing_columns = [col for col in required_columns if col not in df_composite.columns]
    if missing_columns:
        raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„DLIç»´åº¦åˆ—: {missing_columns}")
    
    # æå–å››ä¸ªç»´åº¦çš„æ•°æ®
    dli_dimensions = df_composite[required_columns].copy()
    
    # æ•°æ®éªŒè¯ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼æˆ–å¼‚å¸¸å€¼
    logger.info("ğŸ” DLIç»´åº¦æ•°æ®è´¨é‡æ£€æŸ¥:")
    for col in required_columns:
        missing_count = dli_dimensions[col].isnull().sum()
        if missing_count > 0:
            logger.warning(f"  {col}: {missing_count} ä¸ªç¼ºå¤±å€¼")
        
        # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡
        stats = dli_dimensions[col].describe()
        logger.info(f"  {col}: å‡å€¼={stats['mean']:.4f}, æ ‡å‡†å·®={stats['std']:.4f}, " + 
                   f"èŒƒå›´=[{stats['min']:.4f}, {stats['max']:.4f}]")
    
    # å¤„ç†ç¼ºå¤±å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
    if dli_dimensions.isnull().any().any():
        logger.warning("å‘ç°ç¼ºå¤±å€¼ï¼Œå°†ä½¿ç”¨å„åˆ—å‡å€¼å¡«å……")
        dli_dimensions = dli_dimensions.fillna(dli_dimensions.mean())
    
    # ç¬¬1æ­¥ï¼šæ ‡å‡†åŒ–å¤„ç†
    logger.info("ğŸ“Š æ‰§è¡Œæ ‡å‡†åŒ–å¤„ç†...")
    scaler = StandardScaler()
    dli_standardized = scaler.fit_transform(dli_dimensions)
    dli_std_df = pd.DataFrame(dli_standardized, columns=required_columns, index=dli_dimensions.index)
    
    # æ˜¾ç¤ºæ ‡å‡†åŒ–åçš„ç»Ÿè®¡
    logger.info("æ ‡å‡†åŒ–åçš„æ•°æ®ç»Ÿè®¡:")
    for col in required_columns:
        mean_val = dli_std_df[col].mean()
        std_val = dli_std_df[col].std()
        logger.info(f"  {col}: å‡å€¼={mean_val:.6f}, æ ‡å‡†å·®={std_val:.6f}")
    
    # ç¬¬2æ­¥ï¼šç¡®å®šæƒé‡
    if use_pca and custom_weights is None:
        logger.info("ğŸ”¬ ä½¿ç”¨PCAç¡®å®šæƒé‡...")
        
        # æ‰§è¡Œä¸»æˆåˆ†åˆ†æ
        pca = PCA(n_components=4)
        pca_result = pca.fit_transform(dli_std_df)
        
        # è·å–ç¬¬ä¸€ä¸»æˆåˆ†çš„è½½è·ä½œä¸ºæƒé‡
        pc1_loadings = pca.components_[0]
        
        # ç¡®ä¿æƒé‡ä¸ºæ­£å€¼ï¼ˆå–ç»å¯¹å€¼ï¼‰å¹¶å½’ä¸€åŒ–
        weights = np.abs(pc1_loadings)
        weights = weights / weights.sum()
        
        weight_dict = dict(zip(required_columns, weights))
        
        # æ˜¾ç¤ºPCAç»“æœ
        logger.info(f"ğŸ“ˆ PCAåˆ†æç»“æœ:")
        logger.info(f"  ç¬¬ä¸€ä¸»æˆåˆ†è§£é‡Šæ–¹å·®æ¯”: {pca.explained_variance_ratio_[0]:.3f}")
        logger.info(f"  ç´¯è®¡è§£é‡Šæ–¹å·®æ¯”: {pca.explained_variance_ratio_[:2].sum():.3f} (å‰ä¸¤ä¸ªä¸»æˆåˆ†)")
        logger.info(f"  PCAç¡®å®šçš„æƒé‡:")
        for dim, weight in weight_dict.items():
            logger.info(f"    {dim}: {weight:.4f}")
            
    elif custom_weights is not None:
        logger.info("âš™ï¸ ä½¿ç”¨è‡ªå®šä¹‰æƒé‡...")
        
        # éªŒè¯è‡ªå®šä¹‰æƒé‡
        if set(custom_weights.keys()) != set(required_columns):
            raise ValueError(f"è‡ªå®šä¹‰æƒé‡å¿…é¡»åŒ…å«æ‰€æœ‰ç»´åº¦: {required_columns}")
        
        if abs(sum(custom_weights.values()) - 1.0) > 1e-6:
            logger.warning("è‡ªå®šä¹‰æƒé‡ä¹‹å’Œä¸ä¸º1ï¼Œå°†è¿›è¡Œå½’ä¸€åŒ–")
            total_weight = sum(custom_weights.values())
            custom_weights = {k: v/total_weight for k, v in custom_weights.items()}
        
        weight_dict = custom_weights
        logger.info(f"  è‡ªå®šä¹‰æƒé‡:")
        for dim, weight in weight_dict.items():
            logger.info(f"    {dim}: {weight:.4f}")
    
    else:
        logger.info("âš–ï¸ ä½¿ç”¨ç­‰æƒé‡...")
        weight_dict = {dim: 0.25 for dim in required_columns}
        logger.info(f"  ç­‰æƒé‡: æ¯ä¸ªç»´åº¦æƒé‡ = 0.25")
    
    # ç¬¬3æ­¥ï¼šè®¡ç®—åŠ æƒç»¼åˆå¾—åˆ†
    logger.info("ğŸ§® è®¡ç®—DLIç»¼åˆå¾—åˆ†...")
    
    dli_composite_score = np.zeros(len(dli_std_df))
    
    for dim, weight in weight_dict.items():
        dli_composite_score += weight * dli_std_df[dim].values
    
    # æ·»åŠ åˆ°åŸDataFrame
    df_composite['dli_composite'] = dli_composite_score
    
    # ä¸ºäº†ä¾¿äºè§£é‡Šï¼Œå°†DLIç»¼åˆå¾—åˆ†è½¬æ¢ä¸ºæ­£å€¼ï¼ˆæœ€å°å€¼æ˜ å°„ä¸º0ï¼‰
    min_dli = df_composite['dli_composite'].min()
    if min_dli < 0:
        df_composite['dli_composite_adjusted'] = df_composite['dli_composite'] - min_dli
        logger.info(f"å°†DLIç»¼åˆå¾—åˆ†è°ƒæ•´ä¸ºéè´Ÿå€¼ (æœ€å°å€¼è°ƒæ•´: {min_dli:.4f})")
    else:
        df_composite['dli_composite_adjusted'] = df_composite['dli_composite']
    
    # åŒæ—¶ä¿å­˜æ ‡å‡†åŒ–åçš„å„ç»´åº¦åˆ†å€¼å’Œæƒé‡ä¿¡æ¯
    for dim in required_columns:
        df_composite[f'{dim}_standardized'] = dli_std_df[dim]
    
    # å°†æƒé‡ä¿¡æ¯ä¿å­˜ä¸ºå±æ€§ï¼ˆç”¨äºåç»­åˆ†æï¼‰
    df_composite.attrs = {
        'dli_weights': weight_dict,
        'pca_explained_variance': pca.explained_variance_ratio_[0] if use_pca else None,
        'standardization_params': {
            'mean': scaler.mean_.tolist(),
            'scale': scaler.scale_.tolist()
        }
    }
    
    # ç»Ÿè®¡æ‘˜è¦
    logger.info(f"ğŸ“Š DLIç»¼åˆæŒ‡æ ‡ç»Ÿè®¡:")
    logger.info(f"  åŸå§‹DLIå¾—åˆ†:")
    logger.info(f"    å‡å€¼: {df_composite['dli_composite'].mean():.4f}")
    logger.info(f"    æ ‡å‡†å·®: {df_composite['dli_composite'].std():.4f}")
    logger.info(f"    èŒƒå›´: [{df_composite['dli_composite'].min():.4f}, {df_composite['dli_composite'].max():.4f}]")
    
    if 'dli_composite_adjusted' in df_composite.columns:
        logger.info(f"  è°ƒæ•´åDLIå¾—åˆ†:")
        logger.info(f"    å‡å€¼: {df_composite['dli_composite_adjusted'].mean():.4f}")
        logger.info(f"    æ ‡å‡†å·®: {df_composite['dli_composite_adjusted'].std():.4f}")
        logger.info(f"    èŒƒå›´: [{df_composite['dli_composite_adjusted'].min():.4f}, {df_composite['dli_composite_adjusted'].max():.4f}]")
    
    # æ˜¾ç¤ºå„ç»´åº¦ä¸ç»¼åˆå¾—åˆ†çš„ç›¸å…³æ€§
    logger.info(f"  å„ç»´åº¦ä¸DLIç»¼åˆå¾—åˆ†çš„ç›¸å…³æ€§:")
    for dim in required_columns:
        corr = df_composite[dim].corr(df_composite['dli_composite'])
        logger.info(f"    {dim}: {corr:.4f}")
    
    logger.info("âœ… DLIç»¼åˆæŒ‡æ ‡è®¡ç®—å®Œæˆ!")
    return df_composite

def generate_dli_panel_data(trade_data: pd.DataFrame = None, 
                           data_file_path: str = None,
                           output_path: str = None) -> pd.DataFrame:
    """
    ç”Ÿæˆå®Œæ•´çš„DLIé¢æ¿æ•°æ®é›†
    
    è¿™æ˜¯DLIè®¡ç®—æ¨¡å—çš„ä¸»è¦æ¥å£å‡½æ•°ï¼Œæ•´åˆæ‰€æœ‰DLIç»´åº¦è®¡ç®—æ­¥éª¤
    
    Args:
        trade_data: é¢„å¤„ç†çš„ç¾å›½è´¸æ˜“æ•°æ®DataFrameï¼Œå¦‚æœä¸ºNoneåˆ™ä»æ–‡ä»¶åŠ è½½
        data_file_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨æ ‡å‡†è·¯å¾„
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¿å­˜åˆ°outputsç›®å½•
        
    Returns:
        åŒ…å«å®Œæ•´DLIæŒ‡æ ‡çš„é¢æ¿æ•°æ®DataFrame
        
    è¾“å‡ºåˆ—åŒ…æ‹¬ï¼š
        - åŸºç¡€æ•°æ®ï¼šyear, us_partner, energy_product, trade_value_usd, distance_kmç­‰
        - DLIå››ç»´åº¦ï¼šcontinuity, infrastructure, stability, market_locking_power
        - ç»¼åˆæŒ‡æ ‡ï¼šdli_composite, dli_composite_adjusted
    """
    
    logger.info("ğŸš€ å¼€å§‹ç”ŸæˆDLIé¢æ¿æ•°æ®...")
    
    # ç¬¬1æ­¥ï¼šåŠ è½½æ•°æ®
    if trade_data is not None:
        df = trade_data.copy()
        logger.info(f"ä½¿ç”¨æä¾›çš„è´¸æ˜“æ•°æ®: {len(df)} æ¡è®°å½•")
    else:
        if data_file_path is None:
            base_dir = Path(__file__).parent.parent.parent
            data_file_path = base_dir / "outputs" / "tables" / "us_trade_prepared_for_dli.csv"
        
        if not Path(data_file_path).exists():
            raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file_path}")
        
        df = pd.read_csv(data_file_path)
        logger.info(f"ä»æ–‡ä»¶åŠ è½½è´¸æ˜“æ•°æ®: {data_file_path}, {len(df)} æ¡è®°å½•")
    
    # æ•°æ®éªŒè¯
    required_base_columns = ['year', 'us_partner', 'energy_product', 'trade_value_usd', 'distance_km']
    missing_columns = [col for col in required_base_columns if col not in df.columns]
    if missing_columns:
        raise ValueError(f"æ•°æ®ç¼ºå°‘å¿…éœ€åˆ—: {missing_columns}")
    
    # ç¬¬2æ­¥ï¼šä¾æ¬¡è®¡ç®—å››ä¸ªDLIç»´åº¦
    logger.info("è®¡ç®—DLIå››ä¸ªç»´åº¦æŒ‡æ ‡...")
    
    # è´¸æ˜“æŒç»­æ€§
    df = calculate_continuity(df)
    
    # åŸºç¡€è®¾æ–½å¼ºåº¦
    df = calculate_infrastructure(df)
    
    # è´¸æ˜“ç¨³å®šæ€§
    df = calculate_stability(df)
    
    # å¸‚åœºé”å®šåŠ›
    df = calculate_market_locking_power(df)
    
    # ç¬¬3æ­¥ï¼šè®¡ç®—DLIç»¼åˆæŒ‡æ ‡
    df = calculate_dli_composite(df)
    
    # ç¬¬4æ­¥ï¼šæ•°æ®æ•´ç†å’ŒéªŒè¯
    logger.info("ğŸ”§ æœ€ç»ˆæ•°æ®æ•´ç†...")
    
    # é€‰æ‹©éœ€è¦ä¿å­˜çš„åˆ—
    output_columns = [
        # åŸºç¡€æ ‡è¯†åˆ—
        'year', 'us_partner', 'energy_product', 'us_role',
        # åŸºç¡€æ•°æ®åˆ—
        'trade_value_usd', 'distance_km', 'distance_category',
        # DLIå››ä¸ªç»´åº¦
        'continuity', 'infrastructure', 'stability', 'market_locking_power',
        # DLIç»¼åˆæŒ‡æ ‡
        'dli_composite', 'dli_composite_adjusted'
    ]
    
    # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
    available_columns = [col for col in output_columns if col in df.columns]
    df_output = df[available_columns].copy()
    
    # æŒ‰å…³é”®å­—æ®µæ’åº
    df_output = df_output.sort_values(['year', 'us_partner', 'energy_product', 'us_role'])
    df_output = df_output.reset_index(drop=True)
    
    # æœ€ç»ˆæ•°æ®éªŒè¯
    logger.info("ğŸ” æœ€ç»ˆæ•°æ®éªŒè¯:")
    logger.info(f"  æ€»è®°å½•æ•°: {len(df_output):,}")
    logger.info(f"  å¹´ä»½èŒƒå›´: {df_output['year'].min()}-{df_output['year'].max()}")
    logger.info(f"  è´¸æ˜“ä¼™ä¼´æ•°: {df_output['us_partner'].nunique()}")
    logger.info(f"  èƒ½æºäº§å“æ•°: {df_output['energy_product'].nunique()}")
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    missing_summary = df_output.isnull().sum()
    if missing_summary.any():
        logger.warning("å‘ç°ç¼ºå¤±å€¼:")
        for col, count in missing_summary[missing_summary > 0].items():
            logger.warning(f"  {col}: {count} ä¸ªç¼ºå¤±å€¼")
    else:
        logger.info("âœ… æ— ç¼ºå¤±å€¼")
    
    # DLIæŒ‡æ ‡ç»Ÿè®¡æ‘˜è¦
    dli_columns = ['continuity', 'infrastructure', 'stability', 'market_locking_power', 'dli_composite_adjusted']
    logger.info(f"ğŸ“Š DLIæŒ‡æ ‡æœ€ç»ˆç»Ÿè®¡æ‘˜è¦:")
    for col in dli_columns:
        if col in df_output.columns:
            stats = df_output[col].describe()
            logger.info(f"  {col}:")
            logger.info(f"    å‡å€¼Â±æ ‡å‡†å·®: {stats['mean']:.4f}Â±{stats['std']:.4f}")
            logger.info(f"    èŒƒå›´: [{stats['min']:.4f}, {stats['max']:.4f}]")
            logger.info(f"    åˆ†ä½æ•°(25%,50%,75%): {stats['25%']:.4f}, {stats['50%']:.4f}, {stats['75%']:.4f}")
    
    # ç¬¬5æ­¥ï¼šå¯¼å‡ºæ•°æ®
    if output_path is None:
        base_dir = Path(__file__).parent.parent.parent
        output_dir = base_dir / "outputs" / "tables"
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = output_dir / "dli_panel_data.csv"
    
    df_output.to_csv(output_path, index=False)
    logger.info(f"ğŸ’¾ DLIé¢æ¿æ•°æ®å·²ä¿å­˜è‡³: {output_path}")
    
    # åŒæ—¶ä¿å­˜æƒé‡ä¿¡æ¯åˆ°jsonæ–‡ä»¶
    if hasattr(df, 'attrs') and 'dli_weights' in df.attrs:
        import json
        weights_path = Path(output_path).parent / "dli_weights_and_params.json"
        
        weights_info = {
            'dli_weights': df.attrs['dli_weights'],
            'pca_explained_variance': df.attrs.get('pca_explained_variance'),
            'standardization_params': df.attrs.get('standardization_params'),
            'generation_timestamp': pd.Timestamp.now().isoformat(),
            'data_summary': {
                'total_records': len(df_output),
                'year_range': [int(df_output['year'].min()), int(df_output['year'].max())],
                'num_partners': int(df_output['us_partner'].nunique()),
                'num_products': int(df_output['energy_product'].nunique())
            }
        }
        
        with open(weights_path, 'w', encoding='utf-8') as f:
            json.dump(weights_info, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"ğŸ“„ DLIæƒé‡ä¿¡æ¯å·²ä¿å­˜è‡³: {weights_path}")
    
    logger.info("âœ… DLIé¢æ¿æ•°æ®ç”Ÿæˆå®Œæˆ!")
    return df_output

if __name__ == "__main__":
    # æµ‹è¯•DLIè®¡ç®—åŠŸèƒ½
    try:
        dli_panel = generate_dli_panel_data()
        print(f"âœ… DLIé¢æ¿æ•°æ®ç”ŸæˆæˆåŠŸ!")
        print(f"ğŸ“Š æ•°æ®ç»´åº¦: {dli_panel.shape}")
        print(f"ğŸ”— DLIç»¼åˆæŒ‡æ ‡èŒƒå›´: [{dli_panel['dli_composite_adjusted'].min():.4f}, {dli_panel['dli_composite_adjusted'].max():.4f}]")
        
    except Exception as e:
        logger.error(f"âŒ DLIè®¡ç®—å¤±è´¥: {e}")
        raise