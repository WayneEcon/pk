#!/usr/bin/env python3
"""
092_final_econometric_model æ•°æ®åŠ è½½å™¨
================================

æœ€ç»ˆè®¡é‡åˆ†ææ¨¡å—çš„æ•°æ®æ•´åˆç»„ä»¶
- åŠ è½½åŸºç¡€åˆ†æé¢æ¿æ•°æ®
- æ•´åˆåœ°ç†è·ç¦»æ•°æ®
- æ„å»ºçº¯å‡€LNGä»·æ ¼å˜é‡
- ä¸ºæœ€ç»ˆLP-IRFæ¨¡å‹å‡†å¤‡å®Œæ•´æ•°æ®

ä½œè€…ï¼šEnergy Network Analysis Team
ç‰ˆæœ¬ï¼šv1.0 - å†³å®šæ€§å› æœæ¨æ–­ç‰ˆæœ¬
"""

import pandas as pd
import numpy as np
import json
from pathlib import Path
import logging
from typing import Optional, Dict, Tuple
from scipy.stats import mstats
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

class FinalDataLoader:
    """
    æœ€ç»ˆæ•°æ®åŠ è½½å™¨ - æ•´åˆæ‰€æœ‰æ•°æ®æºä¸ºLP-IRFåˆ†æåšå‡†å¤‡
    """
    
    def __init__(self, project_root: Optional[Path] = None):
        """
        åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        
        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
        """
        if project_root is None:
            self.project_root = Path("/Users/ywz/Desktop/pku/ç¾å›½èƒ½æºç‹¬ç«‹/project/energy_network")
        else:
            self.project_root = Path(project_root)
        
        # å®šä¹‰æ•°æ®è·¯å¾„
        self.analytical_panel_path = self.project_root / "src" / "08_variable_construction" / "outputs" / "analytical_panel.csv"
        self.price_quantity_path = self.project_root / "src" / "08_variable_construction" / "outputs" / "price_quantity_variables.csv"
        self.distance_data_path = Path("/Users/ywz/Desktop/pku/ç¾å›½èƒ½æºç‹¬ç«‹/project/energy_network/src/04_dli_analysis/complete_us_distances_cepii.json")
        self.lng_data_path = Path("/Users/ywz/Desktop/pku/ç¾å›½èƒ½æºç‹¬ç«‹/project/energy_network/src/08_variable_construction/08data/rawdata/lngdata.csv")
        
        logger.info(f"092æ¨¡å—æ•°æ®åŠ è½½å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        
    def load_analytical_panel(self) -> pd.DataFrame:
        """
        åŠ è½½åŸºç¡€åˆ†æé¢æ¿æ•°æ®
        
        Returns:
            åŸºç¡€åˆ†æé¢æ¿DataFrame
        """
        logger.info("ğŸ” åŠ è½½åŸºç¡€åˆ†æé¢æ¿æ•°æ®...")
        
        if not self.analytical_panel_path.exists():
            logger.error(f"âŒ åŸºç¡€åˆ†æé¢æ¿ä¸å­˜åœ¨: {self.analytical_panel_path}")
            return pd.DataFrame()
        
        try:
            df = pd.read_csv(self.analytical_panel_path)
            logger.info(f"âœ… åŸºç¡€é¢æ¿åŠ è½½å®Œæˆ: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
            
            # æ£€æŸ¥æ ¸å¿ƒå˜é‡å­˜åœ¨æ€§
            required_vars = ['country', 'year', 'ovi_gas', 'us_prod_shock', 'log_gdp', 'log_population']
            missing_vars = [var for var in required_vars if var not in df.columns]
            
            if missing_vars:
                logger.warning(f"âš ï¸ ç¼ºå°‘æ ¸å¿ƒå˜é‡: {missing_vars}")
            
            logger.info(f"   æ ¸å¿ƒå˜é‡é½å…¨: {', '.join([v for v in required_vars if v in df.columns])}")
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½åŸºç¡€é¢æ¿å¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def load_distance_data(self) -> Dict:
        """
        åŠ è½½åœ°ç†è·ç¦»æ•°æ®
        
        Returns:
            è·ç¦»æ•°æ®å­—å…¸ {country_code: distance_to_us}
        """
        logger.info("ğŸŒ åŠ è½½åœ°ç†è·ç¦»æ•°æ®...")
        
        if not self.distance_data_path.exists():
            logger.error(f"âŒ è·ç¦»æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.distance_data_path}")
            return {}
        
        try:
            with open(self.distance_data_path, 'r', encoding='utf-8') as f:
                distance_data = json.load(f)
            
            logger.info(f"âœ… è·ç¦»æ•°æ®åŠ è½½å®Œæˆ: {len(distance_data)} ä¸ªå›½å®¶")
            
            # æ˜¾ç¤ºç¤ºä¾‹æ•°æ®
            sample_countries = list(distance_data.items())[:5]
            logger.info(f"   ç¤ºä¾‹æ•°æ®: {sample_countries}")
            
            return distance_data
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½è·ç¦»æ•°æ®å¤±è´¥: {str(e)}")
            return {}
    
    def load_lng_data(self) -> pd.DataFrame:
        """
        åŠ è½½LNGè´¸æ˜“æ•°æ®
        
        Returns:
            LNGæ•°æ®DataFrame
        """
        logger.info("ğŸš¢ åŠ è½½LNGè´¸æ˜“æ•°æ®...")
        
        if not self.lng_data_path.exists():
            logger.error(f"âŒ LNGæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.lng_data_path}")
            return pd.DataFrame()
        
        try:
            df_lng = pd.read_csv(self.lng_data_path)
            logger.info(f"âœ… LNGæ•°æ®åŠ è½½å®Œæˆ: {df_lng.shape[0]} è¡Œ Ã— {df_lng.shape[1]} åˆ—")
            
            # æ£€æŸ¥å…³é”®åˆ—
            required_cols = ['reporterISO', 'refYear', 'primaryValue', 'netWgt']
            missing_cols = [col for col in required_cols if col not in df_lng.columns]
            
            if missing_cols:
                logger.warning(f"âš ï¸ LNGæ•°æ®ç¼ºå°‘åˆ—: {missing_cols}")
                return pd.DataFrame()
            
            # æ˜¾ç¤ºæ•°æ®èŒƒå›´
            if 'refYear' in df_lng.columns:
                year_range = f"{df_lng['refYear'].min()}-{df_lng['refYear'].max()}"
                logger.info(f"   æ—¶é—´èŒƒå›´: {year_range}")
            
            if 'reporterISO' in df_lng.columns:
                country_count = df_lng['reporterISO'].nunique()
                logger.info(f"   æ¶µç›–å›½å®¶: {country_count} ä¸ª")
            
            return df_lng
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½LNGæ•°æ®å¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def merge_distance_data(self, df_panel: pd.DataFrame, distance_data: Dict) -> pd.DataFrame:
        """
        å°†åœ°ç†è·ç¦»æ•°æ®åˆå¹¶åˆ°åˆ†æé¢æ¿
        
        Args:
            df_panel: åŸºç¡€åˆ†æé¢æ¿
            distance_data: è·ç¦»æ•°æ®å­—å…¸
            
        Returns:
            åˆå¹¶äº†è·ç¦»æ•°æ®çš„DataFrame
        """
        logger.info("ğŸ”— åˆå¹¶åœ°ç†è·ç¦»æ•°æ®...")
        
        if df_panel.empty or not distance_data:
            logger.warning("âš ï¸ è¾“å…¥æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡è·ç¦»æ•°æ®åˆå¹¶")
            return df_panel
        
        try:
            df_with_distance = df_panel.copy()
            
            # æ·»åŠ è·ç¦»åˆ—
            df_with_distance['distance_to_us'] = df_with_distance['country'].map(distance_data)
            
            # ç»Ÿè®¡åˆå¹¶ç»“æœ
            matched_countries = df_with_distance['distance_to_us'].notna().sum()
            total_records = len(df_with_distance)
            match_rate = matched_countries / total_records if total_records > 0 else 0
            
            logger.info(f"âœ… è·ç¦»æ•°æ®åˆå¹¶å®Œæˆ:")
            logger.info(f"   â€¢ æˆåŠŸåŒ¹é…: {matched_countries}/{total_records} æ¡è®°å½• ({match_rate:.1%})")
            
            # æ˜¾ç¤ºæœªåŒ¹é…çš„å›½å®¶
            unmatched_countries = df_with_distance[df_with_distance['distance_to_us'].isna()]['country'].unique()
            if len(unmatched_countries) > 0:
                logger.info(f"   â€¢ æœªåŒ¹é…å›½å®¶: {list(unmatched_countries)[:10]}...")
            
            return df_with_distance
            
        except Exception as e:
            logger.error(f"âŒ è·ç¦»æ•°æ®åˆå¹¶å¤±è´¥: {str(e)}")
            return df_panel
    
    def construct_lng_price(self, df_lng: pd.DataFrame) -> pd.DataFrame:
        """
        æ„å»ºçº¯å‡€LNGä»·æ ¼å˜é‡ P_it_lng
        
        Args:
            df_lng: LNGè´¸æ˜“æ•°æ®
            
        Returns:
            åŒ…å«P_it_lngçš„æ¸…æ´æ•°æ®
        """
        logger.info("ğŸ’° æ„å»ºçº¯å‡€LNGä»·æ ¼å˜é‡...")
        
        if df_lng.empty:
            logger.warning("âš ï¸ LNGæ•°æ®ä¸ºç©ºï¼Œæ— æ³•æ„å»ºä»·æ ¼å˜é‡")
            return pd.DataFrame()
        
        try:
            # å¤åˆ¶æ•°æ®
            df_lng_clean = df_lng.copy()
            
            # æ ‡å‡†åŒ–åˆ—å
            column_mapping = {
                'reporterISO': 'country',
                'refYear': 'year',
                'primaryValue': 'trade_value_usd',
                'netWgt': 'net_weight_kg'
            }
            
            for old_col, new_col in column_mapping.items():
                if old_col in df_lng_clean.columns:
                    df_lng_clean = df_lng_clean.rename(columns={old_col: new_col})
            
            # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
            required_cols = ['country', 'year', 'trade_value_usd', 'net_weight_kg']
            missing_cols = [col for col in required_cols if col not in df_lng_clean.columns]
            
            if missing_cols:
                logger.error(f"âŒ ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                return pd.DataFrame()
            
            # è®¡ç®—å•ä»· P_it_lng = Trade Value (US$) / Net Weight (kg)
            logger.info("   è®¡ç®—åŸå§‹LNGå•ä»·...")
            df_lng_clean = df_lng_clean[
                (df_lng_clean['trade_value_usd'] > 0) & 
                (df_lng_clean['net_weight_kg'] > 0)
            ].copy()
            
            df_lng_clean['P_it_lng_raw'] = (
                df_lng_clean['trade_value_usd'] / df_lng_clean['net_weight_kg']
            )
            
            # ç§»é™¤æ˜æ˜¾å¼‚å¸¸å€¼
            valid_prices = df_lng_clean[df_lng_clean['P_it_lng_raw'] > 0]
            logger.info(f"   åŸå§‹ä»·æ ¼è§‚æµ‹æ•°: {len(valid_prices)}")
            
            # 1%å’Œ99%ç¼©å°¾å¤„ç†
            logger.info("   æ‰§è¡Œ1%å’Œ99%ç¼©å°¾å¤„ç†...")
            price_values = valid_prices['P_it_lng_raw'].values
            
            # ä½¿ç”¨scipyçš„mstats.winsorizeè¿›è¡Œç¼©å°¾
            winsorized_prices = mstats.winsorize(price_values, limits=[0.01, 0.01])
            
            # åˆ›å»ºæœ€ç»ˆä»·æ ¼æ•°æ®
            df_price_final = valid_prices.copy()
            df_price_final['P_it_lng'] = winsorized_prices
            
            # æŒ‰å›½å®¶-å¹´ä»½èšåˆï¼ˆå–å‡å€¼ï¼‰
            logger.info("   æŒ‰å›½å®¶-å¹´ä»½èšåˆä»·æ ¼æ•°æ®...")
            df_price_agg = df_price_final.groupby(['country', 'year']).agg({
                'P_it_lng': 'mean',
                'trade_value_usd': 'sum',
                'net_weight_kg': 'sum'
            }).reset_index()
            
            # ç»Ÿè®¡æœ€ç»ˆç»“æœ
            final_countries = df_price_agg['country'].nunique()
            final_records = len(df_price_agg)
            year_range = f"{df_price_agg['year'].min()}-{df_price_agg['year'].max()}"
            
            logger.info(f"âœ… LNGä»·æ ¼æ„å»ºå®Œæˆ:")
            logger.info(f"   â€¢ æœ€ç»ˆè®°å½•æ•°: {final_records}")
            logger.info(f"   â€¢ æ¶µç›–å›½å®¶: {final_countries} ä¸ª")
            logger.info(f"   â€¢ æ—¶é—´èŒƒå›´: {year_range}")
            logger.info(f"   â€¢ ä»·æ ¼èŒƒå›´: ${df_price_agg['P_it_lng'].min():.4f} - ${df_price_agg['P_it_lng'].max():.4f} /kg")
            
            return df_price_agg
            
        except Exception as e:
            logger.error(f"âŒ æ„å»ºLNGä»·æ ¼å¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def merge_lng_price_data(self, df_panel: pd.DataFrame, df_lng_price: pd.DataFrame) -> pd.DataFrame:
        """
        å°†LNGä»·æ ¼æ•°æ®åˆå¹¶åˆ°ä¸»åˆ†æé¢æ¿
        
        Args:
            df_panel: ä¸»åˆ†æé¢æ¿ï¼ˆå·²å«è·ç¦»æ•°æ®ï¼‰
            df_lng_price: LNGä»·æ ¼æ•°æ®
            
        Returns:
            æœ€ç»ˆçš„å®Œæ•´åˆ†ææ•°æ®
        """
        logger.info("ğŸ”— åˆå¹¶LNGä»·æ ¼æ•°æ®...")
        
        if df_panel.empty:
            logger.warning("âš ï¸ ä¸»åˆ†æé¢æ¿ä¸ºç©º")
            return df_panel
        
        if df_lng_price.empty:
            logger.warning("âš ï¸ LNGä»·æ ¼æ•°æ®ä¸ºç©ºï¼Œå°†æ·»åŠ ç©ºçš„P_it_lngåˆ—")
            df_panel['P_it_lng'] = np.nan
            return df_panel
        
        try:
            # æ‰§è¡Œå·¦è¿æ¥åˆå¹¶
            df_final = df_panel.merge(
                df_lng_price[['country', 'year', 'P_it_lng']], 
                on=['country', 'year'], 
                how='left'
            )
            
            # ç»Ÿè®¡åˆå¹¶ç»“æœ
            total_records = len(df_final)
            lng_matched = df_final['P_it_lng'].notna().sum()
            lng_countries = df_final[df_final['P_it_lng'].notna()]['country'].nunique()
            match_rate = lng_matched / total_records if total_records > 0 else 0
            
            logger.info(f"âœ… LNGä»·æ ¼æ•°æ®åˆå¹¶å®Œæˆ:")
            logger.info(f"   â€¢ LNGä»·æ ¼è¦†ç›–: {lng_matched}/{total_records} æ¡è®°å½• ({match_rate:.1%})")
            logger.info(f"   â€¢ æœ‰LNGæ•°æ®çš„å›½å®¶: {lng_countries} ä¸ª")
            
            return df_final
            
        except Exception as e:
            logger.error(f"âŒ LNGä»·æ ¼æ•°æ®åˆå¹¶å¤±è´¥: {str(e)}")
            return df_panel
    
    def load_price_quantity_data(self) -> pd.DataFrame:
        """
        åŠ è½½ä»·æ ¼æ•°é‡å˜é‡æ•°æ® (P_it, g_it)
        
        Returns:
            ä»·æ ¼æ•°é‡æ•°æ®DataFrame
        """
        logger.info("ğŸ“Š åŠ è½½ä»·æ ¼æ•°é‡å˜é‡æ•°æ®...")
        
        if not self.price_quantity_path.exists():
            logger.error(f"âŒ ä»·æ ¼æ•°é‡æ–‡ä»¶ä¸å­˜åœ¨: {self.price_quantity_path}")
            return pd.DataFrame()
        
        try:
            df_pq = pd.read_csv(self.price_quantity_path)
            logger.info(f"âœ… ä»·æ ¼æ•°é‡æ•°æ®åŠ è½½å®Œæˆ: {df_pq.shape[0]} è¡Œ Ã— {df_pq.shape[1]} åˆ—")
            
            # æ£€æŸ¥å…³é”®åˆ—
            required_cols = ['country', 'year', 'P_it', 'g_it']
            missing_cols = [col for col in required_cols if col not in df_pq.columns]
            
            if missing_cols:
                logger.warning(f"âš ï¸ ä»·æ ¼æ•°é‡æ•°æ®ç¼ºå°‘åˆ—: {missing_cols}")
                return pd.DataFrame()
            
            # æ˜¾ç¤ºæ•°æ®èŒƒå›´
            if 'year' in df_pq.columns:
                year_range = f"{df_pq['year'].min()}-{df_pq['year'].max()}"
                logger.info(f"   æ—¶é—´èŒƒå›´: {year_range}")
            
            if 'country' in df_pq.columns:
                country_count = df_pq['country'].nunique()
                logger.info(f"   æ¶µç›–å›½å®¶: {country_count} ä¸ª")
            
            # æ•°æ®è´¨é‡ç»Ÿè®¡
            p_it_valid = df_pq['P_it'].notna().sum()
            g_it_valid = df_pq['g_it'].notna().sum()
            logger.info(f"   P_itæœ‰æ•ˆè§‚æµ‹: {p_it_valid}")
            logger.info(f"   g_itæœ‰æ•ˆè§‚æµ‹: {g_it_valid}")
            
            return df_pq
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ä»·æ ¼æ•°é‡æ•°æ®å¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def merge_price_quantity_data(self, df_panel: pd.DataFrame, df_pq: pd.DataFrame) -> pd.DataFrame:
        """
        å°†ä»·æ ¼æ•°é‡æ•°æ®åˆå¹¶åˆ°ä¸»åˆ†æé¢æ¿
        
        Args:
            df_panel: ä¸»åˆ†æé¢æ¿
            df_pq: ä»·æ ¼æ•°é‡æ•°æ®
            
        Returns:
            åˆå¹¶åçš„DataFrame
        """
        logger.info("ğŸ”— åˆå¹¶ä»·æ ¼æ•°é‡æ•°æ®...")
        
        if df_panel.empty:
            logger.warning("âš ï¸ ä¸»åˆ†æé¢æ¿ä¸ºç©º")
            return df_panel
        
        if df_pq.empty:
            logger.warning("âš ï¸ ä»·æ ¼æ•°é‡æ•°æ®ä¸ºç©ºï¼Œå°†æ·»åŠ ç©ºçš„P_itå’Œg_itåˆ—")
            df_panel['P_it'] = np.nan
            df_panel['g_it'] = np.nan
            return df_panel
        
        try:
            # æ‰§è¡Œå·¦è¿æ¥åˆå¹¶
            df_merged = df_panel.merge(
                df_pq[['country', 'year', 'P_it', 'g_it']], 
                on=['country', 'year'], 
                how='left'
            )
            
            # ç»Ÿè®¡åˆå¹¶ç»“æœ
            total_records = len(df_merged)
            p_it_matched = df_merged['P_it'].notna().sum()
            g_it_matched = df_merged['g_it'].notna().sum()
            pq_countries = df_merged[df_merged['P_it'].notna() | df_merged['g_it'].notna()]['country'].nunique()
            
            logger.info(f"âœ… ä»·æ ¼æ•°é‡æ•°æ®åˆå¹¶å®Œæˆ:")
            logger.info(f"   â€¢ P_itè¦†ç›–: {p_it_matched}/{total_records} æ¡è®°å½• ({p_it_matched/total_records:.1%})")
            logger.info(f"   â€¢ g_itè¦†ç›–: {g_it_matched}/{total_records} æ¡è®°å½• ({g_it_matched/total_records:.1%})")
            logger.info(f"   â€¢ æœ‰ä»·æ ¼æ•°é‡æ•°æ®çš„å›½å®¶: {pq_countries} ä¸ª")
            
            return df_merged
            
        except Exception as e:
            logger.error(f"âŒ ä»·æ ¼æ•°é‡æ•°æ®åˆå¹¶å¤±è´¥: {str(e)}")
            return df_panel

    def load_clean_lng_price(self) -> pd.DataFrame:
        """
        åŠ è½½æ¸…ç†åçš„LNGä»·æ ¼æ•°æ®
        
        Returns:
            æ¸…ç†åçš„LNGä»·æ ¼DataFrame
        """
        logger.info("ğŸš¢ åŠ è½½æ¸…ç†åçš„LNGä»·æ ¼æ•°æ®...")
        
        clean_lng_path = Path("outputs/clean_lng_price_data.csv")
        
        if not clean_lng_path.exists():
            logger.warning(f"âš ï¸ æ¸…ç†åçš„LNGæ•°æ®ä¸å­˜åœ¨: {clean_lng_path}")
            logger.info("   è¯·å…ˆè¿è¡Œ clean_lng_data.py è„šæœ¬")
            return pd.DataFrame()
        
        try:
            df_lng = pd.read_csv(clean_lng_path)
            logger.info(f"âœ… æ¸…ç†åLNGæ•°æ®åŠ è½½å®Œæˆ: {df_lng.shape[0]} è¡Œ Ã— {df_lng.shape[1]} åˆ—")
            
            # æ£€æŸ¥å¿…è¦åˆ—
            required_cols = ['country', 'year', 'P_lng']
            missing_cols = [col for col in required_cols if col not in df_lng.columns]
            
            if missing_cols:
                logger.warning(f"âš ï¸ LNGæ•°æ®ç¼ºå°‘åˆ—: {missing_cols}")
                return pd.DataFrame()
            
            # æ•°æ®è´¨é‡ç»Ÿè®¡
            valid_prices = df_lng['P_lng'].notna().sum()
            logger.info(f"   æœ‰æ•ˆä»·æ ¼è®°å½•: {valid_prices}")
            logger.info(f"   æ¶µç›–å›½å®¶: {df_lng['country'].nunique()} ä¸ª")
            logger.info(f"   æ—¶é—´èŒƒå›´: {df_lng['year'].min()}-{df_lng['year'].max()}")
            logger.info(f"   ä»·æ ¼èŒƒå›´: ${df_lng['P_lng'].min():.4f} - ${df_lng['P_lng'].max():.4f} /kg")
            
            return df_lng
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ¸…ç†åLNGæ•°æ®å¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def merge_clean_lng_price(self, df_panel: pd.DataFrame, df_lng: pd.DataFrame) -> pd.DataFrame:
        """
        å°†æ¸…ç†åçš„LNGä»·æ ¼æ•°æ®åˆå¹¶åˆ°ä¸»åˆ†æé¢æ¿
        
        Args:
            df_panel: ä¸»åˆ†æé¢æ¿
            df_lng: æ¸…ç†åçš„LNGä»·æ ¼æ•°æ®
            
        Returns:
            æœ€ç»ˆçš„å®Œæ•´åˆ†ææ•°æ®
        """
        logger.info("ğŸ”— åˆå¹¶æ¸…ç†åçš„LNGä»·æ ¼æ•°æ®...")
        
        if df_panel.empty:
            logger.warning("âš ï¸ ä¸»åˆ†æé¢æ¿ä¸ºç©º")
            return df_panel
        
        if df_lng.empty:
            logger.warning("âš ï¸ LNGä»·æ ¼æ•°æ®ä¸ºç©ºï¼Œå°†æ·»åŠ ç©ºçš„P_lngåˆ—")
            df_panel['P_lng'] = np.nan
            return df_panel
        
        try:
            # æ‰§è¡Œå·¦è¿æ¥åˆå¹¶
            df_final = df_panel.merge(
                df_lng[['country', 'year', 'P_lng']], 
                on=['country', 'year'], 
                how='left'
            )
            
            # ç»Ÿè®¡åˆå¹¶ç»“æœ
            total_records = len(df_final)
            lng_matched = df_final['P_lng'].notna().sum()
            lng_countries = df_final[df_final['P_lng'].notna()]['country'].nunique()
            match_rate = lng_matched / total_records if total_records > 0 else 0
            
            logger.info(f"âœ… LNGä»·æ ¼æ•°æ®åˆå¹¶å®Œæˆ:")
            logger.info(f"   â€¢ P_lngè¦†ç›–: {lng_matched}/{total_records} æ¡è®°å½• ({match_rate:.1%})")
            logger.info(f"   â€¢ æœ‰LNGä»·æ ¼æ•°æ®çš„å›½å®¶: {lng_countries} ä¸ª")
            
            return df_final
            
        except Exception as e:
            logger.error(f"âŒ LNGä»·æ ¼æ•°æ®åˆå¹¶å¤±è´¥: {str(e)}")
            return df_panel

    def load_complete_dataset(self) -> Tuple[pd.DataFrame, Dict]:
        """
        åŠ è½½å®Œæ•´çš„æœ€ç»ˆåˆ†ææ•°æ®é›†
        
        Returns:
            (å®Œæ•´æ•°æ®é›†, æ•°æ®ç»Ÿè®¡ä¿¡æ¯)
        """
        logger.info("ğŸš€ å¼€å§‹åŠ è½½å®Œæ•´çš„æœ€ç»ˆåˆ†ææ•°æ®é›†...")
        
        # æ­¥éª¤1: åŠ è½½åŸºç¡€åˆ†æé¢æ¿
        df_panel = self.load_analytical_panel()
        if df_panel.empty:
            return pd.DataFrame(), {'status': 'failed', 'message': 'åŸºç¡€é¢æ¿åŠ è½½å¤±è´¥'}
        
        # æ­¥éª¤2: åŠ è½½ä»·æ ¼æ•°é‡æ•°æ® (P_it, g_it)
        df_pq = self.load_price_quantity_data()
        
        # æ­¥éª¤3: åˆå¹¶ä»·æ ¼æ•°é‡æ•°æ®
        df_with_pq = self.merge_price_quantity_data(df_panel, df_pq)
        
        # æ­¥éª¤4: åŠ è½½åœ°ç†è·ç¦»æ•°æ®
        distance_data = self.load_distance_data()
        
        # æ­¥éª¤5: åˆå¹¶è·ç¦»æ•°æ®
        df_with_distance = self.merge_distance_data(df_with_pq, distance_data)
        
        # æ­¥éª¤6: åŠ è½½æ¸…ç†åçš„LNGä»·æ ¼æ•°æ®
        df_lng_price = self.load_clean_lng_price()
        
        # æ­¥éª¤7: æœ€ç»ˆåˆå¹¶
        df_final = self.merge_clean_lng_price(df_with_distance, df_lng_price)
        
        # ç”Ÿæˆæ•°æ®ç»Ÿè®¡
        stats = self._generate_dataset_stats(df_final)
        
        logger.info(f"ğŸ‰ å®Œæ•´æ•°æ®é›†æ„å»ºå®Œæˆ:")
        logger.info(f"   â€¢ æœ€ç»ˆå½¢çŠ¶: {df_final.shape}")
        logger.info(f"   â€¢ æ ¸å¿ƒå˜é‡å®Œæ•´æ€§: {stats['core_variables_status']}")
        
        return df_final, stats
    
    def _generate_dataset_stats(self, df: pd.DataFrame) -> Dict:
        """
        ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            df: æœ€ç»ˆæ•°æ®é›†
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if df.empty:
            return {'status': 'empty', 'message': 'æ•°æ®é›†ä¸ºç©º'}
        
        # æ ¸å¿ƒå˜é‡æ£€æŸ¥
        core_vars = ['country', 'year', 'ovi_gas', 'us_prod_shock', 'distance_to_us', 'P_it', 'g_it', 'P_lng', 'log_gdp', 'log_population']
        core_status = {}
        
        for var in core_vars:
            if var in df.columns:
                non_null_count = df[var].notna().sum()
                total_count = len(df)
                core_status[var] = {
                    'available': True,
                    'coverage': f"{non_null_count}/{total_count} ({non_null_count/total_count:.1%})"
                }
            else:
                core_status[var] = {'available': False, 'coverage': '0/0 (0.0%)'}
        
        return {
            'status': 'success',
            'total_observations': len(df),
            'total_countries': df['country'].nunique() if 'country' in df.columns else 0,
            'year_range': f"{df['year'].min()}-{df['year'].max()}" if 'year' in df.columns and not df['year'].isna().all() else 'N/A',
            'core_variables_status': core_status,
            'columns': list(df.columns)
        }


def main():
    """æµ‹è¯•æ•°æ®åŠ è½½åŠŸèƒ½"""
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')
    
    print("ğŸ”¬ 092_final_econometric_model æ•°æ®åŠ è½½å™¨æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    loader = FinalDataLoader()
    
    # åŠ è½½å®Œæ•´æ•°æ®é›†
    df_final, stats = loader.load_complete_dataset()
    
    print(f"\nğŸ“Š æœ€ç»ˆæ•°æ®é›†ç»Ÿè®¡:")
    print(f"   â€¢ æ•°æ®å½¢çŠ¶: {df_final.shape}")
    print(f"   â€¢ çŠ¶æ€: {stats.get('status', 'unknown')}")
    
    if stats['status'] == 'success':
        print(f"   â€¢ æ€»è§‚æµ‹æ•°: {stats['total_observations']}")
        print(f"   â€¢ å›½å®¶æ•°: {stats['total_countries']}")
        print(f"   â€¢ æ—¶é—´èŒƒå›´: {stats['year_range']}")
        
        print(f"\nğŸ“‹ æ ¸å¿ƒå˜é‡çŠ¶æ€:")
        for var, info in stats['core_variables_status'].items():
            status_icon = "âœ…" if info['available'] else "âŒ"
            print(f"   {status_icon} {var}: {info['coverage']}")
    
    print(f"\nğŸ‰ æ•°æ®åŠ è½½å™¨æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    main()